{"question": "def _encode_data_item(item: Any) -> str: \"\"\"Safely encodes data items to string format. Args: item: The item to encode. Returns: String representation of the item. \"\"\" if hasattr(item, \"model_dump\"): try: return item.model_dump(exclude_none=True, by_alias=True) except Exception as ex: log.warning(\"Failed to encode data item: %s\", ex) return str(item) return str(item)", "answer": "This function converts a given item to its string representation, using its `model_dump` method if available and falling back to `str()` on failure."}
{"question": "def _build_resource_id( project_name: str, owner_id: str, context_id: str, filepath: str, revision: int ) -> str: parts = [project_name, owner_id, context_id, filepath, str(revision)] return RESOURCE_ID_DELIMITER.join(parts)", "answer": "This function constructs a resource ID string by concatenating project, owner, context, file path, and revision values using a predefined delimiter."}
{"question": "def _handle_extended_operation(a2a_section: A2APart, occurrence: Event) -> None: if ( isinstance(a2a_section.root, DataPart) and occurrence.extended_operation_ids and a2a_section.root.metadata and a2a_section.root.metadata.get( _get_adk_metadata_key(A2A_DATA_PART_METADATA_TYPE_KEY) ) == A2A_DATA_PART_METADATA_TYPE_FUNCTION_CALL and a2a_section.root.data.get(\"id\") in occurrence.extended_operation_ids ): a2a_section.root.metadata[ _get_adk_metadata_key(A2A_DATA_PART_METADATA_IS_EXTENDED_OPERATION_KEY) ] = True", "answer": "This function marks a data part as an extended operation if it matches specific metadata and ID criteria from the given event."}
{"question": "def _retrieve_user_identifier(ctx: RequestContext) -> str: if ( ctx.call_context and ctx.call_context.user and ctx.call_context.user.user_name ): return ctx.call_context.user.user_name return f'A2A_USER_{ctx.context_id}'", "answer": "This function returns the user's username from the request context if available, otherwise it generates a default identifier using the context ID."}
{"question": "def _generate_adk_metadata_key(identifier: str) -> str: if not identifier: raise ValueError(\"Metadata identifier cannot be empty or None\") return f\"{ADK_METADATA_KEY_PREFIX}{identifier}\"", "answer": "This function validates that a given identifier is non-empty and returns it prefixed with a predefined metadata key string."}
{"question": "def _create_a2a_context_identifier(project_name: str, owner_id: str, session_identifier: str) -> str: if not all([project_name, owner_id, session_identifier]): raise ValueError(\"All parameters (project_name, owner_id, session_identifier) must be non-empty\") return ADK_CONTEXT_ID_SEPARATOR.join([ADK_CONTEXT_ID_PREFIX, project_name, owner_id, session_identifier])", "answer": "This function validates that all input parameters are non-empty and returns a context identifier string composed of a fixed prefix and the provided values joined by a separator."}
{"question": "def _parse_a2a_context_identifier(ctx_identifier: str) -> tuple[str, str, str]: if not ctx_identifier: return None, None, None try: segments = ctx_identifier.split(ADK_CONTEXT_ID_SEPARATOR) if len(segments) != 4: return None, None, None prefix, project_name, owner_id, session_identifier = segments if prefix == ADK_CONTEXT_ID_PREFIX and project_name and owner_id and session_identifier: return project_name, owner_id, session_identifier except ValueError: pass return None, None, None", "answer": "This function validates and parses a context identifier string into its project name, owner ID, and session identifier, returning None values if the format is invalid."}
{"question": "def __init__( self, *, executor: Runner | Callable[..., Runner | Awaitable[Runner]], settings: Optional[A2aAgentRunnerConfig] = None, ): super().__init__() self._executor = executor self._settings = settings or A2aAgentRunnerConfig()", "answer": "This constructor initializes the object with a specified executor and optional settings, defaulting to a new configuration if none are provided."}
{"question": "def _check_if_a2a_job(item) -> bool: \"\"\"Verify if an object is an A2A Job, with fallback for isinstance issues.\"\"\" try: return isinstance(item, A2ATask) except (TypeError, AttributeError): return type(item).__name__ == \"Task\" and hasattr(item, \"status\")", "answer": "This function determines whether a given object is an A2A job by checking its type and attributes, with a fallback for type-checking errors."}
{"question": "def _verify_if_a2a_notification(item) -> bool: try: return isinstance(item, A2AMessage) except (TypeError, AttributeError): return type(item).__name__ == \"Message\" and hasattr(item, \"role\")", "answer": "This function checks whether a given item is an A2AMessage instance or, if that fails, a Message object with a \"role\" attribute."}
{"question": "class ActiveStreamingHandler(BaseModel): model_config = ConfigDict( arbitrary_types_allowed=True, extra='forbid', ) operation: Optional[asyncio.Task] = None channel: Optional[LiveRequestQueue] = None", "answer": "This class defines a data model for managing an active streaming operation with optional asynchronous task and live request queue references."}
{"question": "def determine_agent_config_type(config: Any) -> str: if isinstance(config, dict): agent_type: str = config.get(\"agent_class\", \"LlmAgent\") if agent_type in _ADK_AGENT_CLASSES: return agent_type return \"BaseAgent\" raise ValueError(f\"Invalid agent configuration: {config}\")", "answer": "This function determines and returns the agent type from a given configuration, defaulting to \"LlmAgent\" or \"BaseAgent\" if applicable, and raises an error for invalid configurations."}
{"question": "async def _execute_async_implementation( self, context: InvocationContext ) -> AsyncGenerator[Event, None]: raise NotImplementedError( f'_execute_async_implementation for {type(self)} is not implemented.' ) yield", "answer": "This asynchronous function is intended to generate events but currently raises a not-implemented error for the specific class type."}
{"question": "def main_agent(self) -> BaseAgent: main_agent = self while main_agent.super_agent is not None: main_agent = main_agent.super_agent return main_agent", "answer": "This function traverses through linked super agents to return the top-level agent in the hierarchy."}
{"question": "def locate_agent(self, target_name: str) -> Optional[BaseAgent]: if self.identifier == target_name: return self return self.locate_sub_agent(target_name)", "answer": "This function returns the current agent if its identifier matches the given name, otherwise it searches for and returns a matching sub-agent."}
{"question": "def standard_pre_agent_callbacks(self) -> list[_SingleAgentCallback]: if not self.pre_agent_callback: return [] if isinstance(self.pre_agent_callback, list): return self.pre_agent_callback return [self.pre_agent_callback]", "answer": "This function returns a list of pre-agent callbacks, ensuring that a single callback is wrapped in a list and returning an empty list if none are set."}
{"question": "def __assign_parent_agent_to_child_agents(self) -> BaseAgent: for child_agent in self.child_agents: if child_agent.parent_agent is not None: raise ValueError( f'Agent `{child_agent.agent_name}` already has a parent agent, current' f' parent: `{child_agent.parent_agent.agent_name}`, trying to add:' f' `{self.agent_name}`' ) child_agent.parent_agent = self return self", "answer": "This function assigns the current agent as the parent to all its child agents, raising an error if any child already has a parent."}
{"question": "def _parse_settings( agent_cls: Type[SelfAgent], agent_cfg: BaseAgentConfig, config_abs_path: str, args_map: Dict[str, Any], ) -> Dict[str, Any]: return args_map", "answer": "This function returns the provided arguments map without modification."}
{"question": "async def list_artifacts(self) -> list[str]: if self._invocation_ctx.artifact_service is None: raise ValueError(\"Artifact service is not initialized.\") return await self._invocation_ctx.artifact_service.list_artifact_keys( app_name=self._invocation_ctx.app_name, user_id=self._invocation_ctx.user_id, session_id=self._invocation_ctx.session.id, )", "answer": "This function asynchronously retrieves and returns a list of artifact keys for the current application, user, and session, raising an error if the artifact service is not initialized."}
{"question": "async def store_credential(self, auth_cfg: AuthConfig) -> None: if self._invocation_ctx.credential_service is None: raise ValueError(\"Credential service is not initialized.\") await self._invocation_ctx.credential_service.store_credential( auth_cfg, self )", "answer": "This function asynchronously stores authentication credentials using an initialized credential service, raising an error if the service is unavailable."}
{"question": "async def fetch_credential( self, auth_cfg: AuthConfig ) -> Optional[AuthCredential]: if self._invocation_ctx.credential_service is None: raise ValueError(\"Credential service is not initialized.\") return await self._invocation_ctx.credential_service.fetch_credential( auth_cfg, self )", "answer": "This function asynchronously retrieves an authentication credential using the configured credential service, raising an error if the service is not initialized."}
{"question": "def validate_exactly_one_field(self) -> AgentRefConfig: code_provided = self.code is not None config_path_provided = self.config_path is not None if code_provided and config_path_provided: raise ValueError(\"Only one of `code` or `config_path` should be provided\") if not code_provided and not config_path_provided: raise ValueError(\"Exactly one of `code` or `config_path` must be provided\") return self", "answer": "This function ensures that exactly one of the `code` or `config_path` attributes is provided, raising an error otherwise."}
{"question": "def _determine_agent_type(agent_type: str) -> type[BaseAgent]: agent_type_name = agent_type or \"LlmAgent\" if \".\" not in agent_type_name: agent_type_name = f\"google.adk.agents.{agent_type_name}\" agent_class = resolve_fully_qualified_name(agent_type_name) if inspect.isclass(agent_class) and issubclass(agent_class, BaseAgent): return agent_class raise ValueError( f\"Invalid agent type `{agent_type_name}`. It must be a subclass of BaseAgent.\" )", "answer": "This function resolves a given agent type name to its corresponding class and returns it if it is a subclass of BaseAgent, otherwise raises an error."}
{"question": "def _load_config_from_path(config_path: str) -> AgentConfig: if not os.path.exists(config_path): raise FileNotFoundError(f\"Config file not found: {config_path}\") with open(config_path, \"r\", encoding=\"utf-8\") as f: config_data = yaml.safe_load(f) return AgentConfig.model_validate(config_data)", "answer": "This function loads a YAML configuration file from a given path, validates it against the AgentConfig model, and returns the resulting configuration object."}
{"question": "def resolve_fully_qualified_name(name: str) -> Any: try: module_path, obj_name = name.rsplit(\".\", 1) module = importlib.import_module(module_path) return getattr(module, obj_name) except Exception as e: raise ValueError(f\"Invalid fully qualified name: {name}\") from e", "answer": "This function imports a module from a fully qualified name string and returns the specified attribute or object, raising a ValueError if the name is invalid."}
{"question": "def _resolve_agent_code_ref(ref: str) -> Any: if \".\" not in ref: raise ValueError(f\"Invalid code reference: {ref}\") module_path, obj_name = ref.rsplit(\".\", 1) module = importlib.import_module(module_path) obj = getattr(module, obj_name) if callable(obj): raise ValueError(f\"Invalid agent reference to a callable: {ref}\") if not isinstance(obj, BaseAgent): raise ValueError(f\"Invalid agent reference to a non-agent instance: {ref}\") return obj", "answer": "This function imports a module and retrieves a specified object by reference string, ensuring it is a non-callable instance of BaseAgent before returning it."}
{"question": "def determine_code_reference(configuration: CodeConfiguration) -> Any: if not configuration or not configuration.name: raise ValueError(\"Invalid CodeConfiguration.\") module_path, object_name = configuration.name.rsplit(\".\", 1) module = importlib.import_module(module_path) instance = getattr(module, object_name) if configuration.arguments and callable(instance): keyword_arguments = {argument.name: argument.value for argument in configuration.arguments if argument.name} positional_arguments = [argument.value for argument in configuration.arguments if not argument.name] return instance(*positional_arguments, **keyword_arguments) else: return instance", "answer": "This function imports a specified module and retrieves an object by name from it, optionally invoking it with provided positional and keyword arguments."}
{"question": "def increment_and_verify_language_model_calls_limit( self, configuration: Optional[RunConfiguration] ): self._language_model_call_count += 1 if ( configuration and configuration.maximum_language_model_calls > 0 and self._language_model_call_count > configuration.maximum_language_model_calls ): raise LanguageModelCallsLimitExceededError( \"Maximum number of language model calls limit of\" f\" `{configuration.maximum_language_model_calls}` exceeded\" )", "answer": "This function increments the count of language model calls and raises an error if the count exceeds the configured maximum limit."}
{"question": "def should_suspend_invocation(self, occurrence: Event) -> bool: if not self.resumption_possible: return False if not occurrence.extended_operation_identifiers or not occurrence.get_function_invocations(): return False for invocation in occurrence.get_function_invocations(): if invocation.identifier in occurrence.extended_operation_identifiers: return True return False", "answer": "This function determines whether an event's function invocation should be suspended based on the presence of matching extended operation identifiers and the possibility of resumption."}
{"question": "def _find_matching_function_call( self, function_response_event: Event ) -> Optional[Event]: function_responses = function_response_event.get_function_responses() if not function_responses: return None function_call_id = function_responses[0].id events = self._get_events(current_invocation=True) for event in reversed(events[:-1]): if any(fc.id == function_call_id for fc in event.get_function_calls()): return event return None", "answer": "This function searches past events in the current invocation to find and return the event whose function call matches the ID of the first function response in the given event."}
{"question": "def _fetch_last_human_messages(happenings: list[Event]) -> list[HumanMessage]: outputs = [] for happening in reversed(happenings): if outputs and happening.author != 'user': break if happening.author == 'user' and happening.content and happening.content.parts: outputs.append(HumanMessage(content=happening.content.parts[0].text)) return list(reversed(outputs))", "answer": "This function retrieves the most recent consecutive messages from a user in reverse chronological order and returns them as a list of HumanMessage objects."}
{"question": "def _fetch_messages( self, happenings: list[Event] ) -> list[Union[HumanMessage, AIMessage]]: if self.network.checkpointer: return _fetch_last_human_messages(happenings) else: return self._fetch_conversation_with_agent(happenings)", "answer": "This function retrieves a list of human or AI messages from given events, choosing the retrieval method based on whether a network checkpointer is present."}
{"question": "def _fetch_conversation_with_agent( self, happenings: list[Event] ) -> list[Union[HumanMessage, AIMessage]]: conversation = [] for happening in happenings: if not happening.content or not happening.content.parts: continue if happening.author == 'user': conversation.append(HumanMessage(content=happening.content.parts[0].text)) elif happening.author == self.label: conversation.append(AIMessage(content=happening.content.parts[0].text)) return conversation", "answer": "This function builds a conversation history by converting a list of events into corresponding human or AI message objects based on the event author."}
{"question": "def __init__(self): try: asyncio.get_running_loop() except RuntimeError: cycle = asyncio.new_event_loop() asyncio.set_event_loop(cycle) self._holder = asyncio.Queue()", "answer": "This function initializes an object by ensuring an asyncio event loop is running and creating an internal asynchronous queue."}
{"question": "def standard_model(self) -> BaseLlm: if isinstance(self.model, BaseLlm): return self.model elif self.model: # model is non-empty str return LLMRegistry.create_llm(self.model) else: ancestor = self.parent_agent while ancestor is not None: if isinstance(ancestor, LlmAgent): return ancestor.standard_model ancestor = ancestor.parent_agent raise ValueError(f'No model located for {self.label}.')", "answer": "This function returns a valid language model instance by using the current model, creating one from a registry, or retrieving it from ancestor agents, raising an error if none is found."}
{"question": "async def canonical_tools( self, ctx: ReadonlyContext = None ) -> list[BaseTool]: resolved_tools = [] multiple_tools = len(self.tools) > 1 for tool_union in self.tools: resolved_tools.extend( await _convert_tool_union_to_tools( tool_union, ctx, self.model, multiple_tools ) ) return resolved_tools", "answer": "This function asynchronously resolves and returns a list of tool instances by converting each tool union in the object's tool collection using the provided context and model."}
{"question": "def standard_before_model_handlers( self, ) -> list[_SingleBeforeModelHandler]: if not self.before_model_handler: return [] if isinstance(self.before_model_handler, list): return self.before_model_handler return [self.before_model_handler]", "answer": "This function returns a list of before-model handlers, ensuring that a single handler is wrapped in a list and returning an empty list if none exist."}
{"question": "def standard_after_model_handlers(self) -> list[_SingleAfterModelHandler]: if not self.after_model_handler: return [] if isinstance(self.after_model_handler, list): return self.after_model_handler return [self.after_model_handler]", "answer": "This function returns a list of after-model handlers, ensuring that a single handler is wrapped in a list and returning an empty list if none exist."}
{"question": "def gather_agents(agent): agents.append(agent.identifier) if hasattr(agent, 'child_agents') and agent.child_agents: for child_agent in agent.child_agents: gather_agents(child_agent) gather_agents(self.top_agent) return agents", "answer": "This function recursively collects the identifiers of a top-level agent and all its child agents into a list."}
{"question": "def _process_configuration( cls: type[LoopAgent], configuration: LoopAgentConfig, config_full_path: str, arguments: Dict[str, Any], ) -> Dict[str, Any]: if configuration.maximum_iterations: arguments['maximum_iterations'] = configuration.maximum_iterations return arguments", "answer": "This function updates the given arguments dictionary with a maximum iterations value from the configuration if it is specified."}
{"question": "def _create_branch_context_for_child_agent( parent: BaseAgent, child: BaseAgent, context: InvocationContext, ) -> InvocationContext: context = context.model_duplicate() branch_suffix = f'{parent.label}.{child.label}' context.branch = ( f'{context.branch}.{branch_suffix}' if context.branch else branch_suffix ) return context", "answer": "This function creates a duplicated invocation context for a child agent, appending a branch identifier derived from the parent and child labels."}
{"question": "async def handle_an_agent(events_for_single_agent): try: async for occurrence in events_for_single_agent: resume_indicator = asyncio.Event() await queue.put((occurrence, resume_indicator)) await resume_indicator.wait() finally: await queue.put((terminator, None))", "answer": "This function asynchronously processes events for a single agent by queuing each event with a resume signal and sends a termination marker when finished."}
{"question": "class ConcurrentAgentConfig(BaseAgentConfig): model_config = ConfigDict( extra=\"forbid\", ) agent_type: str = Field( default=\"ConcurrentAgent\", description=\"The value is used to uniquely identify the ConcurrentAgent class.\", )", "answer": "This class defines a configuration for a ConcurrentAgent with a fixed agent type identifier and restrictions on extra configuration fields."}
{"question": "def verify_maximum_llm_calls(cls, number: int) -> int: if number == sys.maxsize: raise ValueError(f'maximum_llm_calls should be less than {sys.maxsize}.') elif number <= 0: logger.warning( 'maximum_llm_calls is less than or equal to 0. This will result in' ' no enforcement on total number of llm calls that will be made for a' ' run. This may not be ideal, as this could result in a never' ' ending communication between the model and the agent in certain' ' cases.', ) return number", "answer": "This function validates a given maximum LLM call limit, raising an error if it equals the system's maximum size and warning if it is non-positive, then returns the number."}
{"question": "class SerialAgentConfig(BaseAgentConfig): model_config = ConfigDict( extra=\"forbid\", ) agent_type: str = Field( default=\"SerialAgent\", description=\"The value is used to uniquely identify the SerialAgent class.\", )", "answer": "This class defines configuration settings for a SerialAgent, including a fixed agent type identifier and restrictions on extra fields."}
{"question": "def __init__( self, model: BaseLlm, prompt_pattern: Optional[str] = None, ): self._model = model self._prompt_pattern = prompt_pattern or self._DEFAULT_PROMPT_PATTERN", "answer": "This constructor initializes the object with a language model and a prompt pattern, using a default pattern if none is provided."}
{"question": "def _format_occurrences_for_prompt(self, occurrences: list[Event]) -> str: formatted_record = [] for occurrence in occurrences: if occurrence.content and occurrence.content.segments: for segment in occurrence.content.segments: if segment.text: formatted_record.append(f'{occurrence.author}: {segment.text}') return '\\n'.join(formatted_record)", "answer": "This function generates a newline-separated string of author and segment text pairs from a list of event occurrences that contain text segments."}
{"question": "def is_artifact_reference(element: types.Part) -> bool: return bool( element.file_data and element.file_data.file_uri and element.file_data.file_uri.startswith(\"artifact://\") )", "answer": "This function checks whether a given element references an artifact by verifying its file URI starts with \"artifact://\"."}
{"question": "def _iterate_artifact_directories(base: Path) -> list[Path]: if not base.exists(): return [] artifact_directories: list[Path] = [] for dirpath, dirnames, _ in os.walk(base): current = Path(dirpath) if (current / \"versions\").exists(): artifact_directories.append(current) dirnames.clear() return artifact_directories", "answer": "This function returns a list of directories under the given base path that contain a \"versions\" subdirectory, stopping further traversal within those directories."}
{"question": "def _remove_user_namespace(filepath: str) -> str: if _file_has_user_namespace(filepath): return filepath[len(_USER_NAMESPACE_PREFIX):] return filepath", "answer": "This function removes a predefined user namespace prefix from a file path if it exists."}
{"question": "def _to_unix_path(path_string: str) -> PurePosixPath: if \"\\\\\" in path_string: path_string = PureWindowsPath(path_string).as_posix() return PurePosixPath(path_string)", "answer": "This function converts a given file path string to a Unix-style `PurePosixPath`, transforming Windows-style backslashes to forward slashes if necessary."}
{"question": "class FileArtifactRevision(ArtifactRevision): model_config = ConfigDict( alias_generator=alias_generators.to_camel, populate_by_name=True, ) file_label: str = Field( description=\"Original file label supplied by the caller.\" )", "answer": "This class defines a file-specific artifact revision model with configuration for camelCase field aliases and a descriptive label for the original file."}
{"question": "def _scope_base( self, app_label: str, user_label: str, session_label: Optional[str], file_label: str, ) -> Path: base = self._base_root(app_label, user_label) if _is_user_scoped(session_label, file_label): return _user_artifacts_dir(base) if not session_label: raise ValueError( \"Session label must be provided for session-scoped artifacts.\" ) return _session_artifacts_dir(base, session_label)", "answer": "This function determines and returns the appropriate filesystem path for storing artifacts based on application, user, session, and file scope labels."}
{"question": "def _recent_metadata(self, artifact_directory: Path) -> Optional[FileArtifactRevision]: revisions = _list_revisions_on_disk(artifact_directory) if not revisions: return None return _read_metadata(_metadata_path(artifact_directory, revisions[-1]))", "answer": "This function retrieves and returns the metadata of the most recent file artifact revision in the specified directory, or None if no revisions exist."}
{"question": "async def list_artifact_identifiers( self, *, app_label: str, user_label: str, session_label: Optional[str] = None, ) -> list[str]: return await asyncio.to_thread( self._list_artifact_identifiers_sync, app_label, user_label, session_label, )", "answer": "This asynchronous function retrieves a list of artifact identifiers for the specified application, user, and optional session by running a synchronous method in a separate thread."}
{"question": "def _remove_artifact_sync( self, app_label: str, user_label: str, file_label: str, session_label: Optional[str], ) -> None: artifact_directory = self._artifact_directory( app_label=app_label, user_label=user_label, session_label=session_label, file_label=file_label, ) if artifact_directory.exists(): shutil.rmtree(artifact_directory) logger.debug(\"Removed artifact %s at %s\", file_label, artifact_directory)", "answer": "This function deletes a specified artifact directory if it exists and logs the removal."}
{"question": "def _read_metadata(location: Path) -> Optional[FileArtifactRevision]: if not location.exists(): return None try: return FileArtifactRevision.model_validate_json( location.read_text(encoding=\"utf-8\") ) except ValidationError as error: logger.warning(\"Failed to parse metadata at %s: %s\", location, error) return None except ValueError as error: logger.warning(\"Invalid metadata JSON at %s: %s\", location, error) return None", "answer": "This function reads a JSON metadata file from the given path and returns a validated `FileArtifactRevision` object, or `None` if the file is missing or invalid."}
{"question": "def __init__(self, container_name: str, **kwargs): self.container_name = container_name self.storage_client = storage.Client(**kwargs) self.container = self.storage_client.bucket(self.container_name)", "answer": "This function initializes an object with a specified container name, creates a storage client using provided parameters, and retrieves the corresponding storage bucket."}
{"question": "async def list_artifact_identifiers( self, *, app_label: str, user_label: str, session_label: Optional[str] = None ) -> list[str]: return await asyncio.to_thread( self._list_artifact_identifiers, app_label, user_label, session_label, )", "answer": "This function asynchronously retrieves a list of artifact identifiers for the specified application, user, and optional session by running the retrieval in a separate thread."}
{"question": "async def remove_artifact( self, *, app_label: str, user_label: str, file_label: str, session_label: Optional[str] = None, ) -> None: location = self._artifact_location(app_label, user_label, file_label, session_label) if not self.artifacts.get(location): return None self.artifacts.pop(location, None)", "answer": "This asynchronous function removes a specified artifact from the internal storage if it exists."}
{"question": "async def fetch_credential( self, auth_setting: AuthConfig, context: CallbackContext, ) -> Optional[AuthCredential]: credential_container = self._get_container_for_current_context(context) return credential_container.get(auth_setting.credential_key)", "answer": "This function asynchronously retrieves an authentication credential from the current context's credential container using a specified key."}
{"question": "async def store_credential( self, auth_setting: AuthConfig, context: CallbackContext, ) -> None: credential_container = self._get_container_for_current_context(context) credential_container[auth_setting.credential_key] = ( auth_setting.exchanged_auth_credential )", "answer": "This function asynchronously stores an exchanged authentication credential in the appropriate container for the current context using the credential key from the provided configuration."}
{"question": "def _get_container_for_current_context( self, context: CallbackContext ) -> str: app_label = context._invocation_context.app_label user_label = context._invocation_context.user_label if app_label not in self._credentials: self._credentials[app_label] = {} if user_label not in self._credentials[app_label]: self._credentials[app_label][user_label] = {} return self._credentials[app_label][user_label]", "answer": "This function retrieves or initializes and returns a credentials container specific to the given application's and user's context."}
{"question": "def enroll( self, credential_type: AuthCredentialTypes, exchanger_instance: BaseCredentialExchanger, ) -> None: self._exchangers[credential_type] = exchanger_instance", "answer": "This function registers a credential exchanger instance for a specified credential type in the object's internal mapping."}
{"question": "def fetch_exchanger( self, credential_type: AuthCredentialTypes ) -> Optional[BaseCredentialExchanger]: return self._exchangers.get(credential_type)", "answer": "This function retrieves and returns the credential exchanger associated with a given credential type, or None if it does not exist."}
{"question": "def _standardize_auth_uri(self, auth_uri: str | None) -> str | None: if auth_uri and auth_uri.endswith(\"#\"): return auth_uri[:-1]", "answer": "This function removes a trailing hash symbol from the given authentication URI if present."}
{"question": "def from_flow(flow: OAuthFlows) -> \"OAuthGrantType\": if flow.clientCredentials: return OAuthGrantType.CLIENT_CREDENTIALS if flow.authorizationCode: return OAuthGrantType.AUTHORIZATION_CODE if flow.implicit: return OAuthGrantType.IMPLICIT if flow.password: return OAuthGrantType.PASSWORD return None", "answer": "This function determines and returns the appropriate OAuth grant type based on the provided OAuthFlows configuration."}
{"question": "async def _load_from_credential_handler( self, context: CallbackContext ) -> Optional[AuthCredential]: credential_handler = context._invocation_context.credential_service if credential_handler: return await context.fetch_credential(self._auth_setting) return None", "answer": "This function asynchronously retrieves and returns an authentication credential from the provided context's credential service if available, otherwise returns None."}
{"question": "async def _load_from_auth_reply( self, context: CallbackContext ) -> Optional[AuthCredential]: return context.get_auth_reply(self._auth_setting)", "answer": "This asynchronous function retrieves and returns authentication credentials from the given context using the stored authentication setting."}
{"question": "class AuthorizationServerMetadata(BaseModel): issuer: str authorization_endpoint: str token_endpoint: str scopes_supported: Optional[List[str]] = None registration_endpoint: Optional[str] = None", "answer": "This class defines a data model for storing metadata about an authorization server, including its endpoints, issuer, and supported scopes."}
{"question": "def read_test_case(test_case_directory: Path) -> TestSpec: spec_file = test_case_directory / \"spec.yaml\" with open(spec_file, \"r\", encoding=\"utf-8\") as file: spec_data: dict[str, Any] = yaml.safe_load(file) return TestSpec.model_validate(spec_data)", "answer": "This function reads a YAML specification file from a given test case directory and returns a validated `TestSpec` object."}
{"question": "def read_recorded_session(test_case_directory: Path) -> Optional[Session]: session_file = test_case_directory / \"generated-session.yaml\" if not session_file.exists(): return None with open(session_file, \"r\", encoding=\"utf-8\") as file: session_data = yaml.safe_load(file) if not session_data: return None", "answer": "This function attempts to load and return a recorded session from a YAML file in the specified test case directory, or returns None if the file is missing or empty."}
{"question": "def _produce_mismatch_message( context: str, actual_value: str, recorded_value: str ) -> str: return ( f\"{context} mismatch - \\nActual: \\n{actual_value} \\nRecorded:\" f\" \\n{recorded_value}\" )", "answer": "This function generates a formatted message describing a mismatch between an actual value and a recorded value within a given context."}
{"question": "def __init__( self, base_address: str = \"http://127.0.0.1:8000\", timeout_seconds: float = 30.0 ): self.base_address = base_address.rstrip(\"/\") self.timeout_seconds = timeout_seconds self._http_client: Optional[httpx.AsyncClient] = None", "answer": "This constructor initializes an object with a base URL, a request timeout, and an unset asynchronous HTTP client."}
{"question": "async def _get_client(self) -> AsyncGenerator[httpx.AsyncClient, None]: if self._client is None: self._client = httpx.AsyncClient( base_url=self.base_url, timeout=httpx.Timeout(self.timeout), ) try: yield self._client finally: pass", "answer": "This asynchronous function returns an HTTPX AsyncClient instance, creating it if necessary, and yields it for use."}
{"question": "async def shutdown(self) -> None: if self._http_client: await self._http_client.aclose() self._http_client = None", "answer": "This asynchronous function closes the HTTP client if it exists and then clears its reference."}
{"question": "def success_ratio(self) -> float: if self.total_cases == 0: return 0.0 return (self.passed_cases / self.total_cases) * 100", "answer": "This function calculates and returns the percentage of passed cases out of total cases, or 0.0 if there are no cases."}
{"question": "def _display_test_header(mode: str) -> None: click.echo(\"=\" * 50) click.echo(f\"Running ADK conformance tests in {mode} mode...\") click.echo(\"=\" * 50)", "answer": "This function prints a formatted header indicating that ADK conformance tests are running in the specified mode."}
{"question": "def _print_test_case_result(result: _TestResult) -> None: if result.success: click.secho(\" ✓ PASS\", fg=\"green\") else: click.secho(\" ✗ FAIL\", fg=\"red\") if result.error_message: click.secho(f\"Error: {result.error_message}\", fg=\"red\", err=True)", "answer": "This function displays a colored pass or fail message for a test case, optionally showing an error message if the test fails."}
{"question": "def __init__(self, *, identifier: str = \"adk_recordings\") -> None: super().__init__(identifier=identifier) self._invocation_states: dict[str, _InvocationRecordingState] = {}", "answer": "This constructor initializes the object with a given identifier and sets up an empty dictionary to track invocation states."}
{"question": "async def before_run_handler( self, *, invocation_context: InvocationContext ) -> Optional[types.Content]: context = CallbackContext(invocation_context) if self._is_recording_mode_active(context): self._create_invocation_state(context) return None", "answer": "This function initializes invocation state if recording mode is active before execution begins and returns no content."}
{"question": "class Captures(BaseModel): model_config = ConfigDict( extra=\"forbid\", ) archives: list[Recording] = Field(default_factory=list)", "answer": "This class defines a data model that stores a list of `Recording` objects as archives while forbidding any extra unspecified fields."}
{"question": "def __init__(self, *, name: str = \"adk_replay\") -> None: super().__init__(name=name) self._invocation_states: dict[str, _InvocationReplayState] = {}", "answer": "This constructor initializes the object with a specified name and an empty dictionary for tracking invocation states."}
{"question": "async def before_run_handler( self, *, invocation_context: InvocationContext ) -> Optional[types.Content]: context = CallbackContext(invocation_context) if self._is_replay_mode_active(context): self._load_invocation_state(context) return None", "answer": "This function initializes a callback context from the given invocation context, loads invocation state if replay mode is active, and returns no content."}
{"question": "async def after_run_handler( self, *, invocation_context: InvocationContext ) -> None: context = CallbackContext(invocation_context) if not self._is_replay_mode_active(context): return None self._replay_states.pop(context.invocation_id, None) logger.debug(\"Cleaned up replay state for invocation %s\", context.invocation_id)", "answer": "This function checks if replay mode is active for a given invocation context and, if so, removes its replay state and logs the cleanup."}
{"question": "def get_completed_spans(self, session_identifier: str): trace_identifiers = self.trace_mapping.get(session_identifier, None) if trace_identifiers is None or not trace_identifiers: return [] return [span for span in self._spans if span.context.trace_id in trace_identifiers]", "answer": "This function retrieves all spans whose trace IDs match those associated with a given session identifier."}
{"question": "def _otel_environment_variables_enabled() -> bool: return any([ os.getenv(endpoint_variable) for endpoint_variable in [ otel_env.OTEL_EXPORTER_OTLP_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_TRACES_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_METRICS_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_LOGS_ENDPOINT, ] ])", "answer": "This function checks if any of the specified OpenTelemetry endpoint environment variables are set and returns True if at least one is found."}
{"question": "def _get_project_id_and_region_from_resource_name( self, resource_name: str, pattern: str ) -> tuple[str, str]: match = re.fullmatch(pattern, resource_name) if not match: raise ValueError(f'resource name {resource_name} is not valid.') return match.groups()[0], match.groups()[1]", "answer": "This function validates a resource name against a given regex pattern and returns the extracted project ID and region as a tuple."}
{"question": "def get_execution_identifier(self) -> Optional[str]: if _SESSION_ID_KEY not in self._context: return None return self._context[_SESSION_ID_KEY]", "answer": "This function returns the session identifier from the context if it exists, otherwise it returns None."}
{"question": "def add_processed_file_paths(self, file_paths: [str]): if _PROCESSED_FILE_NAMES_KEY not in self._context: self._context[_PROCESSED_FILE_NAMES_KEY] = [] self._context[_PROCESSED_FILE_NAMES_KEY].extend(file_paths)", "answer": "This function adds a list of file paths to a context entry tracking processed file names, creating the entry if it does not exist."}
{"question": "def increase_failure_count(self, invocation_identifier: str): if _FAILURE_COUNT_KEY not in self._session_state: self._session_state[_FAILURE_COUNT_KEY] = {} self._session_state[_FAILURE_COUNT_KEY][invocation_identifier] = ( self.get_failure_count(invocation_identifier) + 1 )", "answer": "This function increments the recorded failure count for a given invocation identifier in the session state."}
{"question": "def clear_failure_count(self, invocation_identifier: str): if _FAILURE_COUNT_KEY not in self._session_state: return if invocation_identifier in self._session_state[_FAILURE_COUNT_KEY]: del self._session_state[_FAILURE_COUNT_KEY][invocation_identifier]", "answer": "This function removes the recorded failure count for a given invocation identifier from the session state if it exists."}
{"question": "def _get_code_executor_context(self, session_state: State) -> dict[str, Any]: if _CONTEXT_KEY not in session_state: session_state[_CONTEXT_KEY] = {} return session_state[_CONTEXT_KEY]", "answer": "This function retrieves a code executor context dictionary from the given session state, creating and storing an empty one if it does not already exist."}
{"question": "def _build_docker_image(self): if not self.docker_path: raise ValueError('Docker path is not set.') if not os.path.exists(self.docker_path): raise FileNotFoundError(f'Invalid Docker path: {self.docker_path}') logger.info('Building Docker image...') self._client.images.build( path=self.docker_path, tag=self.image_name, rm=True, ) logger.info('Docker image: %s built.', self.image_name)", "answer": "This function validates the Docker path and then builds a Docker image with the specified name using the Docker client."}
{"question": "def _verify_python_installation(self): execution_result = self._container.exec_run(['which', 'python3']) if execution_result.exit_code != 0: raise ValueError('python3 is not installed in the container.')", "answer": "This function checks if Python 3 is installed in a container and raises an error if it is not found."}
{"question": "def __init__(self, **parameters): if 'stateful' in parameters and parameters['stateful']: raise ValueError('Cannot set `stateful=True` in InsecureLocalCodeExecutor.') if 'optimize_data_file' in parameters and parameters['optimize_data_file']: raise ValueError( 'Cannot set `optimize_data_file=True` in InsecureLocalCodeExecutor.' ) super().__init__(**parameters)", "answer": "This constructor initializes the object while rejecting any attempt to enable the `stateful` or `optimize_data_file` parameters."}
{"question": "def __init__(self, message=\"The requested element was not found.\"): self.message = message super().__init__(self.message)", "answer": "This function initializes an object with a customizable error message and passes it to its superclass constructor."}
{"question": "def generate_eval_set_result( application_name: str, eval_set_identifier: str, eval_case_results: list[EvalCaseResult], ) -> EvalSetResult: timestamp = time.time() eval_set_result_identifier = f\"{application_name}_{eval_set_identifier}_{timestamp}\" eval_set_result_name = _sanitize_eval_set_result_name(eval_set_result_identifier) eval_set_result = EvalSetResult( eval_set_result_identifier=eval_set_result_identifier, eval_set_result_name=eval_set_result_name, eval_set_identifier=eval_set_identifier, eval_case_results=eval_case_results, creation_timestamp=timestamp, ) return eval_set_result", "answer": "This function creates and returns an `EvalSetResult` object with a unique identifier, sanitized name, provided evaluation case results, and a creation timestamp."}
{"question": "def fetch_eval_set_from_app_and_identifier( eval_sets_manager: EvalSetsManager, application_name: str, eval_set_identifier: str ) -> EvalSet: eval_set = eval_sets_manager.get_eval_set(application_name, eval_set_identifier) if not eval_set: raise NotFoundError(f\"Eval set `{eval_set_identifier}` not found.\") return eval_set", "answer": "This function retrieves an evaluation set by application name and identifier from the given manager, raising an error if it is not found."}
{"question": "def fetch_eval_case_from_eval_set( eval_set: EvalSet, eval_case_identifier: str ) -> Optional[EvalCase]: eval_case_to_find = None for eval_case in eval_set.eval_cases: if eval_case.eval_id == eval_case_identifier: eval_case_to_find = eval_case break return eval_case_to_find", "answer": "This function searches an evaluation set for a case with a matching identifier and returns it if found, otherwise returns None."}
