{"question": "This function is designed to take an input value of any type and produce a string representation that is safe for use as serialized metadata. It first checks whether the given value has an attribute named `model_dump`, which suggests that the object follows a certain interface or comes from a library that supports structured serialization. If such an attribute exists, the function attempts to call `model_dump` with parameters that exclude any fields whose values are `None` and that use alias names for fields instead of their original names. This call is wrapped in a try-except block to handle any errors that might occur during serialization. If an exception is raised, the function logs a warning message indicating that serialization failed, including the error details, and then falls back to converting the value to a string using Python’s built-in `str()` function. If the original value does not have a `model_dump` method, the function simply returns its string representation directly. The overall logic ensures that objects capable of structured dumping are serialized in a more controlled and consistent way, while still providing a safe fallback for other types or in case of errors.", "answer": "def _serialize_metadata_value(value: Any) -> str: \"\"\"Safely serializes metadata values to string format. Args: value: The value to serialize. Returns: String representation of the value. \"\"\" if hasattr(value, \"model_dump\"): try: return value.model_dump(exclude_none=True, by_alias=True) except Exception as e: logger.warning(\"Failed to serialize metadata value: %s\", e) return str(value) return str(value)"}
{"question": "This function is designed to generate a unique identifier string for an artifact by combining several pieces of information into a single value. It accepts five inputs: the name of the application, the identifier of the user, the identifier of the session, the name of the file, and a numeric version. Inside the function, these inputs are collected into a list, with the numeric version converted into a string so that all elements are of the same type. The function then joins these elements together into one continuous string, using a predefined separator value referenced by the constant `ARTIFACT_ID_SEPARATOR`. The resulting string represents a composite identifier that encodes all the provided details in a consistent format, making it suitable for uniquely distinguishing artifacts based on their origin, ownership, session context, file name, and version number.", "answer": "def _create_artifact_id( app_name: str, user_id: str, session_id: str, filename: str, version: int ) -> str: components = [app_name, user_id, session_id, filename, str(version)] return ARTIFACT_ID_SEPARATOR.join(components)"}
{"question": "This function is designed to inspect a given `A2APart` object in the context of an `Event` and determine whether it represents a function call that should be marked as a long-running tool. It begins by checking several conditions in sequence. First, it verifies that the `root` attribute of the `A2APart` is an instance of `DataPart`. It then ensures that the event contains a list or collection of identifiers for long-running tools. Next, it confirms that the `root` object has associated metadata. Within that metadata, it looks up a specific key—derived from a helper function that generates metadata keys—and checks whether the stored value matches a predefined constant indicating that the data part represents a function call. Finally, it checks whether the `id` value stored in the `root`’s data is present in the event’s list of long-running tool IDs. If all of these conditions are satisfied, the function updates the metadata of the `root` object by setting another specific metadata key—again generated by the helper function—to `True`. This effectively flags the data part as being associated with a long-running tool, allowing other parts of the system to recognize and handle it accordingly.", "answer": "def _process_long_running_tool(a2a_part: A2APart, event: Event) -> None: if ( isinstance(a2a_part.root, DataPart) and event.long_running_tool_ids and a2a_part.root.metadata and a2a_part.root.metadata.get( _get_adk_metadata_key(A2A_DATA_PART_METADATA_TYPE_KEY) ) == A2A_DATA_PART_METADATA_TYPE_FUNCTION_CALL and a2a_part.root.data.get(\"id\") in event.long_running_tool_ids ): a2a_part.root.metadata[ _get_adk_metadata_key(A2A_DATA_PART_METADATA_IS_LONG_RUNNING_KEY) ] = True"}
{"question": "This function is designed to determine and return a user identifier based on information contained in a given request object. It accepts a single argument, which is expected to be an instance of a request context containing details about the current call and its associated user. The function first checks whether the request has a call context, whether that call context includes a user object, and whether that user object has a non-empty user name. If all of these conditions are met, it returns the user name directly, treating it as the definitive identifier. If any of these conditions fail—meaning the request does not have a call context, the call context does not have a user, or the user does not have a valid user name—the function constructs a fallback identifier. This fallback is a string that begins with a fixed prefix indicating an automated or system-to-system user, followed by the request’s context ID, ensuring that even in the absence of explicit user information, a unique identifier can still be generated. This approach ensures that the function always returns a valid string representing the user, either from actual user data or from a generated placeholder based on the request context.", "answer": "def _get_user_id(request: RequestContext) -> str: if ( request.call_context and request.call_context.user and request.call_context.user.user_name ): return request.call_context.user.user_name return f'A2A_USER_{request.context_id}'"}
{"question": "This function is designed to generate a standardized metadata key string by combining a predefined prefix with a user-provided key. It accepts a single argument, which must be a string. The first step in its logic is to validate the input: if the provided key is either empty or evaluates to a false value such as `None` or an empty string, the function immediately stops execution and raises a `ValueError` with a clear message indicating that the metadata key cannot be empty or null. This ensures that only valid, non-empty keys are processed. If the input passes this validation, the function constructs the final metadata key by concatenating a constant prefix, referenced as `ADK_METADATA_KEY_PREFIX`, with the given key. The result is returned as a single string, which can then be used elsewhere in the application to consistently identify or store metadata entries. This approach enforces both input integrity and a uniform naming convention for metadata keys.", "answer": "def _get_adk_metadata_key(key: str) -> str: if not key: raise ValueError(\"Metadata key cannot be empty or None\") return f\"{ADK_METADATA_KEY_PREFIX}{key}\""}
{"question": "This function is designed to generate a standardized context identifier string based on three input values: the application name, a user identifier, and a session identifier. It begins by checking that all three parameters have been provided and are non-empty. This validation is done by grouping the parameters into a list and using a built-in function to confirm that none of them are empty or evaluate to false. If any of the inputs fail this check, the function immediately stops execution and raises an error, clearly stating that all parameters must be non-empty. Once the inputs are confirmed to be valid, the function constructs the context identifier by combining a predefined prefix with the three provided values. The combination is performed by joining these elements into a single string, using a predefined separator constant to ensure consistent formatting. The resulting string follows a fixed structure: it starts with the prefix, followed by the application name, then the user ID, and finally the session ID, each separated by the designated separator. This output serves as a unique and consistently formatted identifier that can be used elsewhere in the system to reference a specific application-user-session context.", "answer": "def _to_a2a_context_id(app_name: str, user_id: str, session_id: str) -> str: if not all([app_name, user_id, session_id]): raise ValueError(\"All parameters (app_name, user_id, session_id) must be non-empty\") return ADK_CONTEXT_ID_SEPARATOR.join([ADK_CONTEXT_ID_PREFIX, app_name, user_id, session_id])"}
{"question": "This function is designed to take a string that represents a specific type of context identifier and extract meaningful components from it, provided it matches an expected format. It begins by checking whether the input string is present at all; if the string is empty or missing, it immediately returns a tuple of three `None` values, indicating that no valid data could be obtained. If a string is provided, the function attempts to split it into separate parts using a predefined separator constant. The expected format is that the string should break into exactly four segments. If the split does not produce exactly four parts, the function concludes that the input is invalid and returns three `None` values. When the split yields four parts, these are assigned to variables representing a prefix, an application name, a user identifier, and a session identifier. The function then checks that the prefix matches a predefined constant and that the other three components are all non-empty. If these conditions are met, it returns a tuple containing the application name, user identifier, and session identifier, effectively extracting the useful information from the original string. If any error occurs during the splitting process, such as a `ValueError`, the function ignores the error and proceeds to return three `None` values. In all cases where the input does not meet the expected structure or fails validation, the function returns a tuple of `None` values to signal that no valid context information could be extracted.", "answer": "def _from_a2a_context_id(context_id: str) -> tuple[str, str, str]: if not context_id: return None, None, None try: parts = context_id.split(ADK_CONTEXT_ID_SEPARATOR) if len(parts) != 4: return None, None, None prefix, app_name, user_id, session_id = parts if prefix == ADK_CONTEXT_ID_PREFIX and app_name and user_id and session_id: return app_name, user_id, session_id except ValueError: pass return None, None, None"}
{"question": "This code defines a constructor method for a class, which is responsible for initializing new instances of that class. It requires a parameter named `runner`, which can either be an instance of the `Runner` type or a callable object that, when invoked, returns either a `Runner` instance or an awaitable that resolves to a `Runner`. This design allows flexibility in how the runner is provided, supporting both direct instances and functions that create or supply them asynchronously or synchronously. An optional parameter named `config` can also be provided. If it is not supplied, the constructor will automatically create a new instance of `A2aAgentExecutorConfig` to use as the configuration. The constructor begins by calling the parent class’s initializer to ensure proper setup of inherited behavior. It then stores the provided `runner` in a private instance variable for later use, and stores either the provided configuration or the newly created default configuration in another private instance variable. This setup ensures that every instance of the class has a runner mechanism and a configuration object ready for use in subsequent operations.", "answer": "def __init__( self, *, runner: Runner | Callable[..., Runner | Awaitable[Runner]], config: Optional[A2aAgentExecutorConfig] = None, ): super().__init__() self._runner = runner self._config = config or A2aAgentExecutorConfig()"}
{"question": "This function is designed to determine whether a given object should be considered an instance of a specific type called `A2ATask`. It first attempts to use Python’s built-in `isinstance` check, which is the standard way to verify if an object belongs to a particular class. This check is wrapped in a `try` block because, in certain situations, calling `isinstance` can raise exceptions such as `TypeError` or `AttributeError`—for example, if the class reference is incompatible with the object or if the object’s type information is unusual or incomplete. If such an exception occurs, the function falls back to a more manual identification method. In this fallback, it checks whether the object’s type name is exactly `\"Task\"` and also verifies that the object has an attribute named `status`. This secondary check acts as a heuristic to recognize objects that behave like an `A2ATask` even if they cannot be directly confirmed through `isinstance`. The function ultimately returns a boolean value indicating whether the object meets either the direct type check or the fallback criteria. This approach ensures robustness when dealing with objects that may come from different contexts, modules, or serialization boundaries where normal type checking might fail.", "answer": "def _is_a2a_task(obj) -> bool: \"\"\"Check if an object is an A2A Task, with fallback for isinstance issues.\"\"\" try: return isinstance(obj, A2ATask) except (TypeError, AttributeError): return type(obj).__name__ == \"Task\" and hasattr(obj, \"status\")"}
{"question": "This function is designed to determine whether a given object should be considered an “A2A message.” It accepts a single argument and attempts to verify its type in two different ways. The first approach is to check if the object is an instance of the `A2AMessage` class using Python’s built-in `isinstance` function. This is wrapped in a try block to guard against situations where the type check might fail due to unexpected conditions, such as the class not being defined or the object being of a type that causes `isinstance` to raise a `TypeError` or `AttributeError`. If such an exception occurs, the function falls back to a secondary check: it inspects the object’s type name and ensures it matches the string `\"Message\"`, and also verifies that the object has an attribute named `role`. If both of these conditions are met, the function treats the object as an A2A message. In all other cases, it returns `False`. This dual-check approach allows the function to handle both the standard `A2AMessage` type and certain compatible objects that meet specific structural criteria.", "answer": "def _is_a2a_message(obj) -> bool: try: return isinstance(obj, A2AMessage) except (TypeError, AttributeError): return type(obj).__name__ == \"Message\" and hasattr(obj, \"role\")"}
{"question": "This code defines a class named `ActiveStreamingTool` that inherits from `BaseModel`, which suggests it is using Pydantic or a similar data validation and configuration framework. The class is configured with a `model_config` object that specifies certain behaviors: it allows arbitrary types to be assigned to its fields, meaning that type checking will not be strictly enforced for non-standard Python types, and it forbids any extra fields that are not explicitly declared in the class definition. Within the class, there are two attributes defined. The first attribute, `task`, can hold either an `asyncio.Task` object or be `None`. This indicates that the class is designed to potentially manage or track an asynchronous task, such as a coroutine running in the background. The second attribute, `stream`, can hold either a `LiveRequestQueue` object or be `None`. This suggests that the class may be associated with a streaming or live data handling mechanism, where `LiveRequestQueue` likely represents a queue structure for managing incoming live requests or data packets. Overall, the class appears to be a structured data model intended to represent the state of an active streaming tool, keeping track of both an asynchronous execution task and a live data stream queue, while enforcing strict control over which fields can exist and allowing flexibility in the types stored in those fields.", "answer": "class ActiveStreamingTool(BaseModel): model_config = ConfigDict( arbitrary_types_allowed=True, extra='forbid', ) task: Optional[asyncio.Task] = None stream: Optional[LiveRequestQueue] = None"}
{"question": "This function is designed to determine and return the appropriate agent class name based on the input it receives. It accepts a single argument, which can be of any type. The first step is to check whether the provided value is a dictionary. If it is not a dictionary, the function immediately raises an error indicating that the agent configuration is invalid, including the problematic value in the error message. When the input is a dictionary, the function looks for a key named \"agent_class\". If that key exists, its value is retrieved; if it does not exist, a default value of \"LlmAgent\" is used instead. The retrieved or default agent class name is then checked against a predefined collection of valid agent class names, represented by `_ADK_AGENT_CLASSES`. If the name is found in that collection, it is returned as the result. If it is not found, the function returns the string \"BaseAgent\" as a fallback, indicating that the configuration does not match any recognized specialized agent class and should be treated as a base type. This logic ensures that only recognized agent classes are returned, while unrecognized ones default to a generic base agent, and invalid input types are rejected outright.", "answer": "def agent_config_discriminator(v: Any) -> str: if isinstance(v, dict): agent_class: str = v.get(\"agent_class\", \"LlmAgent\") if agent_class in _ADK_AGENT_CLASSES: return agent_class return \"BaseAgent\" raise ValueError(f\"Invalid agent config: {v}\")"}
{"question": "This code defines an asynchronous method named `_run_async_impl` that belongs to a class. The method is designed to take a single parameter, `ctx`, which is expected to be an instance of `InvocationContext`. It is declared as returning an asynchronous generator that will yield objects of type `Event` and does not produce a final return value. The body of the method immediately raises a `NotImplementedError` exception, including in the error message the specific type of the current object to indicate which subclass has not provided its own implementation. This makes it clear that the method is intended to be overridden in subclasses and is not meant to be executed in its current form. The `yield` statement that follows is unreachable because the exception is raised beforehand, but its presence ensures that the function is recognized as an asynchronous generator by Python’s type system and runtime. This structure effectively defines an abstract asynchronous generator method that enforces implementation in derived classes while preserving the correct coroutine and generator semantics.", "answer": "async def _run_async_impl( self, ctx: InvocationContext ) -> AsyncGenerator[Event, None]: raise NotImplementedError( f'_run_async_impl for {type(self)} is not implemented.' ) yield"}
{"question": "This function is designed to locate and return the highest-level agent in a chain of linked agents. It begins by assuming that the current object itself is the root, storing it in a local variable. It then repeatedly checks whether this agent has a parent agent. If a parent exists, the function moves up one level by reassigning the local variable to reference that parent. This process continues in a loop until it reaches an agent that has no parent, meaning it is at the top of the hierarchy. Once the traversal reaches this topmost agent, the function returns it. In effect, it walks up the chain of parent relationships from the current agent to the ultimate ancestor in the structure.", "answer": "def root_agent(self) -> BaseAgent: root_agent = self while root_agent.parent_agent is not None: root_agent = root_agent.parent_agent return root_agent"}
{"question": "This function is designed to locate and return an agent object based on a given name. It accepts a string parameter representing the name to search for and returns either an instance of a `BaseAgent` or `None` if no matching agent is found. The method first checks whether the current object’s `name` attribute matches the provided name. If they are identical, it immediately returns the current object itself, indicating that the search target has been found at the top level. If the names do not match, the method delegates the search to another function called `find_sub_agent`, passing along the same name. This secondary function is presumably responsible for searching through subordinate or nested agents associated with the current object. The overall logic ensures that the search begins with the current agent and, if unsuccessful, continues into its hierarchy of sub-agents.", "answer": "def find_agent(self, name: str) -> Optional[BaseAgent]: if self.name == name: return self return self.find_sub_agent(name)"}
{"question": "This function is designed to produce a standardized list of callback objects that should be executed before an agent runs. It begins by checking whether the instance variable holding these callbacks is set at all; if it is missing or evaluates to a false value, the function returns an empty list, indicating that there are no callbacks to process. If the variable is present, the function then determines whether it is already a list. If it is, that list is returned directly, preserving its contents exactly as they were stored. If the variable contains a single callback object rather than a list, the function wraps that single object inside a new list so that the result is always in list form. This ensures that the output is consistently a list of callback objects, regardless of whether the original data was stored as one item or multiple items.", "answer": "def canonical_before_agent_callbacks(self) -> list[_SingleAgentCallback]: if not self.before_agent_callback: return [] if isinstance(self.before_agent_callback, list): return self.before_agent_callback return [self.before_agent_callback]"}
{"question": "This method is designed to establish a parent–child relationship between an agent object and a collection of its subordinate agents. It operates by iterating through the list of subordinate agents stored in the instance’s `sub_agents` attribute. For each subordinate agent encountered, it first checks whether that agent already has a parent assigned. If a parent is already present, the method halts execution by raising a `ValueError`, providing a detailed message that includes the subordinate agent’s name, the name of its current parent, and the name of the agent attempting to become the new parent. This prevents accidental reassignment of a subordinate agent to a different parent without explicit handling. If no parent is set, the method assigns the current agent instance as the subordinate’s parent by setting the subordinate’s `parent_agent` attribute to `self`. After processing all subordinate agents successfully, the method returns the current agent instance, allowing for method chaining or further operations on the same object.", "answer": "def __set_parent_agent_for_sub_agents(self) -> BaseAgent: for sub_agent in self.sub_agents: if sub_agent.parent_agent is not None: raise ValueError( f'Agent `{sub_agent.name}` already has a parent agent, current' f' parent: `{sub_agent.parent_agent.name}`, trying to add:' f' `{self.name}`' ) sub_agent.parent_agent = self return self"}
{"question": "This code defines a method named `_parse_config` that belongs to a class, indicated by the presence of `cls` as its first parameter. The method is intended to work with a specific type of class, `SelfAgent`, and it accepts four arguments. The first argument, `cls`, represents the class itself rather than an instance, which means this method is likely a class method even though the decorator is not shown here. The second argument, `config`, is expected to be an object of type `BaseAgentConfig`, which suggests it contains configuration data relevant to the agent. The third argument, `config_abs_path`, is a string that presumably holds the absolute file path to the configuration source. The fourth argument, `kwargs`, is a dictionary mapping string keys to values of any type, representing additional parameters or overrides that may be passed in. Despite the variety of inputs, the method’s implementation is minimal. It does not perform any processing, validation, or transformation of the provided configuration or path. Instead, it simply returns the `kwargs` dictionary exactly as it was received. This means that whatever extra keyword arguments are passed into the method become its direct output, without any modification. The presence of the other parameters suggests that in a more complete implementation, the method might merge these keyword arguments with values from the configuration object or file, but in its current form, it acts as a pass-through for the `kwargs` data.", "answer": "def _parse_config( cls: Type[SelfAgent], config: BaseAgentConfig, config_abs_path: str, kwargs: Dict[str, Any], ) -> Dict[str, Any]: return kwargs"}
{"question": "This asynchronous method is designed to retrieve a list of artifact identifiers associated with a particular application, user, and session. It begins by checking whether the artifact service within the current invocation context has been properly initialized. If this service is missing, it immediately stops execution by raising a ValueError, signaling that the operation cannot proceed without it. When the artifact service is available, the method calls its function for listing artifact keys, supplying it with three pieces of contextual information: the name of the application, the unique identifier of the user, and the identifier of the current session. This call is performed asynchronously, meaning the method will pause until the artifact service returns the results. Once the service responds, the method produces a list of strings, each representing an artifact key, and returns that list to the caller.", "answer": "async def list_artifacts(self) -> list[str]: if self._invocation_context.artifact_service is None: raise ValueError(\"Artifact service is not initialized.\") return await self._invocation_context.artifact_service.list_artifact_keys( app_name=self._invocation_context.app_name, user_id=self._invocation_context.user_id, session_id=self._invocation_context.session.id, )"}
{"question": "This asynchronous method is responsible for storing authentication credentials using a credential service that is expected to be available within the object’s invocation context. When the method is called, it first checks whether the credential service has been initialized. This is done by examining a property of the invocation context that should hold a reference to the credential service. If that reference is missing or set to None, the method immediately stops execution and raises a ValueError to indicate that the credential service is not ready for use. If the credential service is present, the method proceeds to call its asynchronous save operation, passing along the provided authentication configuration object as well as the current instance. The save operation is awaited, meaning the method will pause until the credential service finishes storing the credentials before continuing. This ensures that credential persistence is handled reliably and that any dependent operations occur only after the save process has completed.", "answer": "async def save_credential(self, auth_config: AuthConfig) -> None: if self._invocation_context.credential_service is None: raise ValueError(\"Credential service is not initialized.\") await self._invocation_context.credential_service.save_credential( auth_config, self )"}
{"question": "This asynchronous function is responsible for retrieving authentication credentials based on a provided configuration object. It expects to receive an `AuthConfig` instance, which contains the necessary parameters or settings for identifying and loading the correct credentials. The function first checks whether the current invocation context has an associated credential service available. This credential service is the component responsible for actually performing the credential lookup or retrieval. If the credential service is missing, the function immediately stops execution by raising a `ValueError`, signaling that the environment has not been properly set up to handle credential loading. If the credential service is present, the function delegates the task of loading the credentials to it, passing along both the provided authentication configuration and a reference to the current object instance. The credential service performs its work asynchronously, and the function waits for the result before returning it. The returned value will either be an `AuthCredential` object containing the loaded authentication details or `None` if no matching credentials are found.", "answer": "async def load_credential( self, auth_config: AuthConfig ) -> Optional[AuthCredential]: if self._invocation_context.credential_service is None: raise ValueError(\"Credential service is not initialized.\") return await self._invocation_context.credential_service.load_credential( auth_config, self )"}
{"question": "This function is designed to enforce a strict rule about the presence of two specific attributes, `code` and `config_path`, on the object it belongs to. It first determines whether each of these attributes has been set by checking if they are not `None`. These checks result in two Boolean values that indicate whether `code` is provided and whether `config_path` is provided. The function then evaluates these conditions to ensure that exactly one of the two attributes is present. If both attributes are set, it raises an error indicating that only one should be provided. If neither attribute is set, it raises an error stating that exactly one must be provided. When the validation passes—meaning one attribute is set and the other is not—the function returns the current object instance, allowing further operations to be performed on it. This logic ensures that the object is always in a valid state with respect to these two mutually exclusive configuration options.", "answer": "def validate_exactly_one_field(self) -> AgentRefConfig: code_provided = self.code is not None config_path_provided = self.config_path is not None if code_provided and config_path_provided: raise ValueError(\"Only one of `code` or `config_path` should be provided\") if not code_provided and not config_path_provided: raise ValueError(\"Exactly one of `code` or `config_path` must be provided\") return self"}
{"question": "This function is designed to take a string that represents the name of an agent class and return the actual Python class object corresponding to it, ensuring that the class meets certain requirements. It begins by checking whether the provided string is empty or missing; if so, it defaults to using the name \"LlmAgent\". Next, it determines whether the given name is already in a fully qualified form, meaning it contains a dot to indicate a module path. If the name is not fully qualified, it automatically prepends a standard module path prefix, specifically \"google.adk.agents.\", to construct the complete reference to the class. Once the fully qualified name is determined, the function uses a helper routine called `resolve_fully_qualified_name` to dynamically locate and load the actual class object from that name. After retrieving the object, it verifies that the result is indeed a class and that it inherits from the `BaseAgent` class, ensuring it conforms to the expected type hierarchy. If both conditions are satisfied, the function returns the class object for further use. If the resolved object is not a class or does not derive from `BaseAgent`, the function raises a `ValueError` with a clear message indicating that the provided name is invalid and must refer to a subclass of `BaseAgent`. This logic ensures that only valid agent classes from the expected namespace or a fully qualified path are accepted, and it provides a default fallback when no specific class name is given.", "answer": "def _resolve_agent_class(agent_class: str) -> type[BaseAgent]: agent_class_name = agent_class or \"LlmAgent\" if \".\" not in agent_class_name: agent_class_name = f\"google.adk.agents.{agent_class_name}\" agent_class = resolve_fully_qualified_name(agent_class_name) if inspect.isclass(agent_class) and issubclass(agent_class, BaseAgent): return agent_class raise ValueError( f\"Invalid agent class `{agent_class_name}`. It must be a subclass of BaseAgent.\" )"}
{"question": "This function is designed to read and interpret a configuration file from a specified location on the filesystem, then convert that data into a structured configuration object. It begins by checking whether the file exists at the given path. If the file is missing, it immediately stops execution and signals an error by raising a `FileNotFoundError`, including the path in the error message so the caller knows exactly which file could not be found. If the file is present, it opens the file in read mode using UTF-8 encoding to ensure proper handling of text content. The contents of the file are then read and parsed using a YAML parser that safely loads the data into a Python data structure, such as dictionaries and lists, without executing any potentially unsafe code. Once the raw configuration data is available in memory, the function passes it to a validation method on the `AgentConfig` class, which likely checks that the data matches the expected schema and converts it into an `AgentConfig` instance. The resulting validated configuration object is then returned to the caller for use elsewhere in the program.", "answer": "def _load_config_from_path(config_path: str) -> AgentConfig: if not os.path.exists(config_path): raise FileNotFoundError(f\"Config file not found: {config_path}\") with open(config_path, \"r\", encoding=\"utf-8\") as f: config_data = yaml.safe_load(f) return AgentConfig.model_validate(config_data)"}
{"question": "This function is designed to take a string that represents a fully qualified name of a Python object, meaning it includes both the module path and the object’s name separated by a dot. It first attempts to split the input string into two parts: everything before the last dot is treated as the module path, and the part after the last dot is treated as the name of the object within that module. Using the module path, it dynamically imports the corresponding module at runtime. Once the module is successfully imported, it looks up the specified object within that module by name and returns it. If any step in this process fails—such as if the string does not contain a valid module path and object name, the module cannot be imported, or the object does not exist in the module—the function catches the resulting exception and raises a new ValueError, indicating that the provided fully qualified name is invalid, while preserving the original exception as the underlying cause.", "answer": "def resolve_fully_qualified_name(name: str) -> Any: try: module_path, obj_name = name.rsplit(\".\", 1) module = importlib.import_module(module_path) return getattr(module, obj_name) except Exception as e: raise ValueError(f\"Invalid fully qualified name: {name}\") from e"}
{"question": "This function is designed to take a string that represents a reference to a Python object and return the corresponding object if it meets specific criteria. It begins by checking whether the provided string contains a dot character, which is required to separate the module path from the object name. If no dot is found, it immediately raises an error, indicating that the reference format is invalid. The function then splits the string into two parts: the portion before the last dot is treated as the module path, and the portion after the last dot is treated as the name of the object within that module. It dynamically imports the specified module using Python’s import system and retrieves the object with the given name from that module. Once the object is obtained, the function verifies that it is not callable, meaning it should not be a function, method, or any other callable entity. If it is callable, an error is raised to indicate that the reference points to an invalid type. Next, it checks whether the object is an instance of the `BaseAgent` class. If it is not, another error is raised to signal that the reference does not point to a valid agent instance. If all these checks pass, the function returns the object, ensuring that the result is a non-callable instance of `BaseAgent` that was located via a fully qualified module and object name.", "answer": "def _resolve_agent_code_reference(code: str) -> Any: if \".\" not in code: raise ValueError(f\"Invalid code reference: {code}\") module_path, obj_name = code.rsplit(\".\", 1) module = importlib.import_module(module_path) obj = getattr(module, obj_name) if callable(obj): raise ValueError(f\"Invalid agent reference to a callable: {code}\") if not isinstance(obj, BaseAgent): raise ValueError(f\"Invalid agent reference to a non-agent instance: {code}\") return obj"}
{"question": "This function is designed to dynamically locate and optionally execute a Python object based on configuration data provided through a `CodeConfig` instance. It begins by validating that the configuration object exists and contains a non-empty `name` attribute, which is expected to represent the fully qualified path to a Python object, including both its module and the object’s name. If this validation fails, it raises an error to signal that the configuration is unusable. Once validated, the function separates the module path from the object name by splitting the string at the last period. It then imports the specified module at runtime using Python’s import machinery. After the module is loaded, it retrieves the target object from the module by name. The function then checks whether the configuration includes arguments and whether the retrieved object is callable, meaning it can be invoked like a function or class constructor. If both conditions are met, it prepares two sets of arguments: keyword arguments built from configuration entries that have explicit names, and positional arguments taken from entries without names. These arguments are then passed to the callable object, and the result of that invocation is returned. If the object is not callable or no arguments are provided, the function simply returns the object itself without invoking it. This allows the configuration to reference either executable code or static values, depending on the intended use.", "answer": "def resolve_code_reference(code_config: CodeConfig) -> Any: if not code_config or not code_config.name: raise ValueError(\"Invalid CodeConfig.\") module_path, obj_name = code_config.name.rsplit(\".\", 1) module = importlib.import_module(module_path) obj = getattr(module, obj_name) if code_config.args and callable(obj): kwargs = {arg.name: arg.value for arg in code_config.args if arg.name} positional_args = [arg.value for arg in code_config.args if not arg.name] return obj(*positional_args, **kwargs) else: return obj"}
{"question": "This function is responsible for tracking how many times a certain process, specifically one involving calls to a large language model (LLM), has been executed, and for enforcing a limit on those calls if such a limit is configured. Each time the function is invoked, it increases an internal counter that keeps track of the total number of LLM calls made so far. After incrementing the counter, it checks whether a run configuration object has been provided and whether that configuration specifies a positive maximum number of allowed LLM calls. If both conditions are true, it then compares the updated counter against the configured maximum. If the counter has exceeded the allowed limit, the function interrupts execution by raising a specific exception that signals the limit has been breached, including in the error message the maximum number that was permitted. This ensures that the system can prevent excessive LLM usage according to predefined constraints.", "answer": "def increment_and_enforce_llm_calls_limit( self, run_config: Optional[RunConfig] ): self._number_of_llm_calls += 1 if ( run_config and run_config.max_llm_calls > 0 and self._number_of_llm_calls > run_config.max_llm_calls ): raise LlmCallsLimitExceededError( \"Max number of llm calls limit of\" f\" `{run_config.max_llm_calls}` exceeded\" )"}
{"question": "This function determines whether an ongoing process should be paused based on certain conditions related to the event it receives. It begins by checking whether the current object is in a state that allows resuming later; if it is not resumable, the function immediately decides that pausing is unnecessary and returns false. Next, it examines the event to see if there is a list of identifiers for tools that are considered long-running and whether the event contains any recorded function calls. If either of these is missing or empty, the function again concludes that pausing is not needed. If both are present, it iterates through each function call associated with the event and checks whether the identifier of that function call matches any of the long-running tool identifiers. If a match is found, this indicates that a long-running tool is currently in use, and the function decides that the process should be paused, returning true. If no matches are found after checking all function calls, it returns false, meaning there is no reason to pause.", "answer": "def should_pause_invocation(self, event: Event) -> bool: if not self.is_resumable: return False if not event.long_running_tool_ids or not event.get_function_calls(): return False for fc in event.get_function_calls(): if fc.id in event.long_running_tool_ids: return True return False"}
{"question": "This piece of code defines a method whose purpose is to locate a previously recorded event that corresponds to a specific function call, based on information contained in a given function response event. The method begins by retrieving all function responses from the provided event object. If there are no function responses present, it immediately concludes that there is nothing to match and returns no result. When function responses do exist, it takes the identifier from the first one, assuming that this identifier uniquely represents the function call that produced the response. Next, it obtains a list of events from the current invocation context. These events are ordered chronologically, with the most recent one at the end. The method then iterates backward through all but the last event in this list, effectively searching from the most recent past event toward older ones. For each event examined, it checks whether any of its recorded function calls share the same identifier as the one extracted from the function response. If such a match is found, that event is returned immediately as the corresponding function call event. If the search completes without finding a match, the method returns no result, indicating that there is no earlier event in the current invocation that corresponds to the given function response. This logic ensures that the method links a function response back to the original function call that triggered it, if such a link exists.", "answer": "def _find_matching_function_call( self, function_response_event: Event ) -> Optional[Event]: function_responses = function_response_event.get_function_responses() if not function_responses: return None function_call_id = function_responses[0].id events = self._get_events(current_invocation=True) for event in reversed(events[:-1]): if any(fc.id == function_call_id for fc in event.get_function_calls()): return event return None"}
{"question": "This function is designed to extract the most recent consecutive messages authored by a human user from a sequence of event objects. It begins by initializing an empty list to hold the resulting human messages. The function then iterates over the provided events in reverse order, starting from the most recent and moving backward in time. While traversing, it checks whether any messages have already been collected; if so, and the current event is not authored by the user, the loop stops, ensuring that only the latest contiguous block of user messages is captured. For each event authored by the user, it verifies that the event contains content and that the content has parts. If these conditions are met, it takes the text from the first part of the content and wraps it in a HumanMessage object, adding it to the collection. After the loop finishes, the collected messages are reversed so that they are returned in chronological order, from oldest to newest within that contiguous block of recent user messages.", "answer": "def _get_last_human_messages(events: list[Event]) -> list[HumanMessage]: messages = [] for event in reversed(events): if messages and event.author != 'user': break if event.author == 'user' and event.content and event.content.parts: messages.append(HumanMessage(content=event.content.parts[0].text)) return list(reversed(messages))"}
{"question": "This function is designed to produce a list of message objects based on a sequence of event data. It accepts a list of `Event` instances and returns a list containing either `HumanMessage` or `AIMessage` objects. The function first checks whether the `graph` object associated with the current instance has a `checkpointer` configured. If a checkpointer is present, it delegates the work to a helper function named `_get_last_human_messages`, which presumably extracts the most recent messages from a human participant based on the provided events. If no checkpointer is available, the function instead calls another method on the current instance, `_get_conversation_with_agent`, which likely reconstructs or retrieves the conversation history between a human and an AI agent from the given events. The choice between these two paths allows the function to adapt its behavior depending on whether the system is maintaining a checkpointed state or needs to rebuild the conversation from scratch.", "answer": "def _get_messages( self, events: list[Event] ) -> list[Union[HumanMessage, AIMessage]]: if self.graph.checkpointer: return _get_last_human_messages(events) else: return self._get_conversation_with_agent(events)"}
{"question": "This function is designed to take a sequence of event objects and transform them into a structured list of message objects representing a conversation between a human user and an AI agent. It begins by initializing an empty list to hold the resulting messages. It then iterates through each event in the provided list. For each event, it first checks whether the event contains any content and whether that content has parts; if either is missing, the event is skipped entirely. If the event was authored by a user, the function creates a new human message using the text from the first part of the event’s content and adds it to the list. If the event was authored by the AI agent itself—identified by matching the event’s author name to the agent’s own name—it creates an AI message in the same way, using the text from the first content part. After processing all events, the function returns the list of messages, which now represents the conversation in a structured form, alternating between human and AI messages depending on the source of each event.", "answer": "def _get_conversation_with_agent( self, events: list[Event] ) -> list[Union[HumanMessage, AIMessage]]: messages = [] for event in events: if not event.content or not event.content.parts: continue if event.author == 'user': messages.append(HumanMessage(content=event.content.parts[0].text)) elif event.author == self.name: messages.append(AIMessage(content=event.content.parts[0].text)) return messages"}
{"question": "This code defines the initialization behavior for an object when it is created. During construction, it first checks whether there is already an active asyncio event loop running in the current thread. It does this by attempting to retrieve the running loop. If no loop is currently active, that attempt raises a runtime error, which is caught. In that case, a new event loop is created and explicitly set as the current loop for the thread, ensuring that asynchronous operations can be scheduled and executed. After ensuring that an event loop is available, the code creates an asynchronous queue associated with that loop and stores it in an instance variable. This queue will be used later to hold and manage items in a way that integrates with asyncio’s non-blocking, coroutine-based execution model.", "answer": "def __init__(self): try: asyncio.get_running_loop() except RuntimeError: loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) self._queue = asyncio.Queue()"}
{"question": "This function is designed to determine and return a standardized language model instance associated with the current object. It first checks whether the object’s `model` attribute is already an instance of the expected base language model class. If so, it simply returns that instance directly. If the `model` attribute is not an object but contains a non-empty string, it treats that string as a model identifier and uses a registry mechanism to create a new language model instance from it. If neither of those conditions is met, meaning the current object does not have a usable model defined, the function attempts to locate one by traversing upward through a chain of related agents via the `parent_agent` attribute. It moves from the current object’s parent to its parent’s parent, and so on, until it finds an ancestor that is recognized as a language model–capable agent. When such an ancestor is found, it returns that ancestor’s canonical model. If the search reaches the top of the chain without finding any suitable model, the function raises an error indicating that no model could be found for the current object, including the object’s name in the error message to aid in debugging. This approach ensures that the function either returns a valid language model instance or fails explicitly when none is available, while also supporting inheritance of models from parent agents.", "answer": "def canonical_model(self) -> BaseLlm: if isinstance(self.model, BaseLlm): return self.model elif self.model: # model is non-empty str return LLMRegistry.new_llm(self.model) else: ancestor_agent = self.parent_agent while ancestor_agent is not None: if isinstance(ancestor_agent, LlmAgent): return ancestor_agent.canonical_model ancestor_agent = ancestor_agent.parent_agent raise ValueError(f'No model found for {self.name}.')"}
{"question": "This asynchronous function is designed to produce a standardized list of tool objects from a collection of tool definitions that may be expressed in different forms. It begins by preparing an empty list to hold the final resolved tools. It then determines whether the current object contains more than one tool, storing that as a Boolean value for later use. The function iterates over each entry in the collection of tools, where each entry may represent a single tool or a union of multiple possible tools. For each entry, it calls another asynchronous helper function that takes the tool definition, the provided context, the model associated with the current object, and the information about whether multiple tools are present. This helper function returns a list of fully converted tool objects, which are then added to the accumulating list of resolved tools. After processing all entries, the function returns the complete list of standardized tool instances, ensuring that any variations in the original definitions have been normalized into a consistent format.", "answer": "async def canonical_tools( self, ctx: ReadonlyContext = None ) -> list[BaseTool]: resolved_tools = [] multiple_tools = len(self.tools) > 1 for tool_union in self.tools: resolved_tools.extend( await _convert_tool_union_to_tools( tool_union, ctx, self.model, multiple_tools ) ) return resolved_tools"}
{"question": "This function is designed to produce a standardized list of callback objects that should be executed before a model-related operation. It checks an attribute named `before_model_callback` on the current object and ensures that the return value is always in list form, even if the original attribute is not. The method first determines whether the attribute is set at all; if it is missing or evaluates to a false value, it returns an empty list, indicating that there are no callbacks to run. If the attribute is already a list, it simply returns that list unchanged, preserving any callbacks already defined. If the attribute contains a single callback object rather than a list, the method wraps that single object inside a new list so that the result is consistently a list of callbacks. This approach guarantees that any code using the result can rely on a uniform list structure, simplifying subsequent processing of these callbacks.", "answer": "def canonical_before_model_callbacks( self, ) -> list[_SingleBeforeModelCallback]: if not self.before_model_callback: return [] if isinstance(self.before_model_callback, list): return self.before_model_callback return [self.before_model_callback]"}
{"question": "This function is designed to produce a standardized list of callback objects that should be executed after a certain model-related operation. It begins by checking whether the instance has any value assigned to its `after_model_callback` attribute. If that attribute is empty or evaluates to false, the function returns an empty list, indicating that there are no callbacks to run. If the attribute is present and is already a list, the function simply returns it as-is, preserving its contents and order. If the attribute contains a single callback object rather than a list, the function wraps that single object inside a new list so that the result is always a list of callbacks. This ensures that the output is consistently in list form, regardless of whether the original attribute was missing, a single callback, or a collection of callbacks.", "answer": "def canonical_after_model_callbacks(self) -> list[_SingleAfterModelCallback]: if not self.after_model_callback: return [] if isinstance(self.after_model_callback, list): return self.after_model_callback return [self.after_model_callback]"}
{"question": "This code defines a function whose purpose is to gather the names of agents in a hierarchical structure, starting from a given agent and including any nested agents beneath it. When the function is called with an agent object, it first adds that agent’s name to a shared list called `agents`. It then checks whether the agent has an attribute named `sub_agents` and whether that attribute contains any elements. If both conditions are true, it iterates through each of those sub-agents and calls the same function recursively on them. This recursive process ensures that the function traverses the entire tree of agents, moving deeper into each level until no further sub-agents are found. After initiating the process with the root agent stored in `self.root_agent`, the function ultimately returns the complete list of agent names collected from the root and all of its descendants.", "answer": "def collect_agents(agent): agents.append(agent.name) if hasattr(agent, 'sub_agents') and agent.sub_agents: for sub_agent in agent.sub_agents: collect_agents(sub_agent) collect_agents(self.root_agent) return agents"}
{"question": "This function is designed to take in a class type representing a `LoopAgent`, a configuration object of type `LoopAgentConfig`, the absolute path to that configuration file, and a dictionary of keyword arguments. It processes the provided configuration to potentially update the keyword arguments before returning them. The function checks whether the configuration object specifies a value for `max_iterations`. If such a value exists and is not null or zero, it adds or updates an entry in the keyword arguments dictionary with the key `'max_iterations'` and the value taken directly from the configuration. After performing this conditional update, the function returns the modified keyword arguments dictionary. This allows the calling code to pass along configuration-driven parameters to the `LoopAgent` without having to manually extract them from the configuration object.", "answer": "def _parse_config( cls: type[LoopAgent], config: LoopAgentConfig, config_abs_path: str, kwargs: Dict[str, Any], ) -> Dict[str, Any]: if config.max_iterations: kwargs['max_iterations'] = config.max_iterations return kwargs"}
{"question": "This function is designed to generate a new invocation context for a sub-agent that operates under a parent agent, while preserving the original context’s data and extending it with additional branch information. It begins by taking the provided invocation context and creating a copy of it, ensuring that any modifications made will not affect the original object. It then constructs a branch suffix string by combining the name of the parent agent with the name of the sub-agent, separated by a dot. This suffix represents a hierarchical relationship between the agents. The function then updates the branch attribute of the copied invocation context. If the branch attribute already contains a value, the new suffix is appended to it with a dot separator, effectively extending the branch path. If the branch attribute is empty or undefined, the branch is set directly to the new suffix. Finally, the updated invocation context, now containing the extended branch information, is returned for use in subsequent operations involving the sub-agent.", "answer": "def _create_branch_ctx_for_sub_agent( agent: BaseAgent, sub_agent: BaseAgent, invocation_context: InvocationContext, ) -> InvocationContext: invocation_context = invocation_context.model_copy() branch_suffix = f'{agent.name}.{sub_agent.name}' invocation_context.branch = ( f'{invocation_context.branch}.{branch_suffix}' if invocation_context.branch else branch_suffix ) return invocation_context"}
{"question": "This asynchronous function is designed to handle a continuous stream of events associated with a single agent. It receives an asynchronous iterable that produces events one at a time. For each event retrieved from this stream, the function creates a new synchronization signal using an asyncio event object. It then places both the event and its corresponding signal into a shared queue, making them available for other parts of the program to process. After placing the event in the queue, the function pauses and waits until the signal is triggered elsewhere, indicating that processing for that event has been completed and it is safe to continue. This cycle repeats for every event in the incoming stream. When the stream ends or if an error occurs, the function ensures that a special sentinel value is placed into the queue along with a null signal. This sentinel acts as a marker to indicate that no more events will be produced for this agent, allowing downstream consumers to detect completion and perform any necessary cleanup.", "answer": "async def process_an_agent(events_for_one_agent): try: async for event in events_for_one_agent: resume_signal = asyncio.Event() await queue.put((event, resume_signal)) await resume_signal.wait() finally: await queue.put((sentinel, None))"}
{"question": "This code defines a class named `ParallelAgentConfig` that inherits from `BaseAgentConfig`. It is intended to hold configuration settings specific to a type of agent referred to as a \"ParallelAgent.\" Within the class, there is a `model_config` attribute that is assigned a `ConfigDict` object configured with the option `extra=\"forbid\"`. This setting indicates that the configuration will reject any fields that are not explicitly defined, ensuring strict adherence to the declared schema. The class also declares an attribute named `agent_class`, which is a string field. This field has a default value of `\"ParallelAgent\"` and includes a descriptive note explaining that the value serves as a unique identifier for the ParallelAgent class. The use of `Field` suggests that this class is leveraging a data validation or modeling library, likely Pydantic, to enforce type constraints, provide defaults, and attach metadata. Overall, the class encapsulates configuration rules for a specific agent type, enforces strict schema validation, and includes a built-in identifier that can be used programmatically to distinguish this agent from others.", "answer": "class ParallelAgentConfig(BaseAgentConfig): model_config = ConfigDict( extra=\"forbid\", ) agent_class: str = Field( default=\"ParallelAgent\", description=\"The value is used to uniquely identify the ParallelAgent class.\", )"}
{"question": "This function is designed to check and enforce certain constraints on a numeric configuration value that represents the maximum number of calls allowed to a large language model. It takes an integer input and first compares it against the largest possible integer value supported by the system. If the input matches this maximum system value, the function immediately stops execution by raising an error, indicating that the maximum number of calls must be strictly less than that limit. If the input is zero or negative, the function does not block execution but instead issues a warning through the logging system. The warning explains that having a non-positive limit effectively removes any restriction on the number of calls that can be made during a run. It also cautions that this could lead to undesirable behavior, such as an endless back-and-forth between the model and the agent in certain scenarios. After performing these checks, the function returns the original value, allowing the calling code to proceed with it, whether or not a warning was issued. This design ensures that extreme or potentially problematic values are either rejected outright or flagged for attention, helping to prevent runaway processes or system misuse.", "answer": "def validate_max_llm_calls(cls, value: int) -> int: if value == sys.maxsize: raise ValueError(f'max_llm_calls should be less than {sys.maxsize}.') elif value <= 0: logger.warning( 'max_llm_calls is less than or equal to 0. This will result in' ' no enforcement on total number of llm calls that will be made for a' ' run. This may not be ideal, as this could result in a never' ' ending communication between the model and the agent in certain' ' cases.', ) return value"}
{"question": "This code defines a Python class named `SequentialAgentConfig` that inherits from a base configuration class called `BaseAgentConfig`. It is intended to hold configuration settings specific to a type of agent referred to as a \"SequentialAgent.\" Within the class, there is a `model_config` attribute that is assigned a `ConfigDict` object with its `extra` parameter set to `\"forbid\"`. This setting indicates that the configuration will reject any fields that are not explicitly defined, preventing accidental inclusion of unsupported or misspelled configuration keys. The class also declares a field named `agent_class`, which is a string with a default value of `\"SequentialAgent\"`. This field includes a description stating that its purpose is to uniquely identify the SequentialAgent class. The use of `Field` suggests that this configuration is built on top of a data validation and settings management library, likely Pydantic, which enforces type checking, default values, and metadata for configuration parameters. Overall, the class encapsulates strict configuration rules and a clear identifier for the agent type it represents.", "answer": "class SequentialAgentConfig(BaseAgentConfig): model_config = ConfigDict( extra=\"forbid\", ) agent_class: str = Field( default=\"SequentialAgent\", description=\"The value is used to uniquely identify the SequentialAgent class.\", )"}
{"question": "This code defines the initialization method for a class, which is executed when a new instance of that class is created. The method requires an object that conforms to the `BaseLlm` type, representing a language model that the class will use internally. It also accepts an optional string parameter intended to serve as a prompt template. If the caller provides a prompt template, that value is stored; if not, the method falls back to a predefined default template stored in the class under `_DEFAULT_PROMPT_TEMPLATE`. During initialization, the provided language model object is assigned to an internal variable for later use, and the chosen prompt template—either the one supplied by the caller or the default—is stored in another internal variable. This setup ensures that every instance of the class has both a language model to work with and a prompt template to guide its interactions with that model.", "answer": "def __init__( self, llm: BaseLlm, prompt_template: Optional[str] = None, ): self._llm = llm self._prompt_template = prompt_template or self._DEFAULT_PROMPT_TEMPLATE"}
{"question": "This function takes a list of `Event` objects and produces a single string that represents those events in a readable, prompt-friendly format. It begins by creating an empty list to hold pieces of formatted text. It then goes through each event in the provided list, checking first that the event has a `content` attribute and that this content contains one or more `parts`. For each part within the event’s content, it verifies that the part has some text. When text is present, it constructs a string that combines the event’s author with the text from that part, separated by a colon and a space. Each of these constructed strings is added to the list of formatted history entries. After all events and their parts have been processed, the function joins all the collected strings together into one continuous block of text, with each entry separated by a newline character. The resulting string is then returned, providing a consolidated textual representation of the events suitable for use in a prompt or display.", "answer": "def _format_events_for_prompt(self, events: list[Event]) -> str: formatted_history = [] for event in events: if event.content and event.content.parts: for part in event.content.parts: if part.text: formatted_history.append(f'{event.author}: {part.text}') return '\\n'.join(formatted_history)"}
{"question": "This function is designed to determine whether a given object, representing a part of some larger data structure, is referencing an artifact by a specific URI format. It accepts an input called `artifact`, which is expected to be an instance of `types.Part`. The function evaluates several conditions in sequence: first, it checks that the `artifact` has a `file_data` attribute that is not empty or null. Next, it verifies that this `file_data` object contains a `file_uri` value. Finally, it inspects the beginning of that `file_uri` string to see if it starts with the prefix `\"artifact://\"` — a convention that likely indicates the resource is an artifact reference rather than a regular file path or URL. All of these checks are combined into a single logical expression, and the result is converted into a boolean value. If every condition is met, the function returns `True`, signaling that the given part is indeed an artifact reference; otherwise, it returns `False`.", "answer": "def is_artifact_ref(artifact: types.Part) -> bool: return bool( artifact.file_data and artifact.file_data.file_uri and artifact.file_data.file_uri.startswith(\"artifact://\") )"}
{"question": "This function is designed to search through a directory tree starting from a given root path and collect specific directories that meet a certain condition. It begins by checking whether the provided root path actually exists in the filesystem; if it does not, the function immediately returns an empty list, indicating that there are no directories to process. If the root exists, it initializes an empty list to store the matching directories. It then uses a recursive directory traversal, walking through each folder and subfolder under the root. For each directory encountered, it converts the directory path into a Path object and checks whether a subdirectory named \"versions\" exists inside it. If such a subdirectory is found, the current directory is considered an artifact directory and is added to the results list. At that point, the list of subdirectories to explore from this location is cleared, which prevents the traversal from descending further into that branch of the directory tree. After the walk completes, the function returns the list of all directories that contained a \"versions\" subdirectory.", "answer": "def _iter_artifact_dirs(root: Path) -> list[Path]: if not root.exists(): return [] artifact_dirs: list[Path] = [] for dirpath, dirnames, _ in os.walk(root): current = Path(dirpath) if (current / \"versions\").exists(): artifact_dirs.append(current) dirnames.clear() return artifact_dirs"}
{"question": "This function is designed to process a filename string and remove a specific prefix if that prefix indicates a “user namespace.” It begins by checking whether the given filename contains this special namespace marker, using another function that determines if the filename meets that condition. If the check confirms that the filename starts with the predefined user namespace prefix, the function creates a new string by slicing off the prefix from the beginning of the filename. The length of the prefix is determined by a constant that stores the exact text of the namespace marker, and the slicing operation returns only the remaining portion of the filename after that prefix. If the filename does not have the user namespace, the function simply returns the original filename unchanged. This ensures that any filenames with the namespace are normalized by removing the marker, while others are left intact.", "answer": "def _strip_user_namespace(filename: str) -> str: if _file_has_user_namespace(filename): return filename[len(_USER_NAMESPACE_PREFIX):] return filename"}
{"question": "This function is designed to take a string representing a filesystem path and ensure that it is converted into a POSIX-style path format. It accepts a single string argument that may contain either Windows-style backslashes or already use POSIX-style forward slashes. The function first checks whether the input string contains any backslash characters, which are typical in Windows paths. If backslashes are found, it interprets the string as a Windows path by creating a `PureWindowsPath` object from it, then converts that representation into a POSIX-style string using the `as_posix()` method, which replaces backslashes with forward slashes. After this conversion, or if the original string already used forward slashes, the function constructs and returns a `PurePosixPath` object from the resulting string. The returned object represents the path in a platform-independent POSIX format, suitable for systems and code that expect forward slashes as directory separators.", "answer": "def _to_posix_path(path_value: str) -> PurePosixPath: if \"\\\\\" in path_value: path_value = PureWindowsPath(path_value).as_posix() return PurePosixPath(path_value)"}
{"question": "This code defines a class named `FileArtifactVersion` that extends the functionality of an existing class called `ArtifactVersion`. It is structured to work with a data modeling framework that uses configuration objects and field definitions, likely something similar to Pydantic. Within the class, a configuration object named `model_config` is set up using `ConfigDict`. This configuration specifies that an alias generator function, `alias_generators.to_camel`, should be used to automatically convert field names into camel case when creating aliases, and that fields can be populated using their original names as well as their aliases. The class introduces a single data attribute called `file_name`, which is explicitly typed as a string. This attribute is defined using a `Field` construct that allows additional metadata to be attached. In this case, the metadata includes a description stating that the value represents the original filename provided by the caller. This suggests that the class is intended to represent a versioned artifact that is specifically associated with a file, and that it stores the original name of that file for reference or processing purposes. The combination of inheritance from `ArtifactVersion`, the configuration for alias handling, and the descriptive field definition indicates that this class is part of a structured data model designed for serialization, validation, and possibly API communication.", "answer": "class FileArtifactVersion(ArtifactVersion): model_config = ConfigDict( alias_generator=alias_generators.to_camel, populate_by_name=True, ) file_name: str = Field( description=\"Original filename supplied by the caller.\" )"}
{"question": "This function is designed to determine and return the appropriate filesystem path where certain artifacts should be stored, based on the scope of those artifacts. It takes in the application name, a user identifier, an optional session identifier, and a filename. The first step is to compute a base directory path that is specific to the given application and user by calling another method that handles that logic. Once the base path is established, the function checks whether the artifact in question should be stored in a user-scoped location by using a helper function that examines the session identifier and filename. If the artifact is determined to be user-scoped, the function returns a path pointing to the directory intended for user-level artifacts within the base path. If the artifact is not user-scoped, the function then verifies that a session identifier has been provided, since session-scoped artifacts require this information. If no session identifier is present, it raises an error indicating that the session ID is mandatory for this type of artifact. When a valid session identifier is available, the function returns a path pointing to the directory intended for session-level artifacts within the base path, using another helper function to construct that location. This logic ensures that artifacts are stored in the correct directory structure depending on whether they are tied to a user or to a specific session.", "answer": "def _scope_root( self, app_name: str, user_id: str, session_id: Optional[str], filename: str, ) -> Path: base = self._base_root(app_name, user_id) if _is_user_scoped(session_id, filename): return _user_artifacts_dir(base) if not session_id: raise ValueError( \"Session ID must be provided for session-scoped artifacts.\" ) return _session_artifacts_dir(base, session_id)"}
{"question": "This function is designed to retrieve the most recent metadata for a stored artifact located in a given directory. It begins by determining all available versions of the artifact that are present on disk within the specified directory. This is done by calling a helper routine that inspects the directory and returns a list of version identifiers. If no versions are found, the function concludes that there is no metadata to return and immediately yields a null result. When versions are present, it assumes that the list is ordered in such a way that the last entry represents the latest version. It then constructs the path to the metadata file associated with that most recent version using another helper routine. Finally, it reads and returns the metadata content from that file, providing the caller with the information corresponding to the newest artifact version.", "answer": "def _latest_metadata(self, artifact_dir: Path) -> Optional[FileArtifactVersion]: versions = _list_versions_on_disk(artifact_dir) if not versions: return None return _read_metadata(_metadata_path(artifact_dir, versions[-1]))"}
{"question": "This code defines an asynchronous method that is intended to retrieve a list of artifact keys associated with a particular application and user, with an optional session identifier. The method accepts three parameters: the name of the application, the user’s unique identifier, and optionally a session ID if the retrieval should be scoped to a specific session. Rather than performing the retrieval directly in asynchronous code, it delegates the work to a synchronous helper method named `_list_artifact_keys_sync`. To ensure that this synchronous operation does not block the event loop, the method uses `asyncio.to_thread` to run the synchronous function in a separate thread. This allows the asynchronous method to integrate smoothly into an async workflow while offloading potentially blocking operations to a background thread. Once the synchronous function completes, its result—a list of strings representing artifact keys—is returned to the caller.", "answer": "async def list_artifact_keys( self, *, app_name: str, user_id: str, session_id: Optional[str] = None, ) -> list[str]: return await asyncio.to_thread( self._list_artifact_keys_sync, app_name, user_id, session_id, )"}
{"question": "This function is designed to remove a stored artifact from the system in a synchronous manner. It takes in the name of the application, the identifier of the user, the name of the file associated with the artifact, and optionally a session identifier. Using these inputs, it calls an internal method to determine the exact directory location where the artifact is stored. Once the directory path is obtained, the function checks whether that directory actually exists on the filesystem. If it does, the function proceeds to delete the entire directory and all of its contents using a recursive removal operation. After successfully removing the directory, it records a debug-level log entry indicating that the artifact with the given filename has been deleted, along with the location from which it was removed. This ensures both the cleanup of the artifact’s data and the availability of a trace in the logs for diagnostic or auditing purposes.", "answer": "def _delete_artifact_sync( self, app_name: str, user_id: str, filename: str, session_id: Optional[str], ) -> None: artifact_dir = self._artifact_dir( app_name=app_name, user_id=user_id, session_id=session_id, filename=filename, ) if artifact_dir.exists(): shutil.rmtree(artifact_dir) logger.debug(\"Deleted artifact %s at %s\", filename, artifact_dir)"}
{"question": "This function is designed to read and interpret metadata stored in a file at a given filesystem path. It begins by checking whether the specified path actually exists; if the file is missing, it immediately returns a null value to indicate that no metadata could be retrieved. If the file is present, the function attempts to open it and read its contents as text using UTF-8 encoding. The text is then passed to a method that validates and converts the JSON data into a structured `FileArtifactVersion` object. If the JSON data fails to meet the expected schema or structure, a validation error is raised. In that case, the function logs a warning message containing the file path and the error details, and returns a null value instead of a parsed object. Similarly, if the file contains invalid JSON that cannot be parsed at all, a value error is caught, a warning is logged with relevant information, and the function returns null. Overall, the function ensures that metadata is only returned when the file exists and contains valid, correctly structured JSON. Any issues—whether due to missing files, schema mismatches, or malformed JSON—are handled gracefully by logging warnings and returning a null result rather than allowing the program to fail.", "answer": "def _read_metadata(path: Path) -> Optional[FileArtifactVersion]: if not path.exists(): return None try: return FileArtifactVersion.model_validate_json( path.read_text(encoding=\"utf-8\") ) except ValidationError as exc: logger.warning(\"Failed to parse metadata at %s: %s\", path, exc) return None except ValueError as exc: logger.warning(\"Invalid metadata JSON at %s: %s\", path, exc) return None"}
{"question": "This code defines a constructor method for a class, which is executed when a new instance of that class is created. It requires a bucket name to be provided as a string and can also accept any number of additional keyword arguments. When the constructor runs, it first stores the provided bucket name in an instance variable so that it can be accessed later by other methods in the class. It then creates a new client object for interacting with a storage service, passing along any extra keyword arguments to configure that client. Using this client, it retrieves a reference to the specific storage bucket identified by the given name and stores that reference in another instance variable. This setup allows the class instance to have a ready-to-use connection to the designated bucket in the storage system, enabling further operations such as reading, writing, or managing data within that bucket.", "answer": "def __init__(self, bucket_name: str, **kwargs): self.bucket_name = bucket_name self.storage_client = storage.Client(**kwargs) self.bucket = self.storage_client.bucket(self.bucket_name)"}
{"question": "This code defines an asynchronous method that is intended to retrieve a list of artifact keys associated with a particular application and user, with an optional session identifier. The method accepts three parameters: the name of the application, the identifier for the user, and optionally a session identifier if the retrieval should be scoped to a specific session. Rather than performing the retrieval directly in the asynchronous event loop, it delegates the work to a synchronous helper method named `_list_artifact_keys`. This delegation is done using `asyncio.to_thread`, which runs the synchronous method in a separate thread so that it does not block the main event loop. The asynchronous method then awaits the completion of that threaded execution, ensuring that the caller receives the result once the background work is finished. The final returned value is a list of strings, each representing an artifact key that matches the given parameters. This approach allows synchronous code to be integrated into an asynchronous workflow without degrading performance or responsiveness.", "answer": "async def list_artifact_keys( self, *, app_name: str, user_id: str, session_id: Optional[str] = None ) -> list[str]: return await asyncio.to_thread( self._list_artifact_keys, app_name, user_id, session_id, )"}
{"question": "This asynchronous function is designed to remove a stored artifact associated with a particular application, user, and file. It requires the name of the application, the identifier of the user, and the filename of the artifact to be deleted. Optionally, a session identifier can also be provided to further narrow down the artifact’s location. The function begins by constructing the full internal path or key for the artifact using a helper method that combines these input parameters into a unique reference. It then checks whether an artifact exists at that computed path within the internal artifacts collection. If no artifact is found, the function exits without performing any further action. If an artifact is present, it removes the corresponding entry from the artifacts collection, effectively deleting it from the system’s in-memory storage. The function does not return any value, and its purpose is solely to ensure that the specified artifact is no longer stored.", "answer": "async def delete_artifact( self, *, app_name: str, user_id: str, filename: str, session_id: Optional[str] = None, ) -> None: path = self._artifact_path(app_name, user_id, filename, session_id) if not self.artifacts.get(path): return None self.artifacts.pop(path, None)"}
{"question": "This asynchronous function is designed to retrieve an authentication credential based on the current execution context and a provided authentication configuration. It accepts two inputs: an object containing authentication-related settings, and another object representing contextual information for the current callback or operation. The function first determines which internal storage bucket should be used for the current context by invoking a helper method that maps the given callback context to the appropriate bucket. Once the correct bucket is identified, it attempts to look up and return the credential associated with the key specified in the authentication configuration. If the key is not found in the bucket, the function will return a null-like value indicating that no credential is available. The use of asynchronous definition suggests that this operation may be part of a larger workflow that supports non-blocking execution, even though the retrieval itself appears to be a straightforward lookup.", "answer": "async def load_credential( self, auth_config: AuthConfig, callback_context: CallbackContext, ) -> Optional[AuthCredential]: credential_bucket = self._get_bucket_for_current_context(callback_context) return credential_bucket.get(auth_config.credential_key)"}
{"question": "This asynchronous function is designed to store authentication credentials in a context-specific location. It takes two inputs: an object containing authentication configuration details and another object representing the current callback context. The function first determines the appropriate storage container, referred to as a “credential bucket,” by invoking an internal method that uses the provided callback context to identify the correct bucket for the current execution environment. Once the correct bucket is obtained, the function uses a key from the authentication configuration to index into that bucket and assigns to it the corresponding exchanged authentication credential from the same configuration object. This effectively saves the credential in a way that is scoped to the current context, ensuring that it can be retrieved later using the same key within that context’s bucket.", "answer": "async def save_credential( self, auth_config: AuthConfig, callback_context: CallbackContext, ) -> None: credential_bucket = self._get_bucket_for_current_context(callback_context) credential_bucket[auth_config.credential_key] = ( auth_config.exchanged_auth_credential )"}
{"question": "This function is designed to retrieve a specific portion of a credentials data structure that corresponds to the current execution context, which is determined by the application name and the user identifier provided through the callback context. It begins by extracting the application name and user ID from the invocation context contained within the callback context object. These two values act as keys for organizing and accessing stored credentials. The method then checks whether the credentials store already has an entry for the given application name. If it does not, it creates an empty dictionary for that application within the credentials structure. Next, it verifies whether there is an entry for the specific user ID under that application. If no such entry exists, it initializes another empty dictionary for that user. By performing these checks and initializations, the function ensures that the credentials data structure always contains a nested dictionary for the given application and user combination. Finally, it returns the innermost dictionary associated with that user under the specified application, which serves as the \"bucket\" for storing or retrieving credentials relevant to the current context.", "answer": "def _get_bucket_for_current_context( self, callback_context: CallbackContext ) -> str: app_name = callback_context._invocation_context.app_name user_id = callback_context._invocation_context.user_id if app_name not in self._credentials: self._credentials[app_name] = {} if user_id not in self._credentials[app_name]: self._credentials[app_name][user_id] = {} return self._credentials[app_name][user_id]"}
{"question": "This function is designed to associate a specific type of authentication credential with an object that knows how to handle or exchange that credential. It takes two inputs: one representing the category or type of credential, and another representing an instance of a class that implements the logic for processing or exchanging that credential type. Inside the function, it stores this pairing in an internal data structure, which is a dictionary maintained by the object. The credential type is used as the key, and the exchanger instance is stored as the corresponding value. This effectively registers the exchanger so that later, when the system needs to work with a credential of that type, it can look up the appropriate handler from the dictionary and use it. The method does not return anything, as its purpose is to update the internal mapping with the new association.", "answer": "def register( self, credential_type: AuthCredentialTypes, exchanger_instance: BaseCredentialExchanger, ) -> None: self._exchangers[credential_type] = exchanger_instance"}
{"question": "This piece of code defines a method named `get_exchanger` that belongs to a class, indicated by the presence of `self` as its first parameter. The method is designed to retrieve a specific object responsible for handling credential exchanges, based on the type of credential provided. It accepts a single argument called `credential_type`, which is expected to be a value from the `AuthCredentialTypes` enumeration or type. The method then looks up this credential type in an internal data structure named `_exchangers`, which is likely a dictionary maintained by the class instance. The lookup uses the credential type as the key, and if a matching entry exists, the corresponding `BaseCredentialExchanger` object is returned. If no matching entry is found, the dictionary’s `get` method will return `None`, which aligns with the method’s declared return type of either a `BaseCredentialExchanger` or `None`. This allows the caller to request the appropriate exchanger for a given credential type and handle the case where no exchanger is available.", "answer": "def get_exchanger( self, credential_type: AuthCredentialTypes ) -> Optional[BaseCredentialExchanger]: return self._exchangers.get(credential_type)"}
{"question": "This function is designed to process an authentication URI string and ensure it is in a normalized form before being used elsewhere. It accepts a single argument, which may either be a string containing the URI or a `None` value. The function first checks whether the provided value is not empty or `None` and then examines whether the string ends with a hash character (`#`). If both conditions are met, it returns a modified version of the string with the trailing hash character removed. This effectively strips off an unnecessary or extraneous `#` from the end of the URI, which might otherwise cause inconsistencies or errors when the URI is used. If the input does not meet these conditions, the function does not explicitly return anything, which means it will implicitly return `None`. The overall purpose is to clean up the URI format so that it conforms to expected standards before further processing.", "answer": "def _normalize_auth_uri(self, auth_uri: str | None) -> str | None: if auth_uri and auth_uri.endswith(\"#\"): return auth_uri[:-1]"}
{"question": "This function is designed to determine the specific OAuth grant type based on the properties of an `OAuthFlows` object that is passed in as its argument. It examines the given `flow` instance in a sequence of conditional checks, each one looking for the presence of a particular grant type configuration. The first check looks for a client credentials flow, and if that is found, it immediately returns the corresponding `OAuthGrantType.CLIENT_CREDENTIALS` value. If that is not present, it proceeds to check for an authorization code flow, returning `OAuthGrantType.AUTHORIZATION_CODE` if found. Next, it checks for an implicit flow and returns `OAuthGrantType.IMPLICIT` when applicable. After that, it checks for a password flow and returns `OAuthGrantType.PASSWORD` if it exists. If none of these specific flow types are detected in the provided `flow` object, the function concludes by returning `None`, indicating that no recognized grant type is configured. The logic ensures that only the first matching grant type in the defined order is returned, and the evaluation stops as soon as a match is found.", "answer": "def from_flow(flow: OAuthFlows) -> \"OAuthGrantType\": if flow.clientCredentials: return OAuthGrantType.CLIENT_CREDENTIALS if flow.authorizationCode: return OAuthGrantType.AUTHORIZATION_CODE if flow.implicit: return OAuthGrantType.IMPLICIT if flow.password: return OAuthGrantType.PASSWORD return None"}
{"question": "This asynchronous function is designed to retrieve authentication credentials from a credential service if one is available in the provided execution context. It accepts a `callback_context` object, which contains information about the current invocation, including a reference to a credential service. The function first accesses the credential service from the invocation context inside the callback context. If a credential service exists, it proceeds to request credentials by calling an asynchronous method on the callback context, passing in the stored authentication configuration for this instance. The result of that asynchronous call, which should be an `AuthCredential` object, is then returned. If no credential service is present in the context, the function returns `None`, indicating that credentials could not be loaded. This structure ensures that credential retrieval only occurs when the necessary service is available, and it integrates cleanly with asynchronous workflows.", "answer": "async def _load_from_credential_service( self, callback_context: CallbackContext ) -> Optional[AuthCredential]: credential_service = callback_context._invocation_context.credential_service if credential_service: return await callback_context.load_credential(self._auth_config) return None"}
{"question": "This asynchronous method is designed to retrieve authentication credentials based on a previously obtained authorization response. It takes a single argument, which is an instance of a `CallbackContext`. This context object acts as a container for data and operations related to an authentication flow. Inside the method, it calls a function on the provided context to obtain the authentication response, passing in the instance’s stored authentication configuration as a parameter. The configuration likely contains necessary details such as client identifiers, scopes, or endpoints that guide how the response should be processed. The method then returns whatever credential object is produced by that call, or `None` if no valid credentials are available. The use of `async` indicates that this method is intended to be part of an asynchronous workflow, allowing it to integrate smoothly with other non-blocking operations in the authentication process.", "answer": "async def _load_from_auth_response( self, callback_context: CallbackContext ) -> Optional[AuthCredential]: return callback_context.get_auth_response(self._auth_config)"}
{"question": "This code defines a data model class intended to represent metadata about an authorization server in an authentication or OAuth 2.0 context. The class inherits from a base model type, which likely provides features such as data validation, serialization, and type enforcement. It specifies several attributes that describe key endpoints and capabilities of the server. The issuer attribute holds a string identifying the entity that issues tokens, typically a URL. The authorization_endpoint attribute contains the URL where clients can initiate the authorization process. The token_endpoint attribute stores the URL used to exchange authorization grants for access tokens. There is an optional scopes_supported attribute, which, if present, is a list of strings indicating the scopes the server supports. Another optional attribute, registration_endpoint, can hold a URL where clients may register with the authorization server. By defining these fields with explicit types, the model ensures that any instance will conform to the expected structure and data types, making it suitable for use in systems that need to parse, validate, and work with authorization server configuration data.", "answer": "class AuthorizationServerMetadata(BaseModel): issuer: str authorization_endpoint: str token_endpoint: str scopes_supported: Optional[List[str]] = None registration_endpoint: Optional[str] = None"}
{"question": "This function is designed to read and interpret the specification for a test case from a given directory. It begins by determining the location of a file named \"spec.yaml\" within the directory provided as its argument. This file is expected to contain the structured definition of the test case in YAML format. The function opens the file in read mode using UTF-8 encoding to ensure proper handling of text data. It then uses a YAML parser to load the contents of the file into a Python dictionary, converting the YAML structure into native Python data types. Once the data is loaded, the function passes this dictionary to a validation method of the `TestSpec` class, which likely checks that the data matches the expected schema and constructs a corresponding `TestSpec` object. The resulting validated `TestSpec` instance is then returned, ready for use in executing or analyzing the test case.", "answer": "def load_test_case(test_case_dir: Path) -> TestSpec: spec_file = test_case_dir / \"spec.yaml\" with open(spec_file, \"r\", encoding=\"utf-8\") as f: data: dict[str, Any] = yaml.safe_load(f) return TestSpec.model_validate(data)"}
{"question": "This function is designed to retrieve a previously recorded session from a specific directory associated with a test case. It begins by constructing the expected location of the session file, which is assumed to be named “generated-session.yaml” and stored directly within the provided directory path. The function first checks whether this file actually exists; if it is missing, the function immediately returns a null value to indicate that no session data is available. If the file is present, the function opens it in read mode using UTF-8 encoding to ensure proper handling of text content. It then reads the file’s contents and uses a YAML parser to convert the textual representation into a Python data structure. After parsing, it verifies that the resulting data is not empty or invalid. If the parsed content is missing or evaluates to a false value, the function again returns a null result, signaling that there is no usable session information. The overall logic ensures that only valid, non-empty session data is returned, and it gracefully handles cases where the file is absent or contains no meaningful content. This makes it suitable for scenarios where test cases may or may not have an associated recorded session, avoiding errors from missing or malformed files.", "answer": "def load_recorded_session(test_case_dir: Path) -> Optional[Session]: session_file = test_case_dir / \"generated-session.yaml\" if not session_file.exists(): return None with open(session_file, \"r\", encoding=\"utf-8\") as f: session_data = yaml.safe_load(f) if not session_data: return None"}
{"question": "This function is designed to produce a formatted text message that highlights a discrepancy between two values in a given context. It takes three pieces of information as input: a description of the context in which the mismatch occurred, the actual value that was observed, and the recorded value that was expected or stored previously. The function constructs a single string that begins with the context followed by the word “mismatch” and a dash, then places each value on its own line with clear labels. The actual value is shown first, preceded by the label “Actual:” and followed by a line break, and the recorded value is shown next, preceded by the label “Recorded:” and also separated by a line break. The resulting string is returned so it can be used elsewhere, such as in logs, error messages, or debugging output, to make it easy for someone reading the message to quickly see what was expected versus what was actually found.", "answer": "def _generate_mismatch_message( context: str, actual_value: str, recorded_value: str ) -> str: return ( f\"{context} mismatch - \\nActual: \\n{actual_value} \\nRecorded:\" f\" \\n{recorded_value}\" )"}
{"question": "This code defines a constructor method for a class, which is responsible for initializing certain attributes when a new instance of the class is created. It accepts two optional parameters: a base URL, which defaults to a local server address, and a timeout value, which defaults to thirty seconds. When the constructor runs, it stores the base URL after removing any trailing slash, ensuring a consistent format for later use. It also stores the timeout value exactly as provided. Additionally, it prepares an attribute intended to hold an asynchronous HTTP client object, but initially sets it to a null value, indicating that no client connection has been established yet. This setup allows the class to be configured with a specific server endpoint and request timeout, while deferring the creation of the actual HTTP client until it is needed.", "answer": "def __init__( self, base_url: str = \"http://127.0.0.1:8000\", timeout: float = 30.0 ): self.base_url = base_url.rstrip(\"/\") self.timeout = timeout self._client: Optional[httpx.AsyncClient] = None"}
{"question": "This asynchronous method is designed to provide access to an HTTP client instance that can be used for making network requests. It returns an asynchronous generator that yields an `httpx.AsyncClient` object. The method first checks whether an internal attribute holding the client instance has already been set. If it has not been initialized yet, it creates a new `AsyncClient` configured with a base URL and a timeout value, both of which are taken from the instance’s own attributes. Once the client is ready, the method yields it to the caller, allowing the caller to perform HTTP operations within an asynchronous context. The `try` block ensures that the yielding process is properly managed, and although the `finally` block does not currently perform any cleanup or resource release, it is in place to allow for such actions in the future if needed. This structure makes it possible to reuse the same client across multiple calls without recreating it each time, while still supporting asynchronous usage patterns.", "answer": "async def _get_client(self) -> AsyncGenerator[httpx.AsyncClient, None]: if self._client is None: self._client = httpx.AsyncClient( base_url=self.base_url, timeout=httpx.Timeout(self.timeout), ) try: yield self._client finally: pass"}
{"question": "This asynchronous method is designed to properly close and clean up an internal client resource managed by the object. When invoked, it first checks whether the instance currently holds a reference to a client object in its internal attribute. If such a client exists, the method awaits the completion of the client’s asynchronous close operation, ensuring that any underlying network connections or resources are released in a non-blocking manner. Once the close operation has finished, the method clears the reference to the client by setting the attribute to None, signaling that the client is no longer active or available for use. This approach helps prevent resource leaks and ensures that subsequent operations do not mistakenly interact with a closed client.", "answer": "async def close(self) -> None: if self._client: await self._client.aclose() self._client = None"}
{"question": "This function is designed to calculate and return the percentage of successful outcomes from a set of tests. It operates within a class context, using two attributes: one that stores the total number of tests conducted and another that stores the number of tests that passed. When the function is called, it first checks whether the total number of tests is zero. If no tests have been run, it immediately returns a value of 0.0 to indicate a zero percent success rate, avoiding any division by zero errors. If there are tests recorded, it computes the success rate by dividing the number of passed tests by the total number of tests, then multiplying the result by 100 to convert it into a percentage. The final value is returned as a floating-point number, representing the proportion of tests that passed relative to the total tests conducted.", "answer": "def success_rate(self) -> float: if self.total_tests == 0: return 0.0 return (self.passed_tests / self.total_tests) * 100"}
{"question": "This function is designed to display a formatted header message in the console when running a set of ADK conformance tests. It accepts a single argument, a string called `mode`, which indicates the mode in which the tests are being executed. When called, the function first outputs a horizontal separator line made up of fifty equal sign characters, creating a clear visual break in the console output. It then prints a message stating that the ADK conformance tests are being run, incorporating the provided mode value into the text so the user knows the specific configuration or environment being used. Finally, it prints another identical separator line to close off the header, making the message stand out and easy to identify among other console output. The printing is handled using the `click.echo` function from the Click library, which ensures consistent and reliable output formatting across different environments.", "answer": "def _print_test_header(mode: str) -> None: click.echo(\"=\" * 50) click.echo(f\"Running ADK conformance tests in {mode} mode...\") click.echo(\"=\" * 50)"}
{"question": "This function is designed to display the outcome of a test case in a clear, color-coded format for the user. It accepts a single argument representing the result of a test, which contains information about whether the test succeeded and, if applicable, an associated error message. The function first checks if the test was successful. If it was, it prints a check mark followed by the word “PASS” in green text to indicate success. If the test failed, it prints a cross mark followed by the word “FAIL” in red text to signal the failure. In the case of a failure, it also checks whether there is an error message included in the result. If such a message exists, it prints the message prefixed with the word “Error:” in red text, directing the output to the error stream so that it is distinguished from normal output. This approach provides immediate visual feedback to the user, making it easy to identify passing and failing tests and to see relevant error details when failures occur.", "answer": "def _print_test_case_result(result: _TestResult) -> None: if result.success: click.secho(\" ✓ PASS\", fg=\"green\") else: click.secho(\" ✗ FAIL\", fg=\"red\") if result.error_message: click.secho(f\"Error: {result.error_message}\", fg=\"red\", err=True)"}
{"question": "This code defines a constructor method for a class, which is responsible for initializing new instances of that class. The constructor accepts a single keyword-only argument called `name`, which must be provided as a string if specified, and defaults to the value `\"adk_recordings\"` when no argument is given. Upon being called, the constructor first invokes the initializer of its parent class, passing along the `name` value so that the base class can perform its own setup using that identifier. After the parent class initialization is complete, the constructor creates an instance variable named `_invocation_states`. This variable is set to an empty dictionary whose keys are strings and whose values are instances of a type called `_InvocationRecordingState`. This dictionary is intended to store and manage state information related to certain invocations, with each entry keyed by a string identifier. The setup ensures that every new object of this class starts with a clean, empty mapping for tracking these invocation states.", "answer": "def __init__(self, *, name: str = \"adk_recordings\") -> None: super().__init__(name=name) self._invocation_states: dict[str, _InvocationRecordingState] = {}"}
{"question": "This asynchronous function is designed to run before a main execution process begins, serving as a preparatory step that can set up necessary state based on the current invocation context. It receives an invocation context object, which contains information about the circumstances under which the function is being called. The first thing it does is wrap that invocation context inside a new `CallbackContext` instance, effectively creating a specialized object that can be used to access or manipulate contextual data in a standardized way. The function then checks whether a certain \"record mode\" is active for this context by calling an internal method that evaluates the state. If record mode is enabled, it proceeds to create and store an invocation state, which likely involves capturing relevant data or initializing structures needed for later processing. After performing these checks and potential setup actions, the function concludes by returning `None`, indicating that it does not produce any content output at this stage but instead focuses solely on preparing the environment for subsequent operations.", "answer": "async def before_run_callback( self, *, invocation_context: InvocationContext ) -> Optional[types.Content]: ctx = CallbackContext(invocation_context) if self._is_record_mode_on(ctx): self._create_invocation_state(ctx) return None"}
{"question": "This code defines a class named `Recordings` that inherits from `BaseModel`, which suggests it is using the Pydantic library for data validation and model management. The class is configured with a `ConfigDict` specifying that any extra fields not explicitly defined in the model are forbidden, meaning that if data is provided with keys outside of those declared in the class, validation will fail. Within the class, there is a single attribute called `recordings`, which is expected to be a list containing `Recording` objects. This attribute is initialized using a default factory that creates an empty list, ensuring that if no recordings are provided when an instance is created, the attribute will still exist as an empty list rather than being `None`. The overall structure enforces strict input validation and ensures that the `recordings` attribute always contains a list of valid `Recording` instances.", "answer": "class Recordings(BaseModel): model_config = ConfigDict( extra=\"forbid\", ) recordings: list[Recording] = Field(default_factory=list)"}
{"question": "This code defines a constructor method for a class, which is intended to be called when a new instance of the class is created. The constructor accepts a single keyword-only argument named `name`, which must be a string. If the caller does not provide a value for `name`, it defaults to the string `\"adk_replay\"`. The first action inside the constructor is to call the constructor of the parent class using `super().__init__`, passing along the `name` value so that the base class can perform its own initialization with that identifier. After the parent class has been initialized, the code creates an instance variable called `_invocation_states`. This variable is set to an empty dictionary whose keys are strings and whose values are instances of the `_InvocationReplayState` type. This dictionary is intended to store and manage state information related to invocations, with each entry keyed by a string identifier. The setup ensures that every new instance of the class starts with a clean, empty mapping for tracking these invocation states.", "answer": "def __init__(self, *, name: str = \"adk_replay\") -> None: super().__init__(name=name) self._invocation_states: dict[str, _InvocationReplayState] = {}"}
{"question": "This asynchronous method is designed to run before a main execution process begins, serving as a preparatory step that can adjust or restore the state of the system based on the current context. It receives an invocation context object, which contains information about the circumstances under which the upcoming operation is being triggered. The method first wraps this invocation context inside a `CallbackContext` object, likely to provide a more specialized interface or additional helper functionality for working with the context data. It then checks whether the system is currently operating in a replay mode, a state that suggests the process is re-running a previous invocation rather than executing fresh logic. If replay mode is active, the method proceeds to load the prior invocation’s state, presumably restoring variables, configurations, or other relevant data so that the replay can proceed consistently with its original run. After performing these checks and potential state restoration, the method concludes by returning `None`, indicating that it does not produce any direct content output at this stage but instead focuses on preparing the environment for the main execution.", "answer": "async def before_run_callback( self, *, invocation_context: InvocationContext ) -> Optional[types.Content]: ctx = CallbackContext(invocation_context) if self._is_replay_mode_on(ctx): self._load_invocation_state(ctx) return None"}
{"question": "This asynchronous method is designed to run after a certain process or task has completed, using information provided through an invocation context. It begins by creating a new callback context object from the given invocation context, which likely encapsulates details about the specific execution instance. The method then checks whether the system is currently operating in a special “replay” mode by calling an internal function with the newly created context. If replay mode is not active, the method exits immediately without performing any further actions. When replay mode is active, it proceeds to remove any stored state associated with the current invocation from an internal dictionary that tracks invocation states, using the invocation’s unique identifier as the key. This cleanup step ensures that replay-related data for that invocation is no longer retained. Finally, it writes a debug-level log entry indicating that the replay state for the given invocation has been successfully cleaned up, including the identifier in the log message for traceability.", "answer": "async def after_run_callback( self, *, invocation_context: InvocationContext ) -> None: ctx = CallbackContext(invocation_context) if not self._is_replay_mode_on(ctx): return None self._invocation_states.pop(ctx.invocation_id, None) logger.debug(\"Cleaned up replay state for invocation %s\", ctx.invocation_id)"}
{"question": "This function is designed to retrieve a collection of completed spans associated with a particular session, identified by a session ID. It begins by looking up the given session ID in an internal dictionary named `trace_dict`. This dictionary appears to map session identifiers to one or more trace IDs. If the lookup does not find an entry for the session, or if the entry exists but contains no trace IDs, the function immediately returns an empty list, indicating that there are no finished spans for that session. If trace IDs are found, the function proceeds to filter another internal collection named `_spans`. This collection contains span objects, each of which has a `context` attribute that includes a `trace_id`. The function iterates through all spans in `_spans` and selects only those whose `trace_id` matches one of the trace IDs associated with the given session. The result is a list of spans that belong to the specified session and are considered finished, which is then returned to the caller. This approach ensures that only relevant spans tied to the session’s trace IDs are included in the output.", "answer": "def get_finished_spans(self, session_id: str): trace_ids = self.trace_dict.get(session_id, None) if trace_ids is None or not trace_ids: return [] return [x for x in self._spans if x.context.trace_id in trace_ids]"}
{"question": "This function is designed to determine whether any of a specific set of OpenTelemetry-related environment variables have been configured in the current runtime environment. It does this by checking four distinct environment variable names, each corresponding to a different type of OpenTelemetry data export endpoint: a general OTLP endpoint, a dedicated traces endpoint, a metrics endpoint, and a logs endpoint. The function retrieves the value of each of these environment variables from the operating system’s environment using a standard lookup method. It then evaluates whether at least one of them contains a non-empty value. If any of these variables are set, the function returns a Boolean value indicating success, meaning that at least one endpoint configuration is present. If none of them are set, it returns false, signaling that no relevant OpenTelemetry endpoint configuration has been provided. This check is useful for determining whether OpenTelemetry exporting is enabled or should be activated based on environment configuration.", "answer": "def _otel_env_vars_enabled() -> bool: return any([ os.getenv(endpoint_var) for endpoint_var in [ otel_env.OTEL_EXPORTER_OTLP_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_TRACES_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_METRICS_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_LOGS_ENDPOINT, ] ])"}
{"question": "This function is designed to extract two specific pieces of information — a project ID and a location — from a given resource name string, based on a provided regular expression pattern. It takes two inputs: the resource name to be analyzed and a pattern that defines the expected structure of that resource name. The function uses a full match operation, meaning the entire resource name must conform exactly to the given pattern for it to be considered valid. If the resource name does not match the pattern, the function raises a ValueError, indicating that the input is invalid. When the match is successful, the function retrieves the captured groups from the regular expression, assuming that the first group corresponds to the project ID and the second group corresponds to the location. It then returns these two values together as a tuple, preserving their order so that the caller can reliably access the project ID first and the location second. This approach ensures strict validation of the resource name format and provides a clear, structured way to extract the required components.", "answer": "def _get_project_id_and_location_from_resource_name( self, resource_name: str, pattern: str ) -> tuple[str, str]: match = re.fullmatch(pattern, resource_name) if not match: raise ValueError(f'resource name {resource_name} is not valid.') return match.groups()[0], match.groups()[1]"}
{"question": "This function is designed to retrieve a specific identifier, referred to here as the execution ID, from an internal context associated with the object. It begins by checking whether a particular key, represented by `_SESSION_ID_KEY`, exists within the `_context` attribute. The `_context` appears to be a data structure, likely a dictionary, that stores various pieces of information relevant to the current state or session. If the key is not present, the function concludes that there is no execution ID available and returns `None`, signaling the absence of such data. If the key is found, the function accesses the value stored under that key in `_context` and returns it. The return type is annotated to indicate that the result may either be a string containing the execution ID or `None` if no ID is available. This approach ensures that callers of the function can reliably determine whether an execution ID is present and handle both cases appropriately.", "answer": "def get_execution_id(self) -> Optional[str]: if _SESSION_ID_KEY not in self._context: return None return self._context[_SESSION_ID_KEY]"}
{"question": "This function is designed to store a collection of file names in an internal context so they can be tracked as having been processed. It accepts a list of strings representing file names. The method first checks whether a specific key, identified by a constant, is already present in the context dictionary maintained by the object. If that key does not exist, it initializes the corresponding entry with an empty list to hold file names. Once the key is confirmed to exist, the function appends all the provided file names to the list associated with that key. This approach ensures that the context always contains a list for processed file names and that new entries are added without overwriting any previously stored names.", "answer": "def add_processed_file_names(self, file_names: [str]): if _PROCESSED_FILE_NAMES_KEY not in self._context: self._context[_PROCESSED_FILE_NAMES_KEY] = [] self._context[_PROCESSED_FILE_NAMES_KEY].extend(file_names)"}
{"question": "This function is designed to track and update the number of errors associated with a specific invocation, identified by a unique string ID. When it is called, it first checks whether the internal session state already contains a dedicated section for storing error counts, keyed by a predefined constant. If that section does not exist, it creates an empty dictionary to hold these counts. It then looks up the current error count for the given invocation ID by calling another method, which retrieves the existing value. The function increases that count by one and stores the updated value back into the error count dictionary within the session state. In effect, each time this method runs, it ensures the error tracking structure is present and increments the recorded number of errors for the specified invocation.", "answer": "def increment_error_count(self, invocation_id: str): if _ERROR_COUNT_KEY not in self._session_state: self._session_state[_ERROR_COUNT_KEY] = {} self._session_state[_ERROR_COUNT_KEY][invocation_id] = ( self.get_error_count(invocation_id) + 1 )"}
{"question": "This function is designed to clear any stored error count associated with a specific invocation identifier within an object's session state. It begins by checking whether the internal session state contains a particular key reserved for tracking error counts. If that key is absent, the function exits immediately without making any changes. If the key is present, it then looks inside the corresponding data structure to see if there is an entry for the given invocation identifier. When such an entry exists, it removes that entry entirely, effectively resetting the error count for that invocation. This ensures that any previous error tracking for that identifier is discarded, allowing future operations tied to it to start without any accumulated error history.", "answer": "def reset_error_count(self, invocation_id: str): if _ERROR_COUNT_KEY not in self._session_state: return if invocation_id in self._session_state[_ERROR_COUNT_KEY]: del self._session_state[_ERROR_COUNT_KEY][invocation_id]"}
{"question": "This function is designed to retrieve a specific portion of data from a given session state object, ensuring that the required structure exists before returning it. It accepts a session state, which behaves like a dictionary, and looks for an entry associated with a predefined key stored in the constant `_CONTEXT_KEY`. If that key is not already present in the session state, the function creates a new empty dictionary and assigns it to that key, effectively initializing the context storage. Once the key is confirmed to exist—either because it was already there or because it has just been created—the function returns the dictionary stored under that key. This returned dictionary serves as a dedicated context for code execution, allowing other parts of the program to store and retrieve execution-related data consistently within the session state.", "answer": "def _get_code_executor_context(self, session_state: State) -> dict[str, Any]: if _CONTEXT_KEY not in session_state: session_state[_CONTEXT_KEY] = {} return session_state[_CONTEXT_KEY]"}
{"question": "This piece of code defines a method responsible for creating a Docker image from a specified directory. It begins by checking whether the object has a valid path to the Docker build context. If the path is missing, it immediately stops execution by raising a ValueError, indicating that the required Docker path has not been set. If a path is provided but does not exist on the filesystem, it raises a FileNotFoundError, making it clear that the given location is invalid. Once these validations pass, the method logs a message to indicate that the Docker image build process is starting. It then uses a Docker client instance associated with the object to invoke the image build operation. The build process uses the provided path as the context, applies a tag to the resulting image based on the object's image attribute, and removes intermediate containers after a successful build to keep things clean. After the build completes, another log message is recorded to confirm that the image has been successfully created, including the image’s tag for reference. This method ensures that the build process is both validated and clearly communicated through logging.", "answer": "def _build_docker_image(self): if not self.docker_path: raise ValueError('Docker path is not set.') if not os.path.exists(self.docker_path): raise FileNotFoundError(f'Invalid Docker path: {self.docker_path}') logger.info('Building Docker image...') self._client.images.build( path=self.docker_path, tag=self.image, rm=True, ) logger.info('Docker image: %s built.', self.image)"}
{"question": "This function is designed to check whether Python 3 is installed inside a specific container environment that the object is managing. It does this by executing a command within the container to locate the Python 3 executable. The command being run is equivalent to asking the system where the `python3` program resides, which is a common way to verify its presence. The result of this command execution is captured, including both its output and an exit code that indicates success or failure. If the exit code shows that the command did not succeed, it means Python 3 could not be found in the container. In that case, the function immediately stops and raises an error, explicitly stating that Python 3 is not installed. This ensures that any subsequent operations that depend on Python 3 will not proceed without the required interpreter being available.", "answer": "def _verify_python_installation(self): exec_result = self._container.exec_run(['which', 'python3']) if exec_result.exit_code != 0: raise ValueError('python3 is not installed in the container.')"}
{"question": "This code defines an initialization method for a class, which accepts a variable number of keyword arguments bundled into a dictionary named `data`. When an instance of the class is created, the method first checks whether the keyword argument `stateful` has been provided and whether its value is set to `True`. If that condition is met, it immediately stops execution by raising a `ValueError` with a message indicating that enabling the `stateful` option is not allowed in this particular class, which is named `UnsafeLocalCodeExecutor`. Next, it performs a similar check for the keyword argument `optimize_data_file`. If this argument is present and its value is `True`, the method raises another `ValueError`, this time stating that enabling the `optimize_data_file` option is also prohibited in this class. If neither of these disallowed configurations is detected, the method proceeds to call the initialization method of its parent class, passing along all the keyword arguments it received. This ensures that the parent class can handle the rest of the setup while enforcing specific restrictions in this subclass to prevent certain behaviors that may be unsafe or incompatible with its intended use.", "answer": "def __init__(self, **data): if 'stateful' in data and data['stateful']: raise ValueError('Cannot set `stateful=True` in UnsafeLocalCodeExecutor.') if 'optimize_data_file' in data and data['optimize_data_file']: raise ValueError( 'Cannot set `optimize_data_file=True` in UnsafeLocalCodeExecutor.' ) super().__init__(**data)"}
{"question": "This code defines a constructor method for a class, most likely a custom exception class, that is intended to handle situations where a requested item cannot be found. When an instance of the class is created, it accepts an optional message parameter. If no message is provided by the caller, a default text stating that the requested item was not found is used. The provided or default message is stored as an instance attribute so it can be accessed later. After setting this attribute, the constructor calls the initializer of its parent class, passing along the message. This ensures that the parent class, which is likely an exception type, is properly initialized with the same message so that it can be displayed or logged when the exception is raised. The overall effect is to create a specialized exception object that carries a clear, customizable description of the error condition.", "answer": "def __init__(self, message=\"The requested item was not found.\"): self.message = message super().__init__(self.message)"}
{"question": "This function is responsible for constructing and returning a new evaluation set result object based on the provided application name, evaluation set identifier, and a collection of individual evaluation case results. When it is called, the function first records the current time in seconds since the epoch, which serves as a creation timestamp for the result. It then generates a unique identifier for the evaluation set result by concatenating the application name, the evaluation set ID, and the timestamp, separated by underscores. This identifier is intended to be unique for each result instance. Next, the function produces a sanitized version of this identifier to serve as a human-readable name for the evaluation set result. The sanitization process is handled by a separate helper function, which likely ensures that the name conforms to certain formatting or character restrictions. With these values prepared, the function creates a new instance of the `EvalSetResult` class, supplying it with the generated identifier, the sanitized name, the original evaluation set ID, the list of evaluation case results passed in by the caller, and the recorded creation timestamp. This object encapsulates all relevant information about the evaluation set’s outcome. Finally, the function returns the newly created `EvalSetResult` instance to the caller, making it available for further processing, storage, or display.", "answer": "def create_eval_set_result( app_name: str, eval_set_id: str, eval_case_results: list[EvalCaseResult], ) -> EvalSetResult: timestamp = time.time() eval_set_result_id = f\"{app_name}_{eval_set_id}_{timestamp}\" eval_set_result_name = _sanitize_eval_set_result_name(eval_set_result_id) eval_set_result = EvalSetResult( eval_set_result_id=eval_set_result_id, eval_set_result_name=eval_set_result_name, eval_set_id=eval_set_id, eval_case_results=eval_case_results, creation_timestamp=timestamp, ) return eval_set_result"}
{"question": "This function is designed to retrieve a specific evaluation set based on an application name and an evaluation set identifier. It takes three inputs: an object responsible for managing evaluation sets, a string representing the name of the application, and another string representing the unique identifier of the desired evaluation set. The function uses the manager object to attempt to locate and return the evaluation set that matches both the provided application name and identifier. If the manager is unable to find a matching evaluation set, the function raises an error indicating that the requested evaluation set could not be found, including the identifier in the error message for clarity. If the evaluation set is successfully located, it is returned to the caller. This ensures that the caller either receives a valid evaluation set object or is explicitly informed that the requested set does not exist.", "answer": "def get_eval_set_from_app_and_id( eval_sets_manager: EvalSetsManager, app_name: str, eval_set_id: str ) -> EvalSet: eval_set = eval_sets_manager.get_eval_set(app_name, eval_set_id) if not eval_set: raise NotFoundError(f\"Eval set `{eval_set_id}` not found.\") return eval_set"}
{"question": "This function is designed to search through a collection of evaluation cases contained within an evaluation set and return the one that matches a specific identifier. It accepts two inputs: an evaluation set object, which holds multiple evaluation case objects, and a string representing the unique identifier of the desired evaluation case. The function begins by initializing a variable to hold the matching case, starting with no value assigned. It then iterates over each evaluation case in the evaluation set, checking whether the case’s identifier matches the provided identifier. If a match is found, the function stores that case in the variable and immediately stops further searching. After the loop completes, the function returns the stored evaluation case if a match was found, or returns nothing if no case in the set matched the given identifier. This approach ensures that the search stops as soon as the correct case is located, avoiding unnecessary processing.", "answer": "def get_eval_case_from_eval_set( eval_set: EvalSet, eval_case_id: str ) -> Optional[EvalCase]: eval_case_to_find = None for eval_case in eval_set.eval_cases: if eval_case.eval_id == eval_case_id: eval_case_to_find = eval_case break return eval_case_to_find"}
