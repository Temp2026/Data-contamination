{"question": "This function is designed to take an arbitrary piece of data and produce a string representation of it in a safe and consistent way. It accepts a single argument, which can be of any type. The function first checks whether the given item has an attribute named `model_dump`, which suggests that the item might be an object from a framework or library that supports structured serialization. If such an attribute exists, the function attempts to call `model_dump` with specific parameters: it excludes any fields whose values are `None`, and it uses alias names for fields if they are defined. This call is wrapped in a try-except block to guard against errors during serialization. If an exception occurs, a warning message is logged indicating that encoding failed, and the function falls back to converting the item to a string using Python’s built-in `str()` function. If the item does not have a `model_dump` method in the first place, the function simply returns its string representation directly. This approach ensures that objects capable of structured dumping are handled in a more controlled way, while still providing a safe fallback for all other types.", "answer": "def _encode_data_item(item: Any) -> str: \"\"\"Safely encodes data items to string format. Args: item: The item to encode. Returns: String representation of the item. \"\"\" if hasattr(item, \"model_dump\"): try: return item.model_dump(exclude_none=True, by_alias=True) except Exception as ex: log.warning(\"Failed to encode data item: %s\", ex) return str(item) return str(item)"}
{"question": "This function is designed to construct a unique resource identifier string from several pieces of information related to a project. It accepts five inputs: the name of the project, an identifier for the owner, an identifier for the context, a file path, and a revision number. Inside the function, these values are collected into a list, with the revision number converted from an integer to a string so that all elements are in a consistent text format. The list represents the ordered components that together define the resource. The function then joins these components into a single string using a predefined delimiter, represented by the constant `RESOURCE_ID_DELIMITER`. The resulting string is returned, providing a standardized way to represent and reference a specific resource based on its project, ownership, context, location, and version.", "answer": "def _build_resource_id( project_name: str, owner_id: str, context_id: str, filepath: str, revision: int ) -> str: parts = [project_name, owner_id, context_id, filepath, str(revision)] return RESOURCE_ID_DELIMITER.join(parts)"}
{"question": "This function is designed to determine whether a given section of data should be marked as representing an “extended operation” within the context of an event. It accepts two inputs: an object representing a section of an A2A data structure, and an event occurrence that may contain identifiers for extended operations. The function begins by checking a series of conditions that must all be true before it proceeds. First, it verifies that the root element of the provided section is of a specific type intended to hold data content. Next, it ensures that the event occurrence contains a list or collection of extended operation identifiers. It also confirms that the root element has associated metadata. From this metadata, the function retrieves a value using a specific key derived from a helper function. This value must indicate that the data part represents a function call. Additionally, the function checks whether the “id” stored in the root element’s data is present in the event’s list of extended operation identifiers. If all these conditions are satisfied, the function updates the metadata of the root element to explicitly mark it as an extended operation. This is done by setting a particular metadata entry, again identified by a key generated through a helper function, to a boolean value indicating that the extended operation flag is active. In essence, the function acts as a filter and marker: it looks for data parts that meet specific type, metadata, and identifier criteria, and when found, it tags them so that other parts of the system can recognize them as extended operations.", "answer": "def _handle_extended_operation(a2a_section: A2APart, occurrence: Event) -> None: if ( isinstance(a2a_section.root, DataPart) and occurrence.extended_operation_ids and a2a_section.root.metadata and a2a_section.root.metadata.get( _get_adk_metadata_key(A2A_DATA_PART_METADATA_TYPE_KEY) ) == A2A_DATA_PART_METADATA_TYPE_FUNCTION_CALL and a2a_section.root.data.get(\"id\") in occurrence.extended_operation_ids ): a2a_section.root.metadata[ _get_adk_metadata_key(A2A_DATA_PART_METADATA_IS_EXTENDED_OPERATION_KEY) ] = True"}
{"question": "This function is designed to determine and return a string that uniquely identifies a user based on information available in a given request context object. It first checks whether the request context contains a `call_context` attribute, and whether that `call_context` has a `user` object with a defined `user_name` value. If all of these conditions are met, it returns the `user_name` directly, using it as the identifier. If any of these conditions fail—meaning the request context does not have a call context, the call context does not have a user, or the user does not have a username—the function instead constructs a fallback identifier. This fallback is a string beginning with the prefix `\"A2A_USER_\"` followed by the value of the `context_id` attribute from the request context. In effect, the function prioritizes returning the actual username when available, but ensures that a consistent, predictable identifier is still produced even when user details are missing.", "answer": "def _retrieve_user_identifier(ctx: RequestContext) -> str: if ( ctx.call_context and ctx.call_context.user and ctx.call_context.user.user_name ): return ctx.call_context.user.user_name return f'A2A_USER_{ctx.context_id}'"}
{"question": "This function is designed to create a standardized metadata key string based on a provided identifier. It accepts a single argument, which must be a string representing the identifier to be incorporated into the key. The first step in its logic is to validate that the identifier is present and not an empty string or a None value. If the identifier fails this check, the function immediately stops execution by raising a ValueError, signaling that the input is invalid. When the identifier passes validation, the function constructs the metadata key by concatenating a predefined constant, referred to as ADK_METADATA_KEY_PREFIX, with the given identifier. This results in a single string that combines the fixed prefix with the dynamic identifier, ensuring that all generated metadata keys follow a consistent naming pattern. The completed key is then returned to the caller for use elsewhere in the application.", "answer": "def _generate_adk_metadata_key(identifier: str) -> str: if not identifier: raise ValueError(\"Metadata identifier cannot be empty or None\") return f\"{ADK_METADATA_KEY_PREFIX}{identifier}\""}
{"question": "This function is designed to generate a standardized context identifier string based on three pieces of information: a project name, an owner ID, and a session identifier. It begins by verifying that all three input parameters are provided and non-empty. This is done by checking them collectively, and if any of them is missing or evaluates to an empty value, the function immediately raises a ValueError with a clear message indicating that all parameters must be supplied. Once the inputs are validated, the function constructs the identifier by concatenating a predefined prefix, the project name, the owner ID, and the session identifier. These components are joined together using a specific separator that is defined elsewhere in the codebase. The resulting string follows a consistent format, ensuring that context identifiers are predictable and easy to parse in other parts of the system. Finally, the function returns this assembled identifier for use wherever a unique, structured reference to a project-owner-session combination is needed.", "answer": "def _create_a2a_context_identifier(project_name: str, owner_id: str, session_identifier: str) -> str: if not all([project_name, owner_id, session_identifier]): raise ValueError(\"All parameters (project_name, owner_id, session_identifier) must be non-empty\") return ADK_CONTEXT_ID_SEPARATOR.join([ADK_CONTEXT_ID_PREFIX, project_name, owner_id, session_identifier])"}
{"question": "This function is designed to take a single string that is expected to represent a structured context identifier and break it into its meaningful components. It first checks whether the input string is present at all; if it is missing or empty, it immediately returns a tuple of three `None` values to indicate that no valid data could be extracted. If the string is provided, the function attempts to split it into parts using a predefined separator constant. The expectation is that the split will produce exactly four segments. If the number of segments is not exactly four, the function again returns three `None` values, signaling an invalid format. When the correct number of segments is present, the function assigns them to four variables: a prefix, a project name, an owner identifier, and a session identifier. It then checks whether the prefix matches a predefined constant that identifies valid context identifiers, and also verifies that the other three components are non-empty. If all these conditions are satisfied, it returns a tuple containing the project name, owner identifier, and session identifier in that order. If any of these checks fail, or if an error occurs during the splitting process, the function falls back to returning three `None` values, indicating that the input could not be parsed into a valid context identifier.", "answer": "def _parse_a2a_context_identifier(ctx_identifier: str) -> tuple[str, str, str]: if not ctx_identifier: return None, None, None try: segments = ctx_identifier.split(ADK_CONTEXT_ID_SEPARATOR) if len(segments) != 4: return None, None, None prefix, project_name, owner_id, session_identifier = segments if prefix == ADK_CONTEXT_ID_PREFIX and project_name and owner_id and session_identifier: return project_name, owner_id, session_identifier except ValueError: pass return None, None, None"}
{"question": "This code defines a constructor method for a class, which is intended to initialize new instances with specific configuration and execution behavior. The method requires that the arguments be passed as keyword arguments only, as indicated by the asterisk at the start of the parameter list. It expects an `executor` parameter, which can either be an instance of `Runner` or a callable that, when invoked, returns either a `Runner` instance or an awaitable that resolves to a `Runner`. This allows flexibility in how the execution logic is provided, supporting both direct objects and functions that produce them, possibly asynchronously. An optional `settings` parameter can also be provided, which should be an instance of `A2aAgentRunnerConfig`. If no settings are supplied, a new default `A2aAgentRunnerConfig` object is created and used. The constructor begins by calling the parent class’s initializer to ensure proper base class setup. It then stores the provided executor in a private instance variable for later use, and stores either the provided settings or the newly created default configuration in another private instance variable. This setup ensures that each instance has both an execution mechanism and a configuration object ready for use in subsequent operations.", "answer": "def __init__( self, *, executor: Runner | Callable[..., Runner | Awaitable[Runner]], settings: Optional[A2aAgentRunnerConfig] = None, ): super().__init__() self._executor = executor self._settings = settings or A2aAgentRunnerConfig()"}
{"question": "This function is designed to determine whether a given object should be considered an “A2A Job.” It first attempts to make this determination by using Python’s built‑in `isinstance` function to check if the object is an instance of the `A2ATask` class. This is the primary and preferred method of verification. However, because `isinstance` can sometimes raise exceptions—specifically `TypeError` or `AttributeError`—in cases where the object’s type information is unusual or incompatible, the function includes a fallback approach. If such an exception occurs, it instead checks two conditions: whether the object’s type name is exactly `\"Task\"` and whether the object has an attribute named `status`. If both of these conditions are met, the function treats the object as an A2A Job. The function returns a boolean value indicating the result of these checks, ensuring that even in cases where normal type checking fails, there is a secondary way to identify the intended object type.", "answer": "def _check_if_a2a_job(item) -> bool: \"\"\"Verify if an object is an A2A Job, with fallback for isinstance issues.\"\"\" try: return isinstance(item, A2ATask) except (TypeError, AttributeError): return type(item).__name__ == \"Task\" and hasattr(item, \"status\")"}
{"question": "This function is designed to determine whether a given object should be considered an A2A notification. It accepts a single argument and attempts to verify its type. The first step is to check if the object is an instance of the `A2AMessage` class. If this check succeeds without error, the function immediately returns the result of that type comparison. However, if the attempt to perform the type check raises either a `TypeError` or an `AttributeError`—which could happen if the object is incompatible with the check or lacks expected attributes—the function falls back to a secondary verification method. In this fallback, it inspects the object’s actual type name to see if it is `\"Message\"` and also checks whether the object has an attribute named `\"role\"`. If both of these conditions are met, the function returns `True`; otherwise, it returns `False`. This approach allows the function to handle different object structures gracefully, ensuring that it can still identify relevant message-like objects even when they are not strictly instances of the expected class.", "answer": "def _verify_if_a2a_notification(item) -> bool: try: return isinstance(item, A2AMessage) except (TypeError, AttributeError): return type(item).__name__ == \"Message\" and hasattr(item, \"role\")"}
{"question": "This code defines a class named `ActiveStreamingHandler` that inherits from `BaseModel`, which suggests it is using Pydantic for data validation and model management. The class is configured with a `ConfigDict` that allows arbitrary types to be assigned to its fields, meaning it will not restrict attributes to only standard Python types or those explicitly supported by Pydantic. It also forbids any extra fields that are not explicitly declared in the class, ensuring that only the defined attributes can be present in instances. Within the class, two attributes are declared. The first, `operation`, is intended to hold an asynchronous task from Python’s `asyncio` library, but it is optional, meaning it can either contain a reference to an `asyncio.Task` object or be left unset with a value of `None`. The second attribute, `channel`, is also optional and is meant to store a reference to a `LiveRequestQueue` object, which appears to be a custom or external type likely used for managing live or streaming requests. By making both attributes optional, the class can represent a handler that may or may not currently have an active streaming operation or an associated communication channel. This structure suggests the class is designed to track and manage the state of a streaming process, including both the asynchronous execution and the data flow channel, while enforcing strict control over what data can be stored in its instances.", "answer": "class ActiveStreamingHandler(BaseModel): model_config = ConfigDict( arbitrary_types_allowed=True, extra='forbid', ) operation: Optional[asyncio.Task] = None channel: Optional[LiveRequestQueue] = None"}
{"question": "This function is designed to inspect a given configuration object and decide what type of agent configuration it represents. It begins by checking whether the provided configuration is a dictionary. If it is, the function attempts to retrieve the value associated with the key `\"agent_class\"`. If that key is not present, it defaults to using the string `\"LlmAgent\"`. Once it has determined this agent type string, it checks whether the value is found within a predefined collection of recognized agent classes, referenced as `_ADK_AGENT_CLASSES`. If the value is recognized, the function returns it directly, indicating that the configuration corresponds to that specific agent type. If the value is not recognized, the function returns the string `\"BaseAgent\"`, treating it as a generic or fallback agent type. If the initial check finds that the configuration is not a dictionary, the function raises a `ValueError`, signaling that the provided configuration is invalid and cannot be processed.", "answer": "def determine_agent_config_type(config: Any) -> str: if isinstance(config, dict): agent_type: str = config.get(\"agent_class\", \"LlmAgent\") if agent_type in _ADK_AGENT_CLASSES: return agent_type return \"BaseAgent\" raise ValueError(f\"Invalid agent configuration: {config}\")"}
{"question": "This code defines an asynchronous method intended to be part of a larger class, likely serving as a base or abstract implementation that subclasses are expected to override. The method is named `_execute_async_implementation` and is declared with the `async def` syntax, meaning it can perform asynchronous operations and return results over time using an asynchronous generator. It accepts a single parameter called `context`, which is of type `InvocationContext`, suggesting that it carries information or state relevant to the execution process. The method is annotated to return an `AsyncGenerator` that will yield `Event` objects and eventually terminate without returning a final value. Inside the method body, the first action is to immediately raise a `NotImplementedError`. This exception includes a message that dynamically inserts the type of the current object, making it clear which class has not provided its own implementation. This design signals that the method is abstract in nature and must be implemented in a subclass before it can be used. Because the exception is raised before any other logic can run, the subsequent `yield` statement is never actually reached during execution. The presence of the `yield` statement, however, ensures that the function is recognized by Python as an asynchronous generator, which is important for type consistency and interface contracts in the broader system. Overall, this snippet serves as a placeholder for asynchronous event-producing logic that subclasses are required to define.", "answer": "async def _execute_async_implementation( self, context: InvocationContext ) -> AsyncGenerator[Event, None]: raise NotImplementedError( f'_execute_async_implementation for {type(self)} is not implemented.' ) yield"}
{"question": "This function is designed to locate and return the highest-level agent in a chain of linked agents. It begins by setting a variable to reference the current object instance. The function then repeatedly checks whether this agent has a “super_agent” associated with it, which would represent a higher-level or parent agent in the hierarchy. If such a parent exists, the variable is updated to reference that parent, and the process continues. This loop repeats until an agent is found that does not have a “super_agent,” meaning it is at the top of the chain. Once the topmost agent is reached, the function returns it. In effect, this method traverses upward through a hierarchy of agents until it finds and returns the root agent.", "answer": "def main_agent(self) -> BaseAgent: main_agent = self while main_agent.super_agent is not None: main_agent = main_agent.super_agent return main_agent"}
{"question": "This function is designed to locate and return an agent object based on a given name. It accepts a string parameter representing the name to search for and returns either an instance of a `BaseAgent` or `None` if no matching agent is found. The method first checks whether the current object’s `name` attribute matches the provided name. If they are identical, it immediately returns the current object itself, indicating that the search target has been found at the top level. If the names do not match, the method delegates the search to another function called `find_sub_agent`, passing along the same name. This secondary function is presumably responsible for searching through subordinate or nested agents associated with the current object. The overall logic ensures that the search begins with the current agent and, if unsuccessful, continues into its hierarchy of sub-agents.", "answer": "def find_agent(self, name: str) -> Optional[BaseAgent]: if self.name == name: return self return self.find_sub_agent(name)"}
{"question": "This function is designed to produce a list of callback objects that should be executed before an agent runs. It begins by checking whether there is any value assigned to the attribute holding the pre-agent callback or callbacks. If that attribute is empty or evaluates to false, the function returns an empty list, indicating that there are no callbacks to run. If the attribute contains a list, it assumes that this list already contains the appropriate callback objects and returns it directly without modification. If the attribute contains a single callback object rather than a list, the function wraps that single object inside a new list so that the result is always in list form. In all cases, the function ensures that its output is consistently a list of callback objects, regardless of whether the original attribute was empty, a single callback, or a list of callbacks.", "answer": "def standard_pre_agent_callbacks(self) -> list[_SingleAgentCallback]: if not self.pre_agent_callback: return [] if isinstance(self.pre_agent_callback, list): return self.pre_agent_callback return [self.pre_agent_callback]"}
{"question": "This method is designed to establish a parent–child relationship between an agent object and a collection of its subordinate agents. It operates by iterating through the list of subordinate agents stored in the instance’s `sub_agents` attribute. For each subordinate agent encountered, it first checks whether that agent already has a parent assigned. If a parent is already present, the method halts execution by raising a `ValueError`, providing a detailed message that includes the subordinate agent’s name, the name of its current parent, and the name of the agent attempting to become the new parent. This prevents accidental reassignment of a subordinate agent to a different parent without explicit handling. If no parent is set, the method assigns the current agent instance as the subordinate’s parent by setting the subordinate’s `parent_agent` attribute to `self`. After processing all subordinate agents successfully, the method returns the current agent instance, allowing for method chaining or further operations on the same object.", "answer": "def __set_parent_agent_for_sub_agents(self) -> BaseAgent: for sub_agent in self.sub_agents: if sub_agent.parent_agent is not None: raise ValueError( f'Agent `{sub_agent.name}` already has a parent agent, current' f' parent: `{sub_agent.parent_agent.name}`, trying to add:' f' `{self.name}`' ) sub_agent.parent_agent = self return self"}
{"question": "This code defines a method named `_parse_config` that belongs to a class, indicated by the presence of `cls` as its first parameter. The method is intended to work with a specific type of class, `SelfAgent`, and it accepts four arguments. The first argument, `cls`, represents the class itself rather than an instance, which means this method is likely a class method even though the decorator is not shown here. The second argument, `config`, is expected to be an object of type `BaseAgentConfig`, which suggests it contains configuration data relevant to the agent. The third argument, `config_abs_path`, is a string that presumably holds the absolute file path to the configuration source. The fourth argument, `kwargs`, is a dictionary mapping string keys to values of any type, representing additional parameters or overrides that may be passed in. Despite the variety of inputs, the method’s implementation is minimal. It does not perform any processing, validation, or transformation of the provided configuration or path. Instead, it simply returns the `kwargs` dictionary exactly as it was received. This means that whatever extra keyword arguments are passed into the method become its direct output, without any modification. The presence of the other parameters suggests that in a more complete implementation, the method might merge these keyword arguments with values from the configuration object or file, but in its current form, it acts as a pass-through for the `kwargs` data.", "answer": "def _parse_config( cls: Type[SelfAgent], config: BaseAgentConfig, config_abs_path: str, kwargs: Dict[str, Any], ) -> Dict[str, Any]: return kwargs"}
{"question": "This asynchronous method is designed to retrieve a list of artifact identifiers associated with the current execution context. It begins by checking whether the artifact service within the stored invocation context has been properly initialized. If the artifact service is missing, it immediately stops execution by raising a ValueError, signaling that the operation cannot proceed without this dependency. When the artifact service is available, the method calls its asynchronous function for listing artifact keys, supplying it with contextual information such as the application name, the user’s unique identifier, and the current session’s identifier. The method then waits for the artifact service to complete its operation and returns the resulting list of strings, each representing an artifact key relevant to the given application, user, and session.", "answer": "async def list_artifacts(self) -> list[str]: if self._invocation_ctx.artifact_service is None: raise ValueError(\"Artifact service is not initialized.\") return await self._invocation_ctx.artifact_service.list_artifact_keys( app_name=self._invocation_ctx.app_name, user_id=self._invocation_ctx.user_id, session_id=self._invocation_ctx.session.id, )"}
{"question": "This asynchronous method is responsible for storing authentication credentials using a credential service that is expected to be available within the object’s invocation context. When the method is called, it first checks whether the credential service in the invocation context has been initialized. If the credential service is missing, it immediately raises a ValueError to signal that the operation cannot proceed. If the service is present, the method then calls its asynchronous store operation, passing along the provided authentication configuration object and a reference to the current instance. The use of the await keyword ensures that the method waits for the credential storage process to complete before continuing, allowing proper handling of asynchronous execution and potential delays in storing the credentials. This design enforces that credentials are only stored when the necessary service is available and integrates the current object’s context into the storage process.", "answer": "async def store_credential(self, auth_cfg: AuthConfig) -> None: if self._invocation_ctx.credential_service is None: raise ValueError(\"Credential service is not initialized.\") await self._invocation_ctx.credential_service.store_credential( auth_cfg, self )"}
{"question": "This asynchronous function is designed to obtain authentication credentials based on a provided configuration object. It takes in an `AuthConfig` instance as its input, which likely contains the necessary parameters or settings for determining how the credentials should be retrieved. The function first checks whether the current invocation context has an associated credential service available. This credential service is expected to be responsible for actually performing the retrieval of credentials. If the credential service is missing, the function immediately raises a `ValueError`, signaling that the operation cannot proceed because the required service has not been initialized. If the credential service is present, the function delegates the task of fetching the credentials to it, passing along both the authentication configuration and a reference to the current object. The call to the credential service is awaited, meaning the function will pause until the asynchronous credential retrieval completes, and then return the resulting `AuthCredential` object or `None` if no credentials are found. This structure ensures that credential fetching is handled in a non-blocking manner while enforcing that the necessary service is available before attempting the operation.", "answer": "async def fetch_credential( self, auth_cfg: AuthConfig ) -> Optional[AuthCredential]: if self._invocation_ctx.credential_service is None: raise ValueError(\"Credential service is not initialized.\") return await self._invocation_ctx.credential_service.fetch_credential( auth_cfg, self )"}
{"question": "This function is designed to ensure that exactly one of two possible attributes, `code` or `config_path`, is set on the current object. It begins by checking whether the `code` attribute has been assigned a value, and separately whether the `config_path` attribute has been assigned a value. These checks result in two Boolean flags indicating the presence or absence of each attribute. The function then enforces two rules: if both attributes are present at the same time, it raises an error indicating that only one should be provided; if neither attribute is present, it raises an error stating that exactly one must be provided. If the object passes these validations—meaning one attribute is set and the other is not—the function returns the object itself, allowing further use or method chaining. This logic ensures that the object is always in a valid state with respect to these two mutually exclusive configuration options.", "answer": "def verify_exactly_one_field(self) -> AgentRefConfig: has_code = self.code is not None has_config_path = self.config_path is not None if has_code and has_config_path: raise ValueError(\"Only one of `code` or `config_path` should be provided\") if not has_code and not has_config_path: raise ValueError(\"Exactly one of `code` or `config_path` must be provided\") return self"}
{"question": "This function is designed to determine and return the appropriate agent class based on a provided type name. It accepts a string that represents the desired agent type. If the caller does not supply a value, it defaults to using the name \"LlmAgent\". The function first checks whether the provided name contains a dot, which would indicate that it is already a fully qualified module path. If no dot is found, it assumes the name is a short form and prepends a default namespace prefix, specifically \"google.adk.agents.\", to construct a fully qualified name. Once the fully qualified name is determined, the function uses a helper routine called `resolve_fully_qualified_name` to dynamically locate and load the corresponding Python object. It then verifies that the resolved object is indeed a class and that it inherits from the `BaseAgent` class, ensuring it meets the expected interface or behavior requirements. If these conditions are satisfied, the function returns the class object so it can be instantiated or otherwise used by the caller. If the resolved object fails either check—meaning it is not a class or does not derive from `BaseAgent`—the function raises a `ValueError` with a clear message indicating that the provided type is invalid and must be a subclass of `BaseAgent`. This ensures that only valid agent types are accepted and prevents runtime errors from incompatible objects.", "answer": "def _determine_agent_type(agent_type: str) -> type[BaseAgent]: agent_type_name = agent_type or \"LlmAgent\" if \".\" not in agent_type_name: agent_type_name = f\"google.adk.agents.{agent_type_name}\" agent_class = resolve_fully_qualified_name(agent_type_name) if inspect.isclass(agent_class) and issubclass(agent_class, BaseAgent): return agent_class raise ValueError( f\"Invalid agent type `{agent_type_name}`. It must be a subclass of BaseAgent.\" )"}
{"question": "This function is designed to load and validate a configuration for an agent from a file stored at a specified location on disk. It begins by checking whether the provided file path actually exists in the filesystem. If the file is missing, it immediately stops execution by raising a `FileNotFoundError`, including the path in the error message so the caller knows exactly which file could not be found. If the file is present, it opens the file in read mode using UTF-8 encoding to ensure proper handling of text content. The contents of the file are then read and parsed as YAML using a safe loading method, which converts the YAML data into a corresponding Python object such as a dictionary. Once the raw configuration data is loaded, the function passes it to the `model_validate` method of the `AgentConfig` class. This step checks that the data matches the expected schema or structure defined by `AgentConfig`, and returns a validated configuration object that can be used by the rest of the program. The function’s overall purpose is to reliably retrieve configuration data from a file, ensure it is correctly structured, and make it available in a validated form for further use.", "answer": "def _read_config_from_path(config_file_path: str) -> AgentConfig: if not os.path.exists(config_file_path): raise FileNotFoundError(f\"Config file not found: {config_file_path}\") with open(config_file_path, \"r\", encoding=\"utf-8\") as f: config_obj = yaml.safe_load(f) return AgentConfig.model_validate(config_obj)"}
{"question": "This function is designed to take a string that represents a fully qualified name of a Python object, meaning it includes both the module path and the object’s name separated by a dot. It begins by attempting to split the input string into two parts: everything before the last dot is treated as the module path, and the part after the last dot is treated as the name of the object within that module. Using the module path, it dynamically imports the specified module at runtime. Once the module is successfully loaded, it looks up the object by name within that module and returns it. If any step in this process fails—such as if the string does not contain a valid module and object name, the module cannot be imported, or the object does not exist in the module—the function catches the resulting exception and raises a new ValueError, indicating that the provided fully qualified name is invalid, while preserving the original exception as the underlying cause.", "answer": "def resolve_fully_qualified_name(fq_name: str) -> Any: try: module_path, obj_name = fq_name.rsplit(\".\", 1) module = importlib.import_module(module_path) return getattr(module, obj_name) except Exception as e: raise ValueError(f\"Invalid fully qualified name: {fq_name}\") from e"}
{"question": "This function is designed to take a string that represents a reference to a Python object and return the corresponding object, but only if it meets specific criteria related to being an agent instance. It begins by checking whether the provided string contains a dot, which is required to separate the module path from the object name. If no dot is found, it immediately raises an error indicating that the reference format is invalid. Next, it splits the string into two parts: the module path and the object name, using the last dot in the string as the separator. It then dynamically imports the module specified by the module path. Once the module is loaded, it retrieves the attribute from that module whose name matches the object name. After obtaining the object, the function verifies that it is not callable, meaning it should not be a function, method, or any other callable entity. If the object is callable, it raises an error because the reference is expected to point to an agent instance rather than executable code. It then checks whether the object is an instance of the BaseAgent class. If it is not, another error is raised, indicating that the reference does not point to a valid agent instance. If all these checks pass, the function returns the object, which at this point is guaranteed to be a non-callable instance of BaseAgent that was located using the provided module and object reference string. If you want, I can also explain why this approach might be risky when dealing with untrusted input. Would you like me to do that?", "answer": "def _resolve_agent_code_ref(ref: str) -> Any: if \".\" not in ref: raise ValueError(f\"Invalid code reference: {ref}\") module_path, obj_name = ref.rsplit(\".\", 1) module = importlib.import_module(module_path) obj = getattr(module, obj_name) if callable(obj): raise ValueError(f\"Invalid agent reference to a callable: {ref}\") if not isinstance(obj, BaseAgent): raise ValueError(f\"Invalid agent reference to a non-agent instance: {ref}\") return obj"}
{"question": "This function is designed to dynamically locate and optionally invoke a Python object based on information provided in a configuration object. It begins by validating that the configuration exists and contains a non-empty name attribute. This name is expected to be a fully qualified reference to a Python object, including both the module path and the object’s name, separated by a dot. The function splits this string into two parts: the module path and the object name. It then imports the specified module at runtime using Python’s import system and retrieves the referenced object from that module. Once the object is obtained, the function checks whether the configuration includes any arguments and whether the retrieved object is callable, such as a function or a class constructor. If both conditions are met, it processes the arguments into two separate collections: keyword arguments, built from configuration entries that specify a name, and positional arguments, built from entries without a name. It then calls the object with these arguments and returns the result of that call. If the object is not callable or no arguments are provided, the function simply returns the object itself without invoking it. This approach allows for flexible, runtime resolution and execution of code elements based on external configuration.", "answer": "def determine_code_reference(configuration: CodeConfiguration) -> Any: if not configuration or not configuration.name: raise ValueError(\"Invalid CodeConfiguration.\") module_path, object_name = configuration.name.rsplit(\".\", 1) module = importlib.import_module(module_path) instance = getattr(module, object_name) if configuration.arguments and callable(instance): keyword_arguments = {argument.name: argument.value for argument in configuration.arguments if argument.name} positional_arguments = [argument.value for argument in configuration.arguments if not argument.name] return instance(*positional_arguments, **keyword_arguments) else: return instance"}
{"question": "This function is responsible for tracking how many times a certain process, specifically one involving calls to a large language model (LLM), has been executed, and for enforcing a limit on those calls if such a limit is configured. Each time the function is invoked, it increases an internal counter that keeps track of the total number of LLM calls made so far. After incrementing the counter, it checks whether a run configuration object has been provided and whether that configuration specifies a positive maximum number of allowed LLM calls. If both conditions are true, it then compares the updated counter against the configured maximum. If the counter has exceeded the allowed limit, the function interrupts execution by raising a specific exception that signals the limit has been breached, including in the error message the maximum number that was permitted. This ensures that the system can prevent excessive LLM usage according to predefined constraints.", "answer": "def increment_and_enforce_llm_calls_limit( self, run_config: Optional[RunConfig] ): self._number_of_llm_calls += 1 if ( run_config and run_config.max_llm_calls > 0 and self._number_of_llm_calls > run_config.max_llm_calls ): raise LlmCallsLimitExceededError( \"Max number of llm calls limit of\" f\" `{run_config.max_llm_calls}` exceeded\" )"}
{"question": "This function determines whether a particular event occurrence should trigger a suspension of an invocation. It begins by checking whether resumption is possible for the current context; if resumption is not possible, the function immediately decides against suspension and returns false. Next, it verifies that the event occurrence contains both a set of extended operation identifiers and at least one recorded function invocation. If either of these is missing or empty, the function concludes that suspension is not warranted and returns false. If both are present, it examines each function invocation associated with the occurrence. For each invocation, it checks whether its identifier matches any of the extended operation identifiers linked to the occurrence. If a match is found, the function determines that suspension should occur and returns true right away. If no matches are found after checking all invocations, the function returns false, indicating that suspension is not necessary.", "answer": "def should_suspend_invocation(self, occurrence: Event) -> bool: if not self.resumption_possible: return False if not occurrence.extended_operation_identifiers or not occurrence.get_function_invocations(): return False for invocation in occurrence.get_function_invocations(): if invocation.identifier in occurrence.extended_operation_identifiers: return True return False"}
{"question": "This piece of code is designed to find the specific function invocation event that corresponds to a given function response event. It begins by retrieving all function responses associated with the provided function response occurrence. If there are no function responses, it immediately concludes that there is nothing to match and returns no result. When function responses are present, it takes the identifier from the first response in the list. This identifier serves as a unique reference to the original function invocation that produced the response. The method then gathers a list of events that represent the current invocation context. It iterates through these events in reverse order, excluding the most recent one, because the most recent event is the response itself and the goal is to find the earlier invocation that triggered it. For each event in this reversed sequence, it checks whether any of the function invocations within that event have an identifier matching the one from the function response. If a match is found, that event is returned as the corresponding function invocation. If the search completes without finding a matching invocation, the method returns no result, indicating that the corresponding invocation could not be located. Would you like me to also explain the possible reasoning behind reversing the order of events in this search?", "answer": "def _locate_corresponding_function_invocation( self, function_response_occurrence: Event ) -> Optional[Event]: function_responses = function_response_occurrence.get_function_responses() if not function_responses: return None function_invocation_identifier = function_responses[0].identifier occurrences = self._get_events(current_invocation=True) for occurrence in reversed(occurrences[:-1]): if any(invocation.identifier == function_invocation_identifier for invocation in occurrence.get_function_invocations()): return occurrence return None"}
{"question": "This function is designed to retrieve the most recent messages authored by a human user from a given list of events. It begins by initializing an empty list to store the results. The function processes the events in reverse order, starting from the most recent and moving backward in time. As it iterates, it checks whether it has already collected at least one message and encounters an event whose author is not the user; if that happens, it stops processing further, effectively limiting the collection to the most recent consecutive block of user-authored messages. For each event authored by the user, it verifies that the event contains content and that the content has parts. If these conditions are met, it takes the text from the first part of the content and wraps it in a HumanMessage object, adding it to the results list. After finishing the iteration, it reverses the collected messages so they are returned in chronological order from oldest to newest within that block of recent user messages.", "answer": "def _fetch_last_human_messages(happenings: list[Event]) -> list[HumanMessage]: outputs = [] for happening in reversed(happenings): if outputs and happening.author != 'user': break if happening.author == 'user' and happening.content and happening.content.parts: outputs.append(HumanMessage(content=happening.content.parts[0].text)) return list(reversed(outputs))"}
{"question": "This function is designed to retrieve a set of messages based on a given list of events. It accepts a collection of `Event` objects as input and produces a list containing either human-generated messages or AI-generated messages. The function first checks whether the associated `network` object has an active `checkpointer` component. If a checkpointer is present, it delegates the retrieval process to a separate function that focuses on obtaining the most recent human messages from the provided events. If no checkpointer is available, it instead calls another method belonging to the same object, which reconstructs or gathers the conversation history involving an agent, using the supplied events. The choice between these two retrieval paths depends entirely on the presence or absence of the checkpointer, ensuring that the returned messages are appropriate for the current state of the system.", "answer": "def _fetch_messages( self, happenings: list[Event] ) -> list[Union[HumanMessage, AIMessage]]: if self.network.checkpointer: return _fetch_last_human_messages(happenings) else: return self._fetch_conversation_with_agent(happenings)"}
{"question": "This function is designed to take a sequence of event objects and transform them into a structured conversation between a human user and an AI agent. It begins by initializing an empty list that will hold the conversation messages in chronological order. It then iterates through each event in the provided list. For each event, it first checks whether the event contains any content and whether that content has at least one part; if either of these conditions is not met, the event is skipped entirely. If the event was authored by a human user, the function creates a new human message object using the text from the first part of the event’s content and adds it to the conversation list. If the event was authored by the AI agent—identified by matching the event’s author to the agent’s label stored in the instance—it creates an AI message object in the same way and adds it to the list. After processing all events, the function returns the assembled list of messages, which represents the back-and-forth dialogue between the human and the AI in the order they occurred.", "answer": "def _fetch_conversation_with_agent( self, happenings: list[Event] ) -> list[Union[HumanMessage, AIMessage]]: conversation = [] for happening in happenings: if not happening.content or not happening.content.parts: continue if happening.author == 'user': conversation.append(HumanMessage(content=happening.content.parts[0].text)) elif happening.author == self.label: conversation.append(AIMessage(content=happening.content.parts[0].text)) return conversation"}
{"question": "This code defines a constructor method for a class, which is executed when an instance of that class is created. Its purpose is to ensure that an appropriate asynchronous event loop is available for the instance to use, and to set up an internal queue for managing asynchronous tasks or data. When the constructor runs, it first attempts to retrieve the currently running asyncio event loop. This is done to check whether the program is already operating within an asynchronous context. If no event loop is active at the moment, the attempt will raise a `RuntimeError`. In that case, the code responds by creating a new event loop and explicitly setting it as the current event loop for the program. This guarantees that subsequent asynchronous operations will have a loop to run on, even if the surrounding environment did not already provide one. After ensuring that an event loop is in place, the constructor creates an instance of `asyncio.Queue` and assigns it to an internal attribute named `_holder`. This queue is designed for asynchronous use, meaning that it can be safely interacted with from coroutines without blocking the event loop. The queue will likely be used later in the class to store and manage items or tasks in a thread-safe, non-blocking manner, allowing producers and consumers to coordinate efficiently within the asynchronous framework.", "answer": "def __init__(self): try: asyncio.get_running_loop() except RuntimeError: cycle = asyncio.new_event_loop() asyncio.set_event_loop(cycle) self._holder = asyncio.Queue()"}
{"question": "This function is designed to determine and return a language model instance that the current object should use. It first checks whether the object’s `model` attribute is already an instance of the expected base language model type. If so, it simply returns that instance directly. If the `model` attribute is not an object but contains a non-empty string, it treats that string as a model identifier and uses a registry mechanism to create a new language model instance based on that identifier. If neither of those conditions is met, meaning the current object does not have a usable model defined, the function attempts to find one by looking upward through a chain of related objects, following the `parent_agent` references. It continues moving up this chain until it encounters an ancestor that is a language model–capable agent, in which case it returns that ancestor’s standard model. If the search reaches the top of the chain without finding any suitable model, the function raises an error indicating that no model could be located for the current object, including its label in the error message for clarity.", "answer": "def standard_model(self) -> BaseLlm: if isinstance(self.model, BaseLlm): return self.model elif self.model: # model is non-empty str return LLMRegistry.create_llm(self.model) else: ancestor = self.parent_agent while ancestor is not None: if isinstance(ancestor, LlmAgent): return ancestor.standard_model ancestor = ancestor.parent_agent raise ValueError(f'No model located for {self.label}.')"}
{"question": "This asynchronous method is designed to gather and return a complete list of tool instances based on the set of tool definitions associated with the current object. It begins by creating an empty list that will hold the resulting tools. It then determines whether there is more than one tool definition present, storing that information as a Boolean value for later use. The method proceeds to iterate over each item in the collection of tool definitions. For each item, it calls another asynchronous function that converts the given tool definition into one or more actual tool instances, passing along the current context, the model associated with the object, and the Boolean flag indicating whether multiple tools are involved. The results from each conversion are added to the accumulating list. Once all tool definitions have been processed and their corresponding tool instances collected, the method returns the complete list.", "answer": "async def standard_implements( self, context: ReadonlyContext = None ) -> list[BaseTool]: fetched_implements = [] several_implements = len(self.implements) > 1 for tool_union in self.implements: fetched_implements.extend( await _transform_tool_union_to_implements( tool_union, context, self.model, several_implements ) ) return fetched_implements"}
{"question": "This function is designed to produce a standardized list of “before model” handler objects, ensuring that the result is always in list form regardless of how the handler or handlers were originally stored. It first checks whether the instance has any value assigned to its `before_model_handler` attribute. If that attribute is empty or evaluates to false, the function immediately returns an empty list, indicating that there are no handlers to run. If there is a value present, the function then determines whether it is already a list. If it is, that list is returned directly without modification. If it is not a list, the function wraps the single handler object in a new list containing just that one element, and returns it. This approach allows the rest of the code to work with a consistent list-based representation of handlers, simplifying downstream processing and avoiding the need to check for single values versus lists elsewhere in the program.", "answer": "def standard_before_model_handlers( self, ) -> list[_SingleBeforeModelHandler]: if not self.before_model_handler: return [] if isinstance(self.before_model_handler, list): return self.before_model_handler return [self.before_model_handler]"}
{"question": "This function is designed to produce a standardized list of handler objects that should be executed after a certain model-related operation. It works by examining an attribute named `after_model_handler` on the current object. If that attribute has not been set or contains a value that evaluates to false, the function returns an empty list, indicating that there are no handlers to run. If the attribute is already a list, it assumes that the list contains the handlers in the correct form and simply returns it unchanged. If the attribute is a single handler rather than a list, the function wraps that single handler inside a new list so that the result is always a list of handlers. This ensures that the rest of the code can consistently work with a list regardless of whether the original attribute was empty, a single handler, or multiple handlers.", "answer": "def standard_after_model_handlers(self) -> list[_SingleAfterModelHandler]: if not self.after_model_handler: return [] if isinstance(self.after_model_handler, list): return self.after_model_handler return [self.after_model_handler]"}
{"question": "This code defines a function whose purpose is to collect identifiers from a hierarchy of agent objects. It begins by taking a single agent as input and adding that agent’s identifier to a shared list named `agents`. The function then checks whether the given agent has an attribute called `child_agents` and whether that attribute contains any elements. If both conditions are met, it iterates through each child agent in that collection and calls the same function recursively on them. This recursive process ensures that not only the initial agent but also all of its descendants in the hierarchy are processed, with each one’s identifier being added to the `agents` list. After defining the function, it is invoked with a top-level agent object, referred to as `self.top_agent`, which serves as the starting point for the traversal. Once the recursive gathering is complete, the accumulated list of agent identifiers is returned, representing all agents found in the hierarchy starting from the top agent.", "answer": "def gather_agents(agent): agents.append(agent.identifier) if hasattr(agent, 'child_agents') and agent.child_agents: for child_agent in agent.child_agents: gather_agents(child_agent) gather_agents(self.top_agent) return agents"}
{"question": "This function is designed to take in a class reference for a type of `LoopAgent`, a configuration object of type `LoopAgentConfig`, a string representing the full path to the configuration, and a dictionary of arguments. It operates by checking whether the configuration object specifies a value for `maximum_iterations`. If such a value exists and is not null or zero, the function adds or updates an entry in the arguments dictionary with the key `'maximum_iterations'` and sets its value to the one provided in the configuration. After performing this conditional update, the function returns the potentially modified arguments dictionary. The overall purpose is to ensure that the arguments dictionary reflects the iteration limit defined in the configuration, if one has been set.", "answer": "def _process_configuration( cls: type[LoopAgent], configuration: LoopAgentConfig, config_full_path: str, arguments: Dict[str, Any], ) -> Dict[str, Any]: if configuration.maximum_iterations: arguments['maximum_iterations'] = configuration.maximum_iterations return arguments"}
{"question": "This function is designed to generate a new invocation context for a child agent, based on an existing context from its parent agent. It begins by creating a duplicate of the provided context object, ensuring that any modifications will not affect the original. It then constructs a branch identifier that represents the relationship between the parent and child agents, using each agent’s label and joining them with a period. If the duplicated context already has a branch value, the new branch identifier is appended to it, separated by a period, effectively extending the branch path to include the child agent. If no branch value exists in the duplicated context, the branch is simply set to the newly constructed identifier. Finally, the updated context, now reflecting the hierarchical relationship between the parent and child agents, is returned for use in subsequent operations.", "answer": "def _create_branch_context_for_child_agent( parent: BaseAgent, child: BaseAgent, context: InvocationContext, ) -> InvocationContext: context = context.model_duplicate() branch_suffix = f'{parent.label}.{child.label}' context.branch = ( f'{context.branch}.{branch_suffix}' if context.branch else branch_suffix ) return context"}
{"question": "This asynchronous function is designed to process a stream of events associated with a single agent. It receives an asynchronous iterable that produces event occurrences one at a time. For each event retrieved from this iterable, the function creates a new synchronization object in the form of an asyncio event. It then places a tuple containing the event occurrence and this synchronization object into a shared queue, making the event available for other parts of the program to handle. After placing the tuple in the queue, the function pauses and waits until the synchronization object is signaled, indicating that processing for that specific event has been completed elsewhere and that it is safe to continue. This cycle repeats for every event in the incoming stream. When the stream ends or if an error occurs, the function ensures that a special termination marker is placed into the queue along with a null value for the synchronization object, signaling to downstream consumers that no further events will be produced for this agent.", "answer": "async def handle_an_agent(events_for_single_agent): try: async for occurrence in events_for_single_agent: resume_indicator = asyncio.Event() await queue.put((occurrence, resume_indicator)) await resume_indicator.wait() finally: await queue.put((terminator, None))"}
{"question": "This code defines a configuration class named `ConcurrentAgentConfig` that inherits from a base configuration class called `BaseAgentConfig`. It is intended to hold and enforce configuration settings specific to a type of agent referred to as a \"ConcurrentAgent.\" Within the class, there is a `model_config` attribute that is assigned a `ConfigDict` object with the `extra` parameter set to `\"forbid\"`. This setting means that when instances of this configuration are created, any attempt to include fields that are not explicitly defined in the class will result in an error, ensuring strict adherence to the predefined schema. The class also declares a field named `agent_type`, which is a string with a default value of `\"ConcurrentAgent\"`. This field serves as a unique identifier for the agent type, making it possible to distinguish this configuration from others. The field includes a descriptive text explaining that its value is used to uniquely identify the `ConcurrentAgent` class. Overall, the code establishes a strict, well-defined configuration structure for a concurrent agent, preventing unexpected or unsupported configuration options and providing a clear identifier for the agent type.", "answer": "class ConcurrentAgentConfig(BaseAgentConfig): model_config = ConfigDict( extra=\"forbid\", ) agent_type: str = Field( default=\"ConcurrentAgent\", description=\"The value is used to uniquely identify the ConcurrentAgent class.\", )"}
{"question": "This function is designed to validate a numeric value that represents the maximum number of calls allowed to a large language model within a certain process or run. It accepts a number as input and performs checks to ensure that the value is within a reasonable range. The first check determines whether the provided number is equal to the largest possible integer value supported by the system, which is obtained from the system’s maximum size constant. If the number matches this extreme upper limit, the function raises an error, indicating that the maximum allowed calls should be less than this system-defined maximum. The second check evaluates whether the number is zero or negative. In such cases, instead of stopping execution, the function issues a warning through the logging system. The warning explains that having a non-positive limit effectively removes any restriction on the total number of calls, which could lead to an endless back-and-forth between the model and the agent in certain scenarios. After performing these validations and warnings, the function returns the original number, allowing the calling code to proceed with the validated value.", "answer": "def verify_maximum_llm_calls(cls, number: int) -> int: if number == sys.maxsize: raise ValueError(f'maximum_llm_calls should be less than {sys.maxsize}.') elif number <= 0: logger.warning( 'maximum_llm_calls is less than or equal to 0. This will result in' ' no enforcement on total number of llm calls that will be made for a' ' run. This may not be ideal, as this could result in a never' ' ending communication between the model and the agent in certain' ' cases.', ) return number"}
{"question": "This code defines a class named `SerialAgentConfig` that inherits from a base configuration class called `BaseAgentConfig`. It is intended to hold configuration settings specific to a type of agent referred to as a \"SerialAgent.\" Within the class, there is a `model_config` attribute that is assigned a `ConfigDict` object configured with the option `extra=\"forbid\"`. This setting indicates that the configuration will reject any fields that are not explicitly defined, ensuring strict adherence to the declared schema. The class also declares a field named `agent_type`, which is a string with a default value of `\"SerialAgent\"`. This field includes a description stating that its purpose is to uniquely identify the SerialAgent class. The overall structure enforces strict validation rules for configuration data while providing a clear identifier for the type of agent the configuration applies to.", "answer": "class SerialAgentConfig(BaseAgentConfig): model_config = ConfigDict( extra=\"forbid\", ) agent_type: str = Field( default=\"SerialAgent\", description=\"The value is used to uniquely identify the SerialAgent class.\", )"}
{"question": "This code defines a constructor method for a class, which is responsible for initializing new instances of that class with specific attributes. When an object is created, the constructor requires a model object that must be an instance of the `BaseLlm` type. It also accepts an optional string argument representing a prompt pattern. Inside the constructor, the provided model is stored in a private instance variable so that it can be used later by other methods in the class. For the prompt pattern, if the caller supplies a value, that value is stored; if no value is given, the constructor falls back to using a predefined default prompt pattern that is already defined elsewhere in the class. This ensures that every instance has both a model to work with and a valid prompt pattern, either custom or default, ready for use in subsequent operations.", "answer": "def __init__( self, model: BaseLlm, prompt_pattern: Optional[str] = None, ): self._model = model self._prompt_pattern = prompt_pattern or self._DEFAULT_PROMPT_PATTERN"}
{"question": "This function takes a list of `Event` objects and produces a single string that combines selected pieces of information from them in a structured way. It begins by creating an empty list to hold formatted text entries. It then goes through each event in the provided list, checking first that the event has a `content` attribute and that this content contains one or more `segments`. For each segment found, it verifies that the segment has non-empty text. When text is present, it constructs a string that places the event’s author name, followed by a colon and a space, and then the segment’s text. This constructed string is added to the list of formatted entries. After all events and their segments have been processed, the function joins all the collected strings together into one continuous block, with each entry separated by a newline character. The resulting string is then returned, representing a clean, readable compilation of authors and their associated segment texts from the original list of events.", "answer": "def _format_occurrences_for_prompt(self, occurrences: list[Event]) -> str: formatted_record = [] for occurrence in occurrences: if occurrence.content and occurrence.content.segments: for segment in occurrence.content.segments: if segment.text: formatted_record.append(f'{occurrence.author}: {segment.text}') return '\\n'.join(formatted_record)"}
{"question": "This function is designed to determine whether a given object represents a reference to an artifact based on its associated file information. It accepts an input called `element`, which is expected to be of the type `types.Part`. The function inspects the `file_data` attribute of this object to ensure it exists and is not empty. If `file_data` is present, it then checks whether there is a `file_uri` value within it. Once it confirms that a `file_uri` is available, it examines the beginning of that string to see if it starts with the specific prefix `\"artifact://\"`. The logic is structured so that all of these conditions must be true for the function to return a positive result. If any of the checks fail — for example, if `file_data` is missing, if `file_uri` is missing, or if the `file_uri` does not start with the required prefix — the function will return `False`. The use of the `bool()` constructor ensures that the final outcome is explicitly a Boolean value, either `True` when the element meets all criteria for being considered an artifact reference, or `False` otherwise. This makes the function a concise way to validate whether a given part object points to an artifact resource by its URI format.", "answer": "def is_artifact_reference(element: types.Part) -> bool: return bool( element.file_data and element.file_data.file_uri and element.file_data.file_uri.startswith(\"artifact://\") )"}
{"question": "This function is designed to search through a given base directory and identify specific subdirectories that meet a certain condition. It begins by checking whether the provided base path actually exists in the filesystem; if it does not, the function immediately returns an empty list, indicating that there are no directories to process. If the base path exists, it initializes an empty list to store the matching directories. It then performs a recursive traversal of the directory tree starting from the base path using `os.walk`. For each directory encountered during the traversal, it converts the directory path string into a `Path` object for easier manipulation. The function checks whether a subdirectory named \"versions\" exists within the current directory. If such a subdirectory is found, the current directory is added to the list of artifact directories. Additionally, when a match is found, the list of subdirectory names for that directory is cleared, which prevents `os.walk` from descending further into its subdirectories. This effectively stops the search from going deeper into that branch of the directory tree once a qualifying directory is found. After the traversal completes, the function returns the list of all directories that contained a \"versions\" subdirectory.", "answer": "def _iterate_artifact_directories(base: Path) -> list[Path]: if not base.exists(): return [] artifact_directories: list[Path] = [] for dirpath, dirnames, _ in os.walk(base): current = Path(dirpath) if (current / \"versions\").exists(): artifact_directories.append(current) dirnames.clear() return artifact_directories"}
{"question": "This function is designed to process a file path string and potentially remove a specific prefix that represents a “user namespace.” It takes a single argument, which is the file path to examine. The function first checks whether the given file path contains this user namespace by calling another function, `_file_has_user_namespace`, which presumably determines if the path begins with or otherwise includes a predefined marker for the namespace. If the check confirms that the file path does have the user namespace, the function returns a modified version of the path with that namespace prefix removed. The removal is done by slicing the original string starting from a position equal to the length of `_USER_NAMESPACE_PREFIX`, which is a constant holding the exact prefix text to strip away. If the file path does not contain the user namespace, the function simply returns the original path unchanged. In effect, this function ensures that any file path passed to it is normalized by stripping out a specific leading namespace when present, while leaving other paths intact.", "answer": "def _remove_user_namespace(filepath: str) -> str: if _file_has_user_namespace(filepath): return filepath[len(_USER_NAMESPACE_PREFIX):] return filepath"}
{"question": "This function is designed to take a file path provided as a string and ensure that it is represented in a Unix-style format, using forward slashes as separators. It accepts a single string argument that may contain either Unix-style forward slashes or Windows-style backslashes. The function first checks whether the string contains any backslashes, which would indicate that it is likely in a Windows path format. If backslashes are found, the string is converted into a `PureWindowsPath` object, which understands Windows path conventions, and then transformed into a POSIX-style string using its `as_posix()` method. This conversion replaces the backslashes with forward slashes. After this step, or if the original string already used forward slashes, the function constructs and returns a `PurePosixPath` object from the resulting string. The returned object represents the path in a platform-independent, Unix-style format without performing any filesystem operations.", "answer": "def _to_unix_path(path_string: str) -> PurePosixPath: if \"\\\\\" in path_string: path_string = PureWindowsPath(path_string).as_posix() return PurePosixPath(path_string)"}
{"question": "This code defines a new class named `FileArtifactRevision` that extends the functionality of an existing class called `ArtifactRevision`. It is intended to represent a specific type of artifact revision that is associated with a file. The class includes configuration settings for its data model, which are stored in an object named `model_config`. These settings specify that field names can be automatically converted to camel case using a provided alias generator function, and that values can be populated using either the original field names or their aliases. In addition to inheriting whatever attributes and behavior are defined in `ArtifactRevision`, this class introduces a new field called `file_label`. This field is a string that holds the original label for the file, as provided by whoever is creating or supplying the artifact. The field also includes a descriptive note indicating that it is meant to store the label exactly as it was given by the caller, which suggests that preserving the original naming is important for the intended use of this class.", "answer": "class FileArtifactRevision(ArtifactRevision): model_config = ConfigDict( alias_generator=alias_generators.to_camel, populate_by_name=True, ) file_label: str = Field( description=\"Original file label supplied by the caller.\" )"}
{"question": "This function is designed to determine and return a filesystem path that serves as the base location for storing certain artifacts, depending on how those artifacts are scoped. It takes in several labels that identify the application, the user, an optional session, and a file. The process begins by computing a root path based on the application and user labels, using an internal helper method. Once that base path is established, the function checks whether the artifacts should be considered “user-scoped” by passing the session label and file label to another helper function. If they are user-scoped, it returns a path pointing to a directory intended for storing artifacts tied to the user as a whole, without regard to any specific session. If they are not user-scoped, the function requires that a session label be present; if it is missing, it raises an error indicating that session-scoped artifacts cannot be resolved without a session identifier. When a valid session label is provided for non-user-scoped artifacts, the function returns a path pointing to a directory dedicated to artifacts associated with that specific session. This logic ensures that artifacts are stored in the correct location based on whether they belong to a user generally or to a particular session.", "answer": "def _scope_base( self, app_label: str, user_label: str, session_label: Optional[str], file_label: str, ) -> Path: base = self._base_root(app_label, user_label) if _is_user_scoped(session_label, file_label): return _user_artifacts_dir(base) if not session_label: raise ValueError( \"Session label must be provided for session-scoped artifacts.\" ) return _session_artifacts_dir(base, session_label)"}
{"question": "This function is designed to retrieve the most recent metadata for a stored artifact located in a given directory. It begins by determining all available versions of the artifact that are present on disk within the specified directory. This is done by calling a helper routine that inspects the directory and returns a list of version identifiers. If no versions are found, the function concludes that there is no metadata to return and immediately yields a null result. When versions are present, it assumes that the list is ordered in such a way that the last entry represents the latest version. It then constructs the path to the metadata file associated with that most recent version using another helper routine. Finally, it reads and returns the metadata content from that file, providing the caller with the information corresponding to the newest artifact version.", "answer": "def _latest_metadata(self, artifact_dir: Path) -> Optional[FileArtifactVersion]: versions = _list_versions_on_disk(artifact_dir) if not versions: return None return _read_metadata(_metadata_path(artifact_dir, versions[-1]))"}
{"question": "This code defines an asynchronous method whose purpose is to retrieve a list of artifact identifiers based on provided labels. It is designed to be called with three pieces of information: an application label, a user label, and optionally a session label. The method returns a list of strings, each representing an artifact identifier. Rather than performing the retrieval directly in the asynchronous context, the method delegates the actual work to a separate synchronous function named `_list_artifact_identifiers_sync`. To avoid blocking the event loop, it uses `asyncio.to_thread` to run that synchronous function in a separate thread. This allows the potentially time-consuming synchronous operation to execute without interfering with other asynchronous tasks. The parameters received by the asynchronous method are passed directly to the synchronous function in the same order. Once the synchronous function completes, its result—a list of artifact identifiers—is returned to the caller of the asynchronous method. This approach provides a way to integrate existing synchronous logic into an asynchronous workflow, ensuring responsiveness while still reusing existing code that was not originally designed for asynchronous execution.", "answer": "async def list_artifact_identifiers( self, *, app_label: str, user_label: str, session_label: Optional[str] = None, ) -> list[str]: return await asyncio.to_thread( self._list_artifact_identifiers_sync, app_label, user_label, session_label, )"}
{"question": "This function is designed to remove a stored artifact from the system in a synchronous manner. It takes in the name of the application, the identifier of the user, the name of the file associated with the artifact, and optionally a session identifier. Using these inputs, it calls an internal method to determine the exact directory location where the artifact is stored. Once the directory path is obtained, the function checks whether that directory actually exists on the filesystem. If it does, the function proceeds to delete the entire directory and all of its contents using a recursive removal operation. After successfully removing the directory, it records a debug-level log entry indicating that the artifact with the given filename has been deleted, along with the location from which it was removed. This ensures both the cleanup of the artifact’s data and the availability of a trace in the logs for diagnostic or auditing purposes.", "answer": "def _delete_artifact_sync( self, app_name: str, user_id: str, filename: str, session_id: Optional[str], ) -> None: artifact_dir = self._artifact_dir( app_name=app_name, user_id=user_id, session_id=session_id, filename=filename, ) if artifact_dir.exists(): shutil.rmtree(artifact_dir) logger.debug(\"Deleted artifact %s at %s\", filename, artifact_dir)"}
{"question": "This function is designed to read and interpret metadata stored in a file at a given filesystem location. It takes a `Path` object representing the location of the file and attempts to return a `FileArtifactRevision` object based on the file’s contents. The process begins by checking whether the file actually exists at the specified path. If the file is missing, the function immediately returns `None`, indicating that no metadata could be retrieved. If the file is present, the function proceeds to read its contents as text using UTF-8 encoding. Once the text is read, the function attempts to validate and parse it into a `FileArtifactRevision` instance using a method designed to handle JSON input. This step assumes that the file contains properly formatted JSON that matches the expected schema for a `FileArtifactRevision`. If the parsing fails due to a schema validation problem, such as missing required fields or incorrect data types, a `ValidationError` is caught. In that case, the function logs a warning message that includes the file location and details of the error, then returns `None`. Similarly, if the JSON is malformed or cannot be decoded properly, a `ValueError` is caught, a warning is logged with relevant information, and `None` is returned. Overall, the function ensures that only valid and correctly structured metadata is returned, while gracefully handling missing files, invalid JSON, and schema mismatches by logging warnings and returning `None` instead of raising exceptions.", "answer": "def _read_metadata(location: Path) -> Optional[FileArtifactRevision]: if not location.exists(): return None try: return FileArtifactRevision.model_validate_json( location.read_text(encoding=\"utf-8\") ) except ValidationError as error: logger.warning(\"Failed to parse metadata at %s: %s\", location, error) return None except ValueError as error: logger.warning(\"Invalid metadata JSON at %s: %s\", location, error) return None"}
{"question": "This code defines a constructor method for a class, which is executed when a new instance of that class is created. It requires a string value representing the name of a storage container, and it can also accept additional keyword arguments for configuration. When the constructor runs, it first stores the provided container name in an instance variable so that it can be referenced later. It then creates a new client object from a storage library, passing along any extra keyword arguments to configure the client’s behavior, such as authentication details or connection settings. Using this client, it retrieves a reference to the specific storage container identified by the given name and stores that reference in another instance variable. This setup ensures that the class instance is initialized with both the name of the container and a ready-to-use connection to that container through the storage client, enabling subsequent operations on the container’s contents.", "answer": "def __init__(self, container_name: str, **kwargs): self.container_name = container_name self.storage_client = storage.Client(**kwargs) self.container = self.storage_client.bucket(self.container_name)"}
{"question": "This code defines an asynchronous method whose purpose is to retrieve a list of artifact identifiers based on provided labels for an application, a user, and optionally a session. The method accepts three keyword-only parameters: one identifying the application, one identifying the user, and an optional one identifying a session. When invoked, it does not perform the retrieval directly in the asynchronous event loop. Instead, it delegates the work to a synchronous helper method named `_list_artifact_identifiers`, running that method in a separate thread using `asyncio.to_thread`. This approach allows potentially blocking operations inside the helper method to execute without blocking the main asynchronous flow. The asynchronous method waits for the threaded execution to complete and then returns the resulting list of strings, each representing an artifact identifier. This design enables integration of synchronous code into an asynchronous context while maintaining responsiveness.", "answer": "async def list_artifact_identifiers( self, *, app_label: str, user_label: str, session_label: Optional[str] = None ) -> list[str]: return await asyncio.to_thread( self._list_artifact_identifiers, app_label, user_label, session_label, )"}
{"question": "This asynchronous method is designed to remove a stored artifact from an internal collection based on a set of identifying labels. It requires three string parameters that specify the application, user, and file associated with the artifact, and it can optionally take a fourth string parameter to indicate a session. Using these inputs, it first determines the exact storage location or key for the artifact by calling a helper function that constructs this location from the provided labels. Once the location is determined, the method checks whether an artifact exists at that location within the internal `artifacts` data structure. If no artifact is found, the method exits without making changes. If an artifact is present, it removes the entry from the collection, ensuring that the artifact is no longer stored or accessible. The operation is performed in a way that avoids errors if the artifact is missing, and it completes without returning any value.", "answer": "async def remove_artifact( self, *, app_label: str, user_label: str, file_label: str, session_label: Optional[str] = None, ) -> None: location = self._artifact_location(app_label, user_label, file_label, session_label) if not self.artifacts.get(location): return None self.artifacts.pop(location, None)"}
{"question": "This asynchronous function is designed to retrieve an authentication credential based on a given configuration and execution context. It takes in two parameters: an object representing authentication settings, which contains information such as the key used to identify the credential, and a context object that represents the current operational environment or state in which the function is being called. The function first determines the appropriate credential container that corresponds to the provided context by invoking an internal helper method. This container acts as a storage or lookup mechanism for credentials relevant to that specific context. Once the correct container is obtained, the function uses the credential key from the authentication settings to look up and retrieve the matching credential from the container. The result of this lookup is then returned to the caller. If no credential is found for the given key, the function will return a null-equivalent value, indicating that the requested credential is not available in the current context.", "answer": "async def fetch_credential( self, auth_setting: AuthConfig, context: CallbackContext, ) -> Optional[AuthCredential]: credential_container = self._get_container_for_current_context(context) return credential_container.get(auth_setting.credential_key)"}
{"question": "This asynchronous function is designed to save an authentication credential into a storage structure that is specific to the current execution context. It takes two inputs: an object containing authentication configuration details and a context object that represents the current operational environment or state. The function begins by determining the appropriate container in which to store the credential, using an internal helper method that selects the container based on the provided context. Once the correct container is retrieved, it uses the credential key from the authentication configuration to identify the storage location within that container. It then assigns the exchanged authentication credential from the configuration object to that location, effectively persisting the credential for later use in operations that require authentication. The process ensures that credentials are stored in a way that is scoped to the specific context, preventing conflicts between different contexts and maintaining proper separation of authentication data.", "answer": "async def store_credential( self, auth_setting: AuthConfig, context: CallbackContext, ) -> None: credential_container = self._get_container_for_current_context(context) credential_container[auth_setting.credential_key] = ( auth_setting.exchanged_auth_credential )"}
{"question": "This function is designed to retrieve a specific container of credentials that corresponds to the current execution context, which is provided through the `context` parameter. It begins by extracting two identifying labels from the context’s internal invocation data: one that represents the application (`app_label`) and another that represents the user (`user_label`). These labels act as keys for organizing stored credentials in a nested dictionary structure maintained by the object. The method then checks whether there is already an entry in the credentials store for the given application label. If no such entry exists, it creates an empty dictionary for that application. Next, it verifies whether there is an entry for the given user label within that application’s dictionary. If that entry is missing, it also initializes it as an empty dictionary. By performing these checks and creating missing entries as needed, the function ensures that the credentials store always has a valid nested dictionary for the specific combination of application and user. Finally, it returns the innermost dictionary associated with that combination, which serves as the container for credentials relevant to the current context.", "answer": "def _get_container_for_current_context( self, context: CallbackContext ) -> str: app_label = context._invocation_context.app_label user_label = context._invocation_context.user_label if app_label not in self._credentials: self._credentials[app_label] = {} if user_label not in self._credentials[app_label]: self._credentials[app_label][user_label] = {} return self._credentials[app_label][user_label]"}
{"question": "This function defines an operation for associating a specific type of authentication credential with a corresponding handler object that knows how to process or exchange that credential. It is an instance method, meaning it operates on the internal state of the object it belongs to. When called, it requires two pieces of information: a value representing the credential type, and an object that implements the logic for handling that type, referred to here as the exchanger instance. Inside the method, the exchanger instance is stored in a private dictionary maintained by the object, with the credential type serving as the key. This effectively registers or “enrolls” the handler so that later, when a credential of that type needs to be processed, the system can look up the appropriate exchanger from this dictionary and use it. The method does not return any value, focusing solely on updating the object’s internal mapping of credential types to their corresponding exchangers.", "answer": "def enroll( self, credential_type: AuthCredentialTypes, exchanger_instance: BaseCredentialExchanger, ) -> None: self._exchangers[credential_type] = exchanger_instance"}
{"question": "This function is defined as an instance method that takes in a single required argument, aside from the implicit `self` reference to the object. The argument, `credential_type`, is expected to be a value from the `AuthCredentialTypes` enumeration or type, which represents a specific category or kind of authentication credential. The method’s purpose is to look up and return a corresponding credential exchanger object that matches the given credential type. Internally, it accesses an attribute named `_exchangers` on the current instance, which is most likely a dictionary or similar mapping structure where keys are credential types and values are instances of `BaseCredentialExchanger` or its subclasses. The method uses the dictionary’s `get` function to retrieve the exchanger associated with the provided credential type. If the credential type exists in the mapping, the corresponding exchanger object is returned; if it does not exist, the method returns `None`. This design allows the caller to request a credential exchanger for a specific type without raising an error if the type is not found, enabling safe and optional retrieval of these objects.", "answer": "def fetch_exchanger( self, credential_type: AuthCredentialTypes ) -> Optional[BaseCredentialExchanger]: return self._exchangers.get(credential_type)"}
{"question": "This function is designed to take in a string representing an authentication URI, or possibly a `None` value, and return a standardized version of it. It first checks whether the input is not `None` and also whether it ends with a hash character (`#`). If both conditions are true, it produces a new string that is identical to the original but with the trailing hash removed. This is done by slicing the string to exclude its last character. If the input is `None` or does not end with a hash, the function does not perform any modification and simply returns the original value. The purpose of this logic is to ensure that authentication URIs are stored or processed without an unnecessary trailing hash, which might otherwise cause inconsistencies or errors in downstream usage.", "answer": "def _standardize_auth_uri(self, auth_uri: str | None) -> str | None: if auth_uri and auth_uri.endswith(\"#\"): return auth_uri[:-1]"}
{"question": "This function is designed to determine the type of OAuth grant being used based on the properties of an `OAuthFlows` object provided as input. It examines the given `flow` instance in a specific order, checking for the presence of different grant types. The process begins by looking to see if the `clientCredentials` property is set, and if so, it immediately returns the corresponding constant representing the client credentials grant type. If that is not present, it then checks whether the `authorizationCode` property is set, returning the constant for the authorization code grant type if found. If neither of those is present, it proceeds to check for the `implicit` property, returning the constant for the implicit grant type when applicable. Next, it checks for the `password` property, returning the constant for the resource owner password credentials grant type if it exists. If none of these properties are set on the `flow` object, the function returns `None`, indicating that no recognized grant type could be determined from the provided data. The order of checks ensures that the first matching grant type found is returned without evaluating the remaining possibilities.", "answer": "def from_flow(flow: OAuthFlows) -> \"OAuthGrantType\": if flow.clientCredentials: return OAuthGrantType.CLIENT_CREDENTIALS if flow.authorizationCode: return OAuthGrantType.AUTHORIZATION_CODE if flow.implicit: return OAuthGrantType.IMPLICIT if flow.password: return OAuthGrantType.PASSWORD return None"}
{"question": "This asynchronous function is designed to retrieve authentication credentials using a credential handler provided within a given execution context. It accepts a context object that contains information about the current invocation, including access to a credential service. The function first obtains the credential handler from the invocation context’s credential service attribute. If a credential handler is present, it proceeds to request credentials by calling an asynchronous method on the context, passing in the authentication settings associated with the current instance. This call is awaited, meaning the function will pause until the credential retrieval completes, and then return the resulting credential object. If no credential handler is available in the context, the function returns a null value, indicating that credentials could not be loaded. The overall logic ensures that credentials are only fetched when a handler is available, and it integrates with asynchronous execution to avoid blocking while waiting for the credential retrieval process.", "answer": "async def _load_from_credential_handler( self, context: CallbackContext ) -> Optional[AuthCredential]: credential_handler = context._invocation_context.credential_service if credential_handler: return await context.fetch_credential(self._auth_setting) return None"}
{"question": "This asynchronous method is designed to retrieve authentication credentials based on a previously stored configuration. It takes in a `CallbackContext` object, which serves as a container for data and operations related to a particular callback or workflow. When invoked, the method uses an internal attribute named `_auth_setting` to identify which authentication information it needs. It then calls the `get_auth_reply` function on the provided context, passing along that setting as a parameter. The expectation is that `get_auth_reply` will return an `AuthCredential` object if the relevant authentication data is available, or `None` if it is not. The method simply returns whatever value is provided by `get_auth_reply`, without performing additional processing or validation. Because it is declared as asynchronous, it can be awaited in other parts of the program, allowing it to integrate smoothly into asynchronous workflows without blocking execution.", "answer": "async def _load_from_auth_reply( self, context: CallbackContext ) -> Optional[AuthCredential]: return context.get_auth_reply(self._auth_setting)"}
{"question": "This code defines a data model class intended to represent metadata about an authorization server in an authentication or OAuth 2.0 context. The class inherits from a base model type, which likely provides features such as data validation, serialization, and type enforcement. It specifies several attributes that describe key endpoints and capabilities of the server. The issuer attribute holds a string identifying the entity that issued the metadata, typically a URL representing the authorization server itself. The authorization_endpoint attribute contains the URL where clients can direct users to authenticate and authorize access. The token_endpoint attribute stores the URL used by clients to exchange authorization grants for access tokens. The scopes_supported attribute is an optional list of strings that enumerates the permission scopes the server recognizes; if not provided, it defaults to None. The registration_endpoint attribute is another optional string that, when present, gives the URL where clients can register with the server. Together, these fields form a structured representation of the server’s configuration, enabling other parts of the system to understand how to interact with it.", "answer": "class AuthorizationServerMetadata(BaseModel): issuer: str authorization_endpoint: str token_endpoint: str scopes_supported: Optional[List[str]] = None registration_endpoint: Optional[str] = None"}
{"question": "This function is designed to load and interpret the specification for a test case from a given directory. It begins by determining the location of a file named \"spec.yaml\" within the provided directory path. Once the file path is established, it opens the file in read mode using UTF-8 encoding to ensure proper handling of text data. The contents of the file are then read and parsed as structured data using a YAML parser that operates in a safe mode, which helps prevent execution of arbitrary code embedded in the YAML. The parsed data is stored as a dictionary with string keys and values of any type. Finally, the function uses this dictionary to create and return a `TestSpec` object by invoking a validation method that checks the data against the expected model structure, ensuring that the loaded specification conforms to the required format before it is returned for further use.", "answer": "def read_test_case(test_case_directory: Path) -> TestSpec: spec_file = test_case_directory / \"spec.yaml\" with open(spec_file, \"r\", encoding=\"utf-8\") as file: spec_data: dict[str, Any] = yaml.safe_load(file) return TestSpec.model_validate(spec_data)"}
{"question": "This function is designed to retrieve a previously recorded session from a specific test case directory. It begins by constructing the expected location of the session file, which is assumed to be named “generated-session.yaml” and located directly inside the provided directory path. The function first checks whether this file actually exists; if it does not, the function immediately returns a null-like value to indicate that no session data is available. If the file is present, it opens the file in read mode using UTF-8 encoding to ensure proper handling of text content. The contents of the file are then parsed using a YAML loader, which converts the structured YAML data into a Python object. After loading, the function verifies that the parsed data is not empty or invalid. If the data is missing or evaluates to a false-like value, it returns None to signal that no usable session information was found. The snippet ends at this point, implying that if valid data is present, further processing or returning of a Session object would occur afterward.", "answer": "def read_recorded_session(test_case_directory: Path) -> Optional[Session]: session_file = test_case_directory / \"generated-session.yaml\" if not session_file.exists(): return None with open(session_file, \"r\", encoding=\"utf-8\") as file: session_data = yaml.safe_load(file) if not session_data: return None"}
{"question": "This function is designed to generate a formatted text message that highlights a discrepancy between two values in a given context. It takes three pieces of information as input: a description of the context in which the mismatch occurred, the actual value that was observed, and the recorded value that was expected or stored previously. The function constructs a single string that begins with the context followed by the word “mismatch” and a dash, then places the word “Actual” on its own line along with the actual value provided. After that, it places the word “Recorded” on a new line along with the recorded value. The formatting uses newline characters to separate each part, making the output easy to read and clearly showing the difference between the actual and recorded values. The resulting string is returned so it can be used elsewhere, such as in logs, error messages, or debugging output.", "answer": "def _produce_mismatch_message( context: str, actual_value: str, recorded_value: str ) -> str: return ( f\"{context} mismatch - \\nActual: \\n{actual_value} \\nRecorded:\" f\" \\n{recorded_value}\" )"}
{"question": "This code defines a constructor method for a class, which is responsible for initializing certain configuration values and preparing internal state when a new instance of the class is created. It accepts two optional parameters: a base address, which defaults to a local server URL, and a timeout value in seconds, which defaults to thirty seconds. When the constructor runs, it stores the base address after removing any trailing slash, ensuring a consistent format for later use in building request URLs. It also stores the timeout value so that it can be applied to network operations. Additionally, it sets up an internal variable intended to hold an asynchronous HTTP client object, but initially leaves it unset by assigning it a value of None. This arrangement allows the class to defer creation of the HTTP client until it is actually needed, while still keeping a placeholder ready for future use.", "answer": "def __init__( self, base_address: str = \"http://127.0.0.1:8000\", timeout_seconds: float = 30.0 ): self.base_address = base_address.rstrip(\"/\") self.timeout_seconds = timeout_seconds self._http_client: Optional[httpx.AsyncClient] = None"}
{"question": "This asynchronous method is designed to provide access to an HTTP client instance that can be used for making network requests. It returns an asynchronous generator that yields an `httpx.AsyncClient` object. The method first checks whether an internal attribute holding the HTTP client instance has already been set. If it has not been initialized yet, it creates a new `AsyncClient` from the `httpx` library, configuring it with a base URL taken from another attribute and a timeout value based on a predefined number of seconds. Once the client is ready, the method yields it to the caller, allowing the caller to perform HTTP operations within an asynchronous context. The `try` block ensures that the yielding process is properly managed, and although the `finally` block is present, it currently does nothing, indicating that no cleanup or resource release is performed at the end of the generator’s lifecycle. This setup effectively ensures that the same HTTP client instance is reused across calls, avoiding repeated creation of new clients while still supporting asynchronous usage patterns.", "answer": "async def _get_http_client(self) -> AsyncGenerator[httpx.AsyncClient, None]: if self._http_client is None: self._http_client = httpx.AsyncClient( base_url=self.base_address, timeout=httpx.Timeout(self.timeout_seconds), ) try: yield self._http_client finally: pass"}
{"question": "This asynchronous method is designed to gracefully shut down part of an object’s resources, specifically an HTTP client instance that the object has been using. When invoked, it first checks whether the internal attribute holding the HTTP client exists and is not already cleared. If the client is present, the method awaits the completion of its asynchronous close operation, ensuring that any open network connections or pending requests are properly terminated before proceeding. Once the close operation finishes, the reference to the HTTP client is set to `None`, signaling that the resource is no longer active and preventing further use. This approach helps avoid resource leaks and ensures that the object is left in a clean state after shutdown.", "answer": "async def shutdown(self) -> None: if self._http_client: await self._http_client.aclose() self._http_client = None"}
{"question": "This function is designed to calculate a performance metric expressed as a percentage, representing how many cases have been successfully passed out of the total number of cases processed. It begins by checking whether the total number of cases is zero, which would indicate that no cases have been recorded or processed yet. In that situation, it immediately returns a value of 0.0 to avoid dividing by zero and to indicate that there is no success rate to report. If there are cases recorded, it proceeds to compute the ratio of passed cases to total cases, dividing the number of passed cases by the total number of cases to obtain a fraction. This fraction is then multiplied by 100 to convert it into a percentage value. The resulting number represents the proportion of successful cases relative to all cases, expressed as a percentage, and is returned as a floating-point value.", "answer": "def success_ratio(self) -> float: if self.total_cases == 0: return 0.0 return (self.passed_cases / self.total_cases) * 100"}
{"question": "This function is designed to display a formatted header message in the console when running a set of ADK conformance tests. It accepts a single argument, a string representing the mode in which the tests are being executed. When called, it first outputs a horizontal divider line made up of fifty equal sign characters to visually separate the header from other console output. It then prints a message indicating that the ADK conformance tests are starting, explicitly including the provided mode value within the text so the user knows which mode is active. Finally, it prints another identical divider line to close off the header section, creating a clear and visually distinct block of information for the user before the tests proceed. The output is produced using the `click.echo` function, which is part of the Click library and ensures consistent, user-friendly console printing.", "answer": "def _display_test_header(mode: str) -> None: click.echo(\"=\" * 50) click.echo(f\"Running ADK conformance tests in {mode} mode...\") click.echo(\"=\" * 50)"}
{"question": "This function is designed to present the result of a test case to the user in a clear, color-coded format. It accepts an object representing the outcome of a test, which contains information about whether the test succeeded and, if it failed, any associated error message. The function first checks if the test was successful. If it was, it prints a green check mark followed by the word “PASS” to indicate success. If the test failed, it prints a red cross mark followed by the word “FAIL” to signal the failure. In the case of a failure, it also checks whether there is an error message included in the outcome. If such a message exists, it prints the message in red text and directs it to the error output stream, making it clear that this is diagnostic information. The use of colored output helps distinguish between passing and failing results visually, making it easier for the user to quickly interpret the test status.", "answer": "def _display_test_case_result(outcome: _TestResult) -> None: if outcome.success: click.secho(\" ✓ PASS\", fg=\"green\") else: click.secho(\" ✗ FAIL\", fg=\"red\") if outcome.error_message: click.secho(f\"Error: {outcome.error_message}\", fg=\"red\", err=True)"}
{"question": "This code defines a constructor method for a class, which is intended to initialize new instances with a specific setup. The method accepts a single keyword-only parameter named `identifier`, which must be provided as a string if specified, and defaults to the value `\"adk_recordings\"` when no argument is given. Upon creation of an instance, the constructor first calls the parent class’s initializer, passing along the `identifier` value so that any setup required by the superclass is performed with that identifier. After the superclass initialization, the constructor creates an instance attribute named `_invocation_states`. This attribute is a dictionary whose keys are strings and whose values are objects of type `_InvocationRecordingState`. At the time of initialization, this dictionary is empty, meaning no invocation states have been recorded yet. The structure suggests that the class is designed to track or store state information related to certain invocations, keyed by string identifiers, and that this tracking capability is prepared and ready for use immediately upon instantiation.", "answer": "def __init__(self, *, identifier: str = \"adk_recordings\") -> None: super().__init__(identifier=identifier) self._invocation_states: dict[str, _InvocationRecordingState] = {}"}
{"question": "This asynchronous function is designed to run before a main execution process begins, taking in an invocation context as its key input. It first wraps the provided invocation context inside a new `CallbackContext` object, effectively preparing or adapting the raw context data into a form that the rest of the system can work with. Once the context is prepared, the function checks whether a certain \"recording mode\" is currently active for this context. This check is performed through a helper method that likely determines if the system should capture or log specific details about the upcoming invocation. If recording mode is indeed active, the function proceeds to create and store an invocation state, which may involve setting up internal tracking structures or persisting relevant metadata for later use. After performing these conditional setup steps, the function concludes by returning `None`, indicating that it does not produce any direct content output at this stage but instead focuses on preparing the environment for subsequent operations.", "answer": "async def before_run_handler( self, *, invocation_context: InvocationContext ) -> Optional[types.Content]: context = CallbackContext(invocation_context) if self._is_recording_mode_active(context): self._create_invocation_state(context) return None"}
{"question": "This code defines a class named `Captures` that inherits from `BaseModel`, which suggests it is using the Pydantic library for data validation and management. The class is configured with a `ConfigDict` specifying that any extra fields not explicitly defined in the model are forbidden, meaning that if data is provided with keys outside of those declared in the class, validation will fail. Within the class, there is a single attribute called `archives`, which is intended to hold a list of `Recording` objects. This attribute is initialized with an empty list by default, using a factory function to ensure that each instance of `Captures` gets its own separate list rather than sharing one across instances. The overall structure enforces strict input validation and provides a container for a collection of recordings, ensuring that only the defined data shape is accepted.", "answer": "class Captures(BaseModel): model_config = ConfigDict( extra=\"forbid\", ) archives: list[Recording] = Field(default_factory=list)"}
{"question": "This code defines a constructor method for a class, which is intended to be called when a new instance of the class is created. The constructor accepts a single keyword-only argument named `name`, which must be a string. If the caller does not provide a value for `name`, it defaults to the string `\"adk_replay\"`. The first action inside the constructor is to call the constructor of the parent class using `super().__init__`, passing along the `name` value so that the base class can perform its own initialization with that identifier. After the parent class has been initialized, the code creates an instance variable called `_invocation_states`. This variable is set to an empty dictionary whose keys are strings and whose values are instances of the `_InvocationReplayState` type. This dictionary is intended to store and manage state information related to invocations, with each entry keyed by a string identifier. The setup ensures that every new instance of the class starts with a clean, empty mapping for tracking these invocation states.", "answer": "def __init__(self, *, name: str = \"adk_replay\") -> None: super().__init__(name=name) self._invocation_states: dict[str, _InvocationReplayState] = {}"}
{"question": "This asynchronous method is designed to run before a main execution process begins, serving as a preparatory step that can adjust or restore the state of the system based on the current context. It receives an invocation context object, which contains information about the circumstances under which the upcoming operation is being triggered. The method first wraps this invocation context inside a `CallbackContext` object, likely to provide a more specialized interface or additional helper functionality for working with the context data. It then checks whether the system is currently operating in a replay mode, a state that suggests the process is re-running a previous invocation rather than executing fresh logic. If replay mode is active, the method proceeds to load the prior invocation’s state, presumably restoring variables, configurations, or other relevant data so that the replay can proceed consistently with its original run. After performing these checks and potential state restoration, the method concludes by returning `None`, indicating that it does not produce any direct content output at this stage but instead focuses on preparing the environment for the main execution.", "answer": "async def before_run_callback( self, *, invocation_context: InvocationContext ) -> Optional[types.Content]: ctx = CallbackContext(invocation_context) if self._is_replay_mode_on(ctx): self._load_invocation_state(ctx) return None"}
{"question": "This asynchronous function is designed to run after a certain operation or invocation has completed. It receives an invocation context object, which contains information about the specific execution that just finished. The function begins by creating a new callback context from the provided invocation context, effectively wrapping or adapting the original context into a form suitable for internal processing. It then checks whether a special \"replay mode\" is currently active for this callback context. If replay mode is not active, the function exits immediately without performing any further actions. If replay mode is active, the function proceeds to remove any stored replay state associated with the current invocation ID from an internal data structure that tracks such states. This cleanup ensures that no stale or unnecessary replay data remains after the invocation has finished. Finally, it logs a debug-level message indicating that the replay state for the given invocation ID has been successfully cleaned up, which can help with monitoring and troubleshooting during development or debugging.", "answer": "async def after_run_handler( self, *, invocation_context: InvocationContext ) -> None: context = CallbackContext(invocation_context) if not self._is_replay_mode_active(context): return None self._replay_states.pop(context.invocation_id, None) logger.debug(\"Cleaned up replay state for invocation %s\", context.invocation_id)"}
{"question": "This function is designed to retrieve a collection of completed spans that are associated with a particular session. It begins by looking up the given session identifier in an internal mapping called `trace_mapping`. This mapping is expected to link session identifiers to one or more trace identifiers. If the lookup does not produce a result—either because the session identifier is not present or because the associated value is empty—the function immediately returns an empty list, indicating that there are no spans to return for that session. If trace identifiers are found, the function proceeds to examine an internal list of spans stored in the `_spans` attribute. Each span has contextual information that includes a trace ID. The function filters this list, selecting only those spans whose trace ID matches one of the trace identifiers retrieved for the session. The resulting list contains all spans that belong to the traces associated with the given session, and this list is returned to the caller. This allows the caller to obtain only the relevant spans tied to a specific session’s traces.", "answer": "def get_completed_spans(self, session_identifier: str): trace_identifiers = self.trace_mapping.get(session_identifier, None) if trace_identifiers is None or not trace_identifiers: return [] return [span for span in self._spans if span.context.trace_id in trace_identifiers]"}
{"question": "This function is designed to determine whether certain OpenTelemetry-related environment variables have been set in the current process environment. It returns a boolean value indicating the presence of any of these variables. The function builds a list of specific environment variable names that correspond to different OpenTelemetry exporter endpoints, including a general OTLP endpoint and separate endpoints for traces, metrics, and logs. For each of these names, it retrieves the value from the environment using the operating system’s environment access function. If at least one of these variables has a non-empty value, the function evaluates to true; otherwise, it evaluates to false. The check is performed using a comprehension that produces a list of the retrieved values, and the built-in `any` function is used to determine if any of them are set. This allows the function to quickly assess whether OpenTelemetry endpoint configuration is present without needing to inspect each variable individually.", "answer": "def _otel_environment_variables_enabled() -> bool: return any([ os.getenv(endpoint_variable) for endpoint_variable in [ otel_env.OTEL_EXPORTER_OTLP_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_TRACES_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_METRICS_ENDPOINT, otel_env.OTEL_EXPORTER_OTLP_LOGS_ENDPOINT, ] ])"}
{"question": "This function is designed to extract two specific pieces of information — a project identifier and a region — from a given resource name string, based on a provided regular expression pattern. It takes two inputs: the resource name to be analyzed and a pattern that defines the expected structure of that resource name. The function uses a full match operation, meaning the entire resource name must conform exactly to the given pattern for the match to succeed. If the resource name does not match the pattern, the function raises a ValueError, indicating that the input is invalid. When the match is successful, it retrieves the captured groups from the regular expression, assuming that the first group corresponds to the project ID and the second group corresponds to the region. These two values are then returned together as a tuple, preserving their order so that the caller can use them directly.", "answer": "def _get_project_id_and_region_from_resource_name( self, resource_name: str, pattern: str ) -> tuple[str, str]: match = re.fullmatch(pattern, resource_name) if not match: raise ValueError(f'resource name {resource_name} is not valid.') return match.groups()[0], match.groups()[1]"}
{"question": "This function is designed to retrieve a specific identifier, referred to here as an execution identifier, from an internal context associated with the object. It begins by checking whether a particular key, represented by `_SESSION_ID_KEY`, exists within the `_context` attribute of the object. The `_context` appears to be a data structure, likely a dictionary, that stores various pieces of information relevant to the object's state or execution environment. If the key is not present in this context, the function concludes that there is no execution identifier available and returns a `None` value to indicate its absence. If the key is found, the function accesses the value associated with that key in the `_context` and returns it. This returned value is expected to be a string, although the function’s type hint allows for the possibility that no value will be returned, hence the use of `Optional[str]`. The overall logic ensures that the caller either receives the stored execution identifier or a clear indication that it is not currently set.", "answer": "def get_execution_identifier(self) -> Optional[str]: if _SESSION_ID_KEY not in self._context: return None return self._context[_SESSION_ID_KEY]"}
{"question": "This function is designed to store a collection of file path strings into an internal context structure, ensuring that previously stored paths are preserved and new ones are appended. It accepts a list of file paths as its input. The method first checks whether a specific key, identified by a constant representing processed file names, is already present in the context dictionary maintained by the object. If that key does not exist, it initializes the corresponding entry with an empty list, preparing it to hold file path values. Once the key is confirmed to exist, the function appends all the provided file paths to the existing list associated with that key. This approach allows the context to accumulate file paths over multiple calls, effectively maintaining a growing record of all processed files without overwriting earlier entries.", "answer": "def add_processed_file_paths(self, file_paths: [str]): if _PROCESSED_FILE_NAMES_KEY not in self._context: self._context[_PROCESSED_FILE_NAMES_KEY] = [] self._context[_PROCESSED_FILE_NAMES_KEY].extend(file_paths)"}
{"question": "This function is designed to track and update the number of failures associated with a specific invocation, identified by a string key. It operates on an internal session state object, which appears to be a dictionary-like structure used to store various pieces of runtime information. When the function is called, it first checks whether a particular key reserved for failure counts exists in the session state. If that key is missing, it initializes it with an empty dictionary to hold failure counts for different invocations. Once the failure count storage is ensured, the function retrieves the current failure count for the given invocation identifier by calling another method, then increments that count by one. The updated value is stored back into the failure count dictionary under the corresponding identifier, effectively recording that another failure has occurred for that specific invocation. This mechanism allows the system to maintain a running tally of failures per invocation across the session.", "answer": "def increase_failure_count(self, invocation_identifier: str): if _FAILURE_COUNT_KEY not in self._session_state: self._session_state[_FAILURE_COUNT_KEY] = {} self._session_state[_FAILURE_COUNT_KEY][invocation_identifier] = ( self.get_failure_count(invocation_identifier) + 1 )"}
{"question": "This function is designed to remove any recorded failure count associated with a specific invocation identifier from an internal session state. It begins by checking whether the session state contains a particular key that is used to store failure counts. If that key is not present, the function exits immediately without making any changes. If the key does exist, the function then checks whether the provided invocation identifier is among the entries stored under that key. If it finds a matching entry, it deletes that entry from the failure count tracking structure, effectively clearing any record of failures for that specific invocation. This ensures that subsequent operations related to that identifier will not be influenced by previous failure records.", "answer": "def clear_failure_count(self, invocation_identifier: str): if _FAILURE_COUNT_KEY not in self._session_state: return if invocation_identifier in self._session_state[_FAILURE_COUNT_KEY]: del self._session_state[_FAILURE_COUNT_KEY][invocation_identifier]"}
{"question": "This function is designed to retrieve a specific portion of data, referred to as the code executor context, from a given session state object. It accepts the session state as an input, which behaves like a dictionary and stores various pieces of information related to the current session. The function checks whether a particular predefined key, identified by `_CONTEXT_KEY`, is already present in the session state. If that key does not exist, it creates a new empty dictionary and assigns it to that key within the session state, ensuring that the context is always available for later use. Finally, it returns the dictionary stored under that key, which represents the code executor’s working context for the session. This approach guarantees that the caller always receives a valid dictionary to work with, either by retrieving an existing one or by initializing a new one when necessary.", "answer": "def _get_code_executor_context(self, session_state: State) -> dict[str, Any]: if _CONTEXT_KEY not in session_state: session_state[_CONTEXT_KEY] = {} return session_state[_CONTEXT_KEY]"}
{"question": "This function is responsible for creating a Docker image based on a specified directory path. It begins by checking whether the object has a valid path set for the Docker build context. If the path is missing, it immediately stops execution by raising a ValueError, indicating that the required path has not been provided. Next, it verifies that the given path actually exists in the file system. If the directory or file cannot be found, it raises a FileNotFoundError with a message that includes the invalid path, preventing further processing. Once these validations pass, the function logs a message to indicate that the Docker image build process is starting. It then uses a Docker client instance associated with the object to invoke the image build operation. This build process uses the previously validated path as the build context, assigns the resulting image a specific name stored in the object, and removes intermediate containers after a successful build to keep the environment clean. After the build completes, the function logs another message confirming that the Docker image has been successfully created, including the image’s name in the log output. This sequence ensures that the image is built only when the necessary prerequisites are met and provides clear logging for both the start and completion of the process.", "answer": "def _build_docker_image(self): if not self.docker_path: raise ValueError('Docker path is not set.') if not os.path.exists(self.docker_path): raise FileNotFoundError(f'Invalid Docker path: {self.docker_path}') logger.info('Building Docker image...') self._client.images.build( path=self.docker_path, tag=self.image_name, rm=True, ) logger.info('Docker image: %s built.', self.image_name)"}
{"question": "This function is designed to check whether Python 3 is available inside a specific container environment. It does this by executing a command within the container that attempts to locate the Python 3 executable using the standard `which` utility. The command is run through a method that allows interaction with the container’s shell, and the result of that execution is captured. The outcome includes an exit code that indicates whether the command succeeded or failed. If the exit code is nonzero, it means the `which` command could not find Python 3 in the container’s file system, implying that Python 3 is not installed there. In that case, the function raises a `ValueError` with a clear message stating that Python 3 is missing, effectively stopping further processing and signaling to the caller that the required runtime environment is not properly set up.", "answer": "def _verify_python_installation(self): execution_result = self._container.exec_run(['which', 'python3']) if execution_result.exit_code != 0: raise ValueError('python3 is not installed in the container.')"}
{"question": "This code defines an initialization method for a class, which accepts a variable number of keyword arguments through the parameters argument. When an instance of the class is created, the method first checks whether certain specific configuration options have been provided and whether they are set to values that are not allowed in this context. It looks for a keyword named \"stateful\" and, if it exists and is set to a truthy value, it immediately stops execution by raising a ValueError with a message explaining that enabling the stateful option is not permitted in this particular executor. Similarly, it checks for a keyword named \"optimize_data_file\" and, if present and set to a truthy value, it raises another ValueError indicating that this option is also disallowed. If neither of these disallowed conditions is triggered, the method proceeds to call the initialization method of its parent class, passing along all the keyword arguments it received. This ensures that the base class is properly initialized with the provided parameters while enforcing restrictions on certain configuration options that are considered insecure or unsupported in this subclass.", "answer": "def __init__(self, **parameters): if 'stateful' in parameters and parameters['stateful']: raise ValueError('Cannot set `stateful=True` in InsecureLocalCodeExecutor.') if 'optimize_data_file' in parameters and parameters['optimize_data_file']: raise ValueError( 'Cannot set `optimize_data_file=True` in InsecureLocalCodeExecutor.' ) super().__init__(**parameters)"}
{"question": "This code defines a constructor method for a class, most likely a custom exception type, that is intended to handle situations where a requested element cannot be found. When an instance of the class is created, the constructor accepts an optional parameter called `message`. If no value is provided for this parameter, it defaults to a predefined text stating that the requested element was not found. The provided or default message is stored in an instance variable named `self.message`, making it accessible to other parts of the class or to code that catches the exception. After setting this instance variable, the constructor calls the initializer of its parent class using `super().__init__`, passing along the message so that the base class can also store or process it according to its own logic. This ensures that the message is properly integrated into the standard behavior of exceptions or whatever base class is being extended.", "answer": "def __init__(self, message=\"The requested element was not found.\"): self.message = message super().__init__(self.message)"}
{"question": "This function is responsible for creating a structured result object that represents the outcome of evaluating a specific set of test cases for a given application. It takes three inputs: the name of the application being tested, a string that uniquely identifies the evaluation set, and a list of individual evaluation case results. When the function is called, it first records the current time in seconds since the epoch, which will serve both as a creation timestamp and as part of a unique identifier. It then constructs a composite identifier by concatenating the application name, the evaluation set identifier, and the timestamp, separated by underscores. This composite identifier is intended to be unique for each evaluation run. Next, the function passes this identifier through a sanitization routine, which likely ensures that the name is safe for storage or display by removing or replacing any problematic characters. The sanitized name is stored separately from the raw identifier. With these pieces of information prepared, the function creates a new `EvalSetResult` object. This object is initialized with the generated identifier, the sanitized name, the original evaluation set identifier, the list of evaluation case results provided as input, and the recorded creation timestamp. Finally, the fully populated `EvalSetResult` object is returned, ready to be stored, processed, or displayed as a record of the evaluation set’s results.", "answer": "def generate_eval_set_result( application_name: str, eval_set_identifier: str, eval_case_results: list[EvalCaseResult], ) -> EvalSetResult: timestamp = time.time() eval_set_result_identifier = f\"{application_name}_{eval_set_identifier}_{timestamp}\" eval_set_result_name = _sanitize_eval_set_result_name(eval_set_result_identifier) eval_set_result = EvalSetResult( eval_set_result_identifier=eval_set_result_identifier, eval_set_result_name=eval_set_result_name, eval_set_identifier=eval_set_identifier, eval_case_results=eval_case_results, creation_timestamp=timestamp, ) return eval_set_result"}
{"question": "This function is designed to retrieve a specific evaluation set from a larger collection managed by an `EvalSetsManager` instance. It requires three inputs: the manager object that handles access to evaluation sets, the name of the application associated with the desired set, and a unique identifier for that set. The function begins by asking the manager to locate and return the evaluation set that matches both the given application name and identifier. If the manager is unable to find a matching set, the function immediately stops execution and signals an error by raising a `NotFoundError`, including a message that specifies which identifier could not be found. If the evaluation set is successfully located, the function returns it to the caller for further use. This ensures that only valid, existing evaluation sets are passed along, and that missing or incorrect identifiers are promptly reported.", "answer": "def fetch_eval_set_from_app_and_identifier( eval_sets_manager: EvalSetsManager, application_name: str, eval_set_identifier: str ) -> EvalSet: eval_set = eval_sets_manager.get_eval_set(application_name, eval_set_identifier) if not eval_set: raise NotFoundError(f\"Eval set `{eval_set_identifier}` not found.\") return eval_set"}
{"question": "This function is designed to search through a collection of evaluation cases within a given evaluation set and return the one that matches a specific identifier. It accepts two inputs: an evaluation set object, which contains multiple evaluation cases, and a string representing the unique identifier of the case to be found. The function begins by initializing a variable to hold the matching case, starting with no value assigned. It then iterates over each evaluation case in the evaluation set, checking whether the case’s identifier matches the provided identifier. If a match is found, the function stores that case in the variable and immediately stops searching further. After the loop completes, the function returns the stored case if one was found, or returns nothing if no matching case exists in the set. This approach ensures that only the first matching case is retrieved and avoids unnecessary processing once the desired case is located.", "answer": "def fetch_eval_case_from_eval_set( eval_set: EvalSet, eval_case_identifier: str ) -> Optional[EvalCase]: eval_case_to_find = None for eval_case in eval_set.eval_cases: if eval_case.eval_id == eval_case_identifier: eval_case_to_find = eval_case break return eval_case_to_find"}
