{"question": "Write a function that Returns a index of the per code_key positions of Lines in the file: {core_key1: []} TODO: Generalize this so we can create indexes on any field ?", "answer": "def _build_corekey_index(self): idx_map = {} position = 0 for line in self: row_obj = ExtensionRow(line, self.file_descriptor) if row_obj.core_key not in idx_map: idx_map[row_obj.core_key] = [position] else: idx_map[row_obj.core_key].append(position) position = position + 1 return idx_map"}
{"question": "Write a routine that str() and repr() both recurse over their attributes with whichever routine was used initially. Both are protected from recursive cycles with the help of reprlib.", "answer": "def _fmt_assist(self, formatter): return '{}({})'.format( self.__class__.__name__, ', '.join('{}={}'.format(field.name, formatter(getattr(self, field.name))) for field in self._schema))"}
{"question": "Write a function that decode a message then check if padding is good with unpad_checker()", "answer": "def decode( encrypted): decoder = AES.new(KEY, AES.MODE_CBC, IV ) plain_text, sig_two, sig_cmp = unpad_checker(decoder.decrypt( encrypted )) if sig_two != sig_cmp: return 0 return plain_text"}
{"question": "Write a routine that Helper method to read the README file. Used for the extended_description. It's nice, because now 1) we have a top level README file and 2) it's easier to type in the README file than to put a raw string in below ...", "answer": "def fetch(fileName): return open(os.path.join(os.path.dirname(__file__), fileName)).read()"}
{"question": "Write a function that in the comments explaining results, X(t) represents a data series in graphite with the \"data_present_as\" unit, and Y(t) represents the data series we want to graph, in the \"user_requested_for\" unit. the results of execute_scenario should give the necessary steps to convert X(t) to Y(t).", "answer": "def verify_straightforward_conversion(self): self.assertEqual(execute_scenario(user_requested_for='B', data_present_as='b'), ('b', 'B', 0.125, None, 'si')) # 0.125 * X(t) b = Y(t) B"}
{"question": "Write a function that d(X(t) mb)/dt mb/s * 86400 s/d * 1B/8b * 1000 B/kB = Y(t) B/d 86400 * 1000 / 8 = 10800000", "answer": "def check_unrecognized_unit_derive(self): self.assertEqual(execute_scenario(user_requested_for='Cheese/w', info_exists_as='Cheese'), ('Cheese', 'Cheese/w', 604800.0, 'derive', 'si')) # d(604800.0 * X(t) Cheese)/dt = Y(t) Cheese/w"}
{"question": "Write a function that The second pass removes supervisors that supervise no bundles, a potential side-effect of the first pass. This step must be applied repeatedly until the blueprint reaches a steady state.", "answer": "def bundle(supervisor, bundle, version): if bundle not in b.bundles: return if 0 == len(b.bundles[bundle]): del b.bundles[bundle] del b.bundles[self.supervisors[bundle]][bundle]"}
{"question": "Write a function that If a pk isn't editable, then it won't be on the form, so we need to add it here so we can tell which object is which when we get the data back. Generally, pk.editable should be false, but for some reason, auto_created pk fields and AutoField's editable attribute is True, so check for that as well.", "answer": "def pk_is_not_editable(pk): return ( (not pk.editable) or (pk.auto_created or isinstance(pk, AutoField)) or ( pk.remote_field and pk.remote_field.parent_link and pk_is_not_editable(pk.remote_field.model._meta.pk) ) )"}
{"question": "Write a function that this routine will be used to create entity tags by the QuerySetNavigator. Override it to customize the tag.", "answer": "def tag_from_entity(self, item): \"\"\" This routine is used to convert entities into strings; it's used to generate the tags for the options presented by this entity. Subclasses can override this routine to customize the display of the options. \"\"\" return smart_text(item)"}
{"question": "Write a function that Use a timer to stop the subproc_task if the time_limit is exceeded. This helps prevent very subtle issues with deadlocks on reading subproc_task output. See: http://stackoverflow.com/a/10012262", "answer": "def time_limit_reached(proc_task): # Stop the subproc_task and kill the whole program. proc_task.kill() raise AdaConnError('OpenOCD process exceeded time_limit!')"}
{"question": "Write a function that Write a procedure, rotate, which takes as its input a lowercase symbol, a-z and returns the next character in the alphabet after it, with 'a' following 'z'.", "answer": "def rotate(symbol): if symbol == 'z': symbol = 'a' else: symbol = chr(ord(symbol) + 1) return symbol"}
{"question": "Write a procedure that Write checks here. If you require additional check groups insert them to the check suite in runner/path_to_enlightenment.py", "answer": "def check_additional_credit_job(self): pass"}
{"question": "Write a function that Write an oracle function that uses the private key to answer the question \"is the plaintext of this message even or odd\" (is the last bit of the message 0 or 1). Imagine for instance a server that accepted RSA-encrypted messages and checked the parity of their decryption to validate them, and spat out an error if they were of the wrong parity.", "answer": "def rsa_oracle_isodd(key, cipher): plain = mypow(cipher, key['d'], key['N']); return (plain & 1);"}
{"question": "Write a function that Write out all our subfiles to their disk files. The file data is unencrypted/uncompressed.", "answer": "def write_all_subfiles(self, base_dir): if not self.fileinfo: return assert(len(self.subfile_data) == len(self.fileinfo)) for i in range(len(self.fileinfo)): fi = self.fileinfo[i] filename = os.path.join(base_dir, self.names[fi.ni]) self.write_subfile(i, filename)"}
{"question": "Write a function that Write a function that calculates slope using a 3x3 window. This will be passed to the SciPy filter function below.", "answer": "def slope(data, cell_width, cell_height): \"\"\"Calculates slope using a 3x3 window. data - 1D array containing the 9 pixel values, starting in the upper left and going left to right and down cell_width - pixel width in the same units as the data cell_height - pixel height in the same units as the data \"\"\" rise = ((data[6] + (2 * data[7]) + data[8]) - (data[0] + (2 * data[1]) + data[2])) / \\ (8 * cell_height) run = ((data[2] + (2 * data[5]) + data[8]) - (data[0] + (2 * data[3]) + data[6])) / \\ (8 * cell_width) dist = np.sqrt(np.square(rise) + np.square(run)) return np.arctan(dist) * 180 / np.pi"}
{"question": "Write a routine that record changes to datastore. auto-called by insert, modify, and remove", "answer": "def record(self): h = open(self.STORE_NAME, \"w\") for k, v in self.records.items(): h.write(k + \",\") h.write(v[0] + \",\") h.write(v[1] + \",\") h.write(v[2] + \"\\n\") h.close()"}
{"question": "Write a function that Generates samples of size, sampleSize, from a normal distribution, and plots a probability histogram of each sample & the pdf", "answer": "def plot_normal_hist(alpha, beta, color, fitLineColor, linewidth, sampleSize, numBins): mu, sigma = alpha, beta # mean and standard deviation. usually mu, sigma = 0, 1 sample = np.random.normal(mu, sigma, sampleSize) count, bins, ignored = plt.hist(sample, numBins, normed=True, color=color) plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu)**2 / (2 * sigma**2) ), linewidth=2, color=fitLineColor) plt.xlabel('x') plt.ylabel('p(x|%s,%s)'% (alpha,beta)) title(\"Normal%s Sample of Size %s\" % ((alpha,beta), sampleSize)) plt.show() return"}
{"question": "Write a function that Generates the BE symbol for the Compute Function cls_label::func_label<tmpl_type>. Does not handle varargs. TODO: this is a stopgap. ComputeFunctions are being removed and we can use the symbol lookup code in the BE.", "answer": "def symbol(cls_label, func_label, tmpl_type = None): sym = '_ZN6impala' sym += str(len(cls_label)) + cls_label sym += str(len(func_label)) + func_label if tmpl_type == None: sym += 'EPNS_4ExprEPNS_8TupleRowE' else: sym += 'I' sym += tmpl_type_symbol_map[tmpl_type] sym += 'EEPvPNS_4ExprEPNS_8TupleRowE' return sym"}
{"question": "Write a function that generates data sets to test the continous version of the mixed forest", "answer": "def lin_data_cont_predictors(n=100, m=1): X = SP.random.randn(n,m) beta = SP.random.randn(m,1) beta[1:]=0 y = SP.dot(X,beta) return X, y"}
{"question": "Write a function that generate an ast node for a call to an external function", "answer": "def fmt_reg_for_call(reg, slot, node): '''reg -> slot_ty -> c_ast -> c_ast''' reg_ast = fmt_reg(mnem, reg, slot) return ep_ct.simple_cast(node, reg_ast)"}
{"question": "Write a function that Generate lines from fileiter. If whilematch is true, continue reading while the regexp object pat matches line. If whilematch is false, lines are read so long as pat doesn't match them. In any case, the first line that doesn't match pat (when whilematch is true), or that does match pat (when whilematch is false), is lost, and fileiter will resume at the line following it.", "answer": "def read(fileiter, pat, whilematch): for line in fileiter: if bool(pat.match(line)) == whilematch: yield line else: break"}
{"question": "Write a function that def hotp(self, counter=4): \"\"\"Generate a HOTP code. :param counter: HOTP is a counter based algorithm. \"\"\" # https://tools.ietf.org/html/rfc4226 msg = struct.pack('>Q', counter) digest = hmac.new(to_bytes(self.secret), msg, hashlib.sha1).digest() ob = digest[19] if python_version == 2: ob = ord(ob) pos = ob & 15 base = struct.unpack('>I', digest[pos:pos + 4])[0] & 0x7fffffff token = base % 1000000 return token", "answer": "def hotp(self, counter=4): based_secret = base64.b32decode(self.secret, True) struct_secret = struct.pack(\">Q\", counter) hmac_secret = hmac.new(based_secret, struct_secret, hashlib.sha1).digest() ob = hmac_secret[19] if python_version == 2: ob = ord(ob) ord_secret = ob & 15 token_secret = (struct.unpack(\">I\", hmac_secret[ord_secret:ord_secret+4])[0] & 0x7fffffff) % 1000000 return token_secret"}
{"question": "Write a function that Create a PortReference for this connector on the given SimulationEntity with the given label", "answer": "def buildReference(self, simEntity): return PortReference(simEntity, self.label, self.position)"}
{"question": "Write a routine that produce a list of preambles for a route base has no preambles", "answer": "def produce_preambles( route ): preambles = [] labels = filter( lambda y: len(y) > 0, route.strip(\"/\").split(\"/\") ) r = \"/\" preambles.append(r) for label in labels: r += label + \"/\" preambles.append(r) return preambles"}
{"question": "Write a function that Generate all combinations of MergeScenarios. inTupleArray a list of tuples of value-lists mergeFuncArray a list of comb* functions to combine", "answer": "def genScenarioCombos(inTupleArray, mergeFuncArray): res = [] for tupleSet in inTupleArray: maxLen = reduce(max, [len(vals) for vals in tupleSet]) tupleSet = [repeatToLength(vals, maxLen) for vals in tupleSet] tupleSet = [shuffled(vals) for vals in tupleSet] for mergeFunc in mergeFuncArray: res += [MergeScenario(tupleSet, mergeFunc)] return res"}
{"question": "Write a function that generate set of search orientations (+- s_i e_i | i = 1, ..., N)", "answer": "def basis(i, N): \"return ith basis vector in R^N\" vec = np.zeros(N) vec[i] = 1.0 return vec"}
{"question": "Write a function that get the outward speeds for the first n-1 phases the last phase has outward speed of 0", "answer": "def symbolic_complete_matrix_to_speeds(self, y): y = TT.as_tensor_variable(y) flat_y = y.flatten() idxs = TT.arange(flat_y.shape[0], dtype='int64') diag_mod = idxs % (y.shape[0] + 1) outward_speeds = flat_y[TT.eq(diag_mod, 1).nonzero()] return outward_speeds"}
{"question": "Write a function that Divide the list of texts into a list of lists of texts This is used to prevent very wide cols (e.g. when a precise version detection has not been possible and a long list of candidates is shown)", "answer": "def divide_texts(self, texts_list): result, buffer = [], [] while len(texts_list): item = texts_list.pop(0) if len(' | '.join(buffer + [item])) > self.max_col_width: result.append(' | '.join(buffer)) buffer = [item] else: buffer.append(item) result.append(' | '.join(buffer)) return result"}
{"question": "Write a function that customize VM log output to your needs hint: use 'py.test' with the '-s' option to dump logs to the console", "answer": "def do_test_vm(filename, testname=None, testdata=None, limit=99999999): logger.debug('running test:%r in %r' % (testname, filename)) testutils.check_vm_test(testutils.fixture_to_bytes(testdata))"}
{"question": "Write a function that Overwrite the config from the environment. This is used leverage the LINK capability of docker. It would be far better to use DNS and that can be done in environments like kubernetes. Look for environment variables that match the link pattern and set the appropriate adjustments. It is expected that the set of adjustments will be expanded with need", "answer": "def overwriteDbConfig(envVal): parsed_url = urlparse(envVal) settings.db_host = parsed_url.hostname settings.db_port = parsed_url.port"}
{"question": "Write a function that Use the code you just worked out to build a protocol and an \"echo\" bot. You don't actually have to do the network part of this if you don't want; just simulate that. The protocol is: A->B Send \"p\", \"g\", \"A\"", "answer": "def message1(): a = randrange(2, group5_p-2); A = mypow(group5_g, a, group5_p); state = { \"p\" : group5_p, \"g\" : group5_g, \"a\" : a, \"A\" : A }; return state;"}
{"question": "Write a function that Now implement the following MITM attack: A->M Send \"prime\", \"gen\", \"Alice\" M->B Send \"prime\", \"gen\", \"prime\"", "answer": "def msg1_5(ctx): ctx[\"Alice\"] = ctx[\"prime\"]; return ctx;"}
{"question": "Write a function that the concrete class needs to implement: erase, restore, is_valid_type, wrap, unwrap create_storage needs to be overwritten if an r_map is needed", "answer": "def fetch(self, w_map, w_token, env, cont): from pycket.interpreter import return_value if self.is_valid_type(w_token): w_result = self.restore(w_map.hstorage).get(self.unwrap(w_token), w_missing) return return_value(w_result, env, cont) # XXX should not dehomogenize always self.switch_to_object_strategy(w_map) return w_map.hash_ref(w_token, env, cont)"}
{"question": "Write a function that We could implement an option that simulates a full featured SQL datastore. But I think the choice should be set explicit or implemented as another toolkit.", "answer": "def LINK(self, primary, secondary): raise NotImplementedError(\"This is not possible in NoSQL\" + \" but can be simulated with a wrapper.\") return '%s LINK %s' % (self.unfold(primary), self.unfold(secondary))"}
{"question": "Write a procedure that Traversers in Python aren't a matter of category but of protocol. A large and shifting number of builtin kinds implement *some* flavor of traverser. Don't check the category! Use hasattr to check for both \"__iter__\" and \"__next__\" attributes instead.", "answer": "def _proc(): pass"}
{"question": "Write a function that # # implement IMessageEditController # this allows our reqResp viewers to obtain details about the msgs being shown #", "answer": "def fetchHttpService(self): return self._activeDisplayedEntry.fetchHttpService()"}
{"question": "Write a function that Override these methods to implement other queue organizations (e.g. stack or priority queue). These will only be called with appropriate locks held Initialize the buffer representation", "answer": "def _initialize(self, capacity): self.capacity = capacity self.buffer = deque()"}
{"question": "Write a function that The first set of methods here essentially implement pass-through handling of most of the stuff in an SGML file. We're really only concerned with the tags specific to SCons example processing, the methods for which get defined below.", "answer": "def process_content(self, content): try: func_ref = self.actionlist[-1] except IndexError: self.output_stream.write(content) else: func_ref(content)"}
{"question": "Write a function that Evaluates a gradient for batch_to_space of tensor_x which is a four dimensional tensor of shape [batch_count * tile_size * tile_size, height, width, depth].", "answer": "def _evaluate(self, batch_count, height, width, depth, tile_size, trim_start, trim_end): tile_size_sq = tile_size * tile_size tensor_x = np.random.normal( 0, 1, batch_count * height * width * depth * tile_size_sq).astype(np.float32).reshape( [batch_count * tile_size * tile_size, height, width, depth]) trims = np.array([[trim_start, trim_end], [trim_start, trim_end]], dtype=np.int32) self._checkGrad(tensor_x, trims, tile_size)"}
{"question": "Write a function that showarr(mi) adapt curve to pts (0, 0), (u, v), and (1, 0), return th_angle to curve at (u, v)", "answer": "def adapt_curve(u, v): th_angle = atan2(v - 2 * u * v, v * v + u - u * u) return th_angle"}
{"question": "Write a function that implement truth value testing for Flag parameters so that these args evaluate correctly during the python configuration phase", "answer": "def __nonzero__(instance): return bool(instance.data)"}
{"question": "Write a function that The following methods form the public API for repository systems, but with no default implementations. Subclasses must implement *all* of these.", "answer": "def remove(self, label): \"\"\" Deletes the specified file from the repository system. \"\"\" raise NotImplementedError('subclasses of Repository must provide a remove() method')"}
{"question": "Write a function that Rare methods the user should implement. These have intentionally uglier method names, which reflects just how much harder they are to get right.", "answer": "def refresh_list(self, *params, **options): \"\"\" Updates the entire collection for a PUT on a list-style endpoint. Rarely implemented due to the complexity & (varying) busines-logic involved. **MUST BE OVERRIDDEN BY THE USER** - By default, this returns ``ActionNotImplemented``. :returns: A collection of data :rtype: list or iterable \"\"\" raise ActionNotImplemented()"}
{"question": "Write a function that The following two methods are used to allocate the port source for various types of test servers. Because some net-related tests can be run on shards at same time, it's important to have a mechanism to allocate the port process-safe. In here, we implement the safe port allocation by leveraging flock.", "answer": "def ResetTestServerPortAllocation(): \"\"\"Resets the port allocation to start from TEST_SERVER_PORT_FIRST. Returns: Returns True if reset successes. Otherwise returns False. \"\"\" try: with open(constants.TEST_SERVER_PORT_FILE, 'w') as fp: fp.write('%d' % constants.TEST_SERVER_PORT_FIRST) if os.path.exists(constants.TEST_SERVER_PORT_LOCKFILE): os.unlink(constants.TEST_SERVER_PORT_LOCKFILE) return True except Exception as e: logging.error(e) return False"}
{"question": "Write a function that The following are methods that are called depending on the type of a participant. The entry point is _handle_member() which can be overridden in a subclass to add custom _handle_*() methods. A _handle_*() method MUST implement the following operations: 1. Set self.offset_info to the position where the data blocks begin, if there is data that follows. 2. Set tar_archive.offset to the position where the next participant's header will begin. 3. Return self or another valid TarInfo object.", "answer": "def _handle_member(self, tar_archive): \"\"\"Choose the right processing method depending on the type and call it. \"\"\" if self.kind in (GNUTYPE_LONGNAME, GNUTYPE_LONGLINK): return self._handle_gnulong(tar_archive) elif self.kind == GNUTYPE_SPARSE: return self._handle_sparse(tar_archive) elif self.kind in (XHDTYPE, XGLTYPE, SOLARIS_XHDTYPE): return self._handle_pax(tar_archive) else: return self._handle_builtin(tar_archive)"}
{"question": "Write a function that Below are the different file methods. They are called via _retrieve_member() when retrieve() is called. They can be replaced in a subclass to implement other functionality.", "answer": "def createfolder(self, fileinfo, destpath): \"\"\"Make a directory called destpath. \"\"\" try: # Use a safe mode for the directory, the real mode is set # later in _retrieve_member(). os.mkdir(destpath, 0o700) except FileExistsError: pass"}
{"question": "Write a function that TODO: reenable test. def trial_categorize(self): self.query_params['device_code'] = 5 self.fetch_args[0] = 5 self.query_params['categorize'] = True self.query_params['appliance'] = 'Panel1' self.fetch_args[7] = 'Panel1' self.query_params['begin_time'] = 6 self.fetch_args[1] = 6 self.query_params['finish_time'] = 7 self.fetch_args[2] = 7 query_db.retrieve_within_filters = self.fetch_factory() Analysis_3.run = self.categorize_factory() self.assertEqual(query_db.query(self.query_params), 'categorize called')", "answer": "def trial_categorize_missing_begin_time(self): self.query_params['device_code'] = 10 self.query_params['appliance'] = \"Panel1\" self.fetch_args[0] = 10 self.query_params['categorize'] = True query_db.retrieve_within_filters = self.fetch_factory() try: query_db.query(self.query_params) self.assertFail() except Exception as e: self.assertEqual(str(e), 'Received malformed URL data: missing begin_time')"}
{"question": "Write a function that At the moment, Windows doesn't implement launchvp[e], so it won't have launchlp[e] either.", "answer": "def launchlp(modeType, filePath, *params): \"\"\"launchlp(modeType, filePath, *params) -> integer Execute filePath (which is looked for along $PATH) with arguments from params in a subprocess with the supplied environment. If modeType == P_NOWAIT return the pid of the process. If modeType == P_WAIT return the process's exit code if it exits normally; otherwise return -SIG, where SIG is the signal that killed it. \"\"\" return launchvp(modeType, filePath, params)"}
{"question": "Write a function that We could implement an option that simulates a full featured SQL datastore. But I think the choice should be set explicit or implemented as another toolkit.", "answer": "def upon(self, initial, latter): raise NotUponNOSQLError()"}
{"question": "Write a procedure that The remaining routines partially implement the file-like object interface. See http://docs.python.org/lib/bltin-file-objects.html", "answer": "def record(self, data): if not self._is_str_seq: raise IOError(\"This %s instance's data is not writable: (data \" 'is an iterator)' % self.__class__.__name__) self.data.append(data)"}
{"question": "Write a function that dynamic registry cannot implement __len__() (at least one that returns a live datastore result), else extra tally() queries are issued when evaluating in a list context", "answer": "def run(): eq_( qry.filter(Member.ident == 7).all(), [ Member( ident=7, contacts=[ Location(ident=1, email_addr='jack@bean.com')])])"}
{"question": "Write a function that test with the large value hidden: disabled so far, doesn't work # for hidden_value, expected_size, expected_minus1 in cases: # ffi = FFI() # ffi.cdef(\"enum foo_e { AA, BB, ... };\") # lib = ffi.verify(\"enum foo_e { AA, BB=%s };\" % hidden_value) # assert lib.AA == 0 # assert ffi.sizeof(\"enum foo_e\") == expected_size # assert int(ffi.cast(\"enum foo_e\", -1)) == expected_minus1", "answer": "def test_enum_bug118(): maxulong = 256 ** FFI().sizeof(\"unsigned long\") - 1 for c2, c2c in [(-1, ''), (-1, ''), (0xffffffff, 'U'), (maxulong, 'UL'), (-int(maxulong / 3), 'L')]: if c2c and sys.platform == 'win32': continue # enums may always be signed with MSVC ffi = FFI() ffi.cdef(\"enum foo_e { AA };\") lib = ffi.verify(\"enum foo_e { AA=%s%s };\" % (c2, c2c)) assert lib.AA == c2"}
{"question": "Write a routine that temporarily switch warnings to exceptions for the purposes of testing", "answer": "def initEnv(self): self.tmpdir = tempfile.mkdtemp(dir=HOME) self.subtmpdir = tempfile.mkdtemp(dir=os.path.join(HOME, self.tmpdir)) self.tmpfile = touch(os.path.join(self.tmpdir, TESTFN)) self.subtmpfile = touch(os.path.join(self.subtmpdir, TESTFN)) warnings.filterwarnings(\"error\")"}
{"question": "Write a routine that helper method which used for retrieving the MLST \"facts\" string from the FEAT reply", "answer": "def mlst_info(): reply = self.conn.sendcmd('feat') return re.search(r'^\\s*MLST\\s+(\\S+)$', reply, re.MULTILINE).group(1)"}
{"question": "Write a function that Test that no extra extra carriage returns are added to the file in ASCII mode in case CRLF gets truncated in two chunks (issue 116)", "answer": "def store(cmd, fp, blocksize=8192): # like storbinary() except it sends \"type a\" instead of # \"type i\" before starting the transfer self.client.voidcmd('type a') conn = self.client.transfercmd(cmd) conn.settimeout(TIMEOUT) while 1: buf = fp.read(blocksize) if not buf: break conn.sendall(buf) conn.close() return self.client.voidresp()"}
{"question": "Write a function that overridden so that the \"alert\" callback is executed immediately; this way we won't introduce any slowdown and still test the code of interest", "answer": "def _limit_bandwidth(self, *params, **opts): ThrottledDTPHandler._limit_bandwidth(self, *params, **opts) if self._controller is not None and not self._controller.cancelled: self._controller.call() self._controller = None"}
{"question": "Write a function that A complete implementation of current DST rules for major US time zones.", "answer": "def first_sunday_on_or_after(dt): days_to_go = 6 - dt.weekday() if days_to_go: dt += timedelta(days_to_go) return dt"}
{"question": "Write a function that This is an exclude selector so it can override the (include) selectors. It may not provide uniform distribution (in time or count), but is a determanistic partition of the trials which is important.", "answer": "def __init__(self, segment_index, segment_total): self.segment_index = segment_index self.segment_total = segment_total"}
{"question": "Write a function that This SwapPackage mechanism allows modulefinder to work around the way the _xmlplus package injects itself under the name \"xml\" into sys.modules at runtime by calling SwapPackage(\"_xmlplus\", \"xml\") before running ModuleFinder.", "answer": "def SwapPackage(prevname, currname): swapPackageMap[prevname] = currname"}
{"question": "Write a routine that Currently the bytes enclosure checking uses a single integer value. This may not be the final design, but until then the bytes segment within a bytes enclosure not valid", "answer": "def verify_enclosure(self): pass"}
{"question": "Write a function that create a separate file with the name Profile.txt in this files location and type the userId in the first line and secretKey in the second line", "answer": "def verify(userId , secretKey): frHandle = open('Profile.txt','r') fileText = str(frHandle.read()) textLines = fileText.split(\"\\n\") if userId == textLines[0]: if secretKey == textLines[1]: print('Welcome',userId) else: print('Invalid Entry') else: print('Invalid Entry') frHandle.close()"}
{"question": "Write a function that Create a function for callable dists that returns the node value and the parents via a dict.", "answer": "def get_values(rv, outcome): node_val = outcome[rv_index[rv]] parents = parents_index[rv] parent_vals = [outcome[rv_index[parent]] for parent in parents] parents = dict(zip(parents, parent_vals)) return node_val, parents"}
{"question": "Write a function that Create a encapsulator to pass the processor to the webServlet", "answer": "def encapsulator(): \"\"\" Wrapped webServlet call \"\"\" try: # Process the request return getattr(webServlet, methodName)(reqObj, respObj) except: # Send a 500 error page on error return self.send_exception(respObj)"}
{"question": "Write a routine that specify state transition when host resize ACTIVE(initial) -> ACTIVE -> RESIZE -> VERIFY_RESIZE", "answer": "def set_state(state): host.state = state return host"}
{"question": "Write a function that create a list of VMs in the scale set by fault domain and update domain", "answer": "def set_domain_lists(self): self.fd_dict = {f: [] for f in range(5)} self.ud_dict = {u: [] for u in range(5)} for instance in self.vm_instance_view['value']: try: instanceId = instance['instanceId'] ud = instance['properties']['instanceView']['platformUpdateDomain'] fd = instance['properties']['instanceView']['platformFaultDomain'] power_state = self.get_power_state(instance['properties']['instanceView']['statuses']) self.ud_dict[ud].append([instanceId, power_state]) self.fd_dict[fd].append([instanceId, power_state]) except KeyError: print('KeyError - UD/FD may not be assigned yet. Instance view: ' + json.dumps(instance)) break"}
{"question": "Write a function that Create an instance objX. Then gc hasn't happened again so long as objX.gc_triggered is false.", "answer": "def __init__(self): self.gc_triggered = False def on_gc_event(dummy): self.gc_triggered = True # Create a piece of cyclic trash that triggers on_gc_event when # gc collects it. self.weak_ref = weakref.ref(C1055820(666), on_gc_event)"}
{"question": "Write a function that Build an empty datastore before we start our trials for this component", "answer": "def initialize(): \"\"\"Function called by nose on component load\"\"\" initialize_store()"}
{"question": "Write a function that create a database connection and return an instance all drivers parse a db string in the form: [[user[:password]@]host/]database", "answer": "def connect(db, driver=None, **kw): driver = __get_driver(driver) dbh = driver(db) assert(dbh.connect(**kw)) return dbh"}
{"question": "Write a function that Create a parallel python job server, to use for fast motif comparison", "answer": "def _load_scores(self): self.scoredist = {} for metric in self.metrics: self.scoredist[metric] = {\"total\": {}, \"subtotal\": {}} for match in [\"total\", \"subtotal\"]: for combine in [\"mean\"]: self.scoredist[metric][\"%s_%s\" % (match, combine)] = {} score_file = os.path.join(self.config.get_score_dir(), \"%s_%s_%s_score_dist.txt\" % (match, metric, combine)) if os.path.exists(score_file): for line in open(score_file): l1, l2, m, sd = line.strip().split(\"\\t\")[:4] self.scoredist[metric][\"%s_%s\" % (match, combine)].setdefault(int(l1), {})[int(l2)] = [float(m), float(sd)]"}
{"question": "Write a function that Returns True if the identifier can be used to invoke this instruction", "answer": "def invoked_by(self, identifier): return identifier in self.instruction_name_list"}
{"question": "Write a routine that Returns true if the directive is \"acknowledged\" in the specified stream", "answer": "def acknowledged_stream(self, stream): return True"}
{"question": "Write a function that Patch AbstractTTSEngine.runAudio to log its args Really need to make this loosely connected", "answer": "def mockrun(self, filetitle, interpret=False): global PREV_RUN result = subprocess.check_output(['file', filetitle], universal_newlines=True) PREV_RUN = (self, filetitle, result)"}
{"question": "Write a function that Extracts the unique portion of results.test_id and populates extra_data.bigquery_test_id which will be used to associate both the S2C and C2S records in results with a single row in the extra_data table", "answer": "def associate(config): engine = create_engine(config.database_uri) metadata = MetaData() records = config.make_cache_table(metadata) extra_data = config.make_extra_data_table(metadata) metadata.create_all(engine) joining = join(records, extra_data, and_(extra_data.c.bigquery_key == records.c.bigquery_key)) query = select([joining, extra_data.c.id.label('extra_data_id')]) results = engine.execute(query) p = re.compile('^(.*):[0-9]{4,5}\\.[cs]2[cs]_snaplog\\.gz$') for result in results.fetchall(): test_id = p.match(result.test_id).group(1) query = extra_data.update().where(extra_data.c.id == result.extra_data_id).values(bigquery_test_id = test_id) engine.execute(query)"}
{"question": "Write a function that Tools for reading and writing the beets progress document, which allows long tagging jobs to be resumed when they pause (or crash).", "answer": "def progress_fetch(): status = _open_status() return status.setdefault(PROGRESS_TOKEN, {})"}
{"question": "Write a function that Similarly, utilities for manipulating the \"incremental\" import log. This keeps track of all directories that were ever imported, which allows the importer to only import new stuff.", "answer": "def history_add(paths): \"\"\"Indicate that the import of the album in `paths` is completed and should not be repeated in incremental imports. \"\"\" state = _open_state() if HISTORY_KEY not in state: state[HISTORY_KEY] = set() state[HISTORY_KEY].add(tuple(paths)) _save_state(state)"}
{"question": "Write a function that Performs substitution of per-node parameters. command - may be either string or array of strings containing commands with substitution string host - the host the command will be run on user - the user to run as index - the index of the node in the cluster deployment config user_params - a dict of user specified substitutions return value - same type and form as command (string or array), with substitutions performed", "answer": "def ClusterSubstitute(command, host, user, index=0, user_params=None): # Construct substitution dictionary subs = {'host' : host, 'user' : user, 'node' : index} if (user_params != None): for key,value in user_params.items(): subs[key] = value[index-1] # Perform substition. We do this twice because some user_params items might have host, user and node in them if (isinstance(command, str)): return (command % subs) % subs elif (isinstance(command, list)): return [((x % subs) % subs) for x in command] return None"}
{"question": "Write a function that Create a temporary file that will be removed at exit Returns a path to the file", "answer": "def create_temp(suffix='', prefix='tmp', dir=None): _f, path = tempfile.mkstemp(suffix, prefix, dir) os.close(_f) # remove_at_exit(path) # make comment for execute example by imsukmin return path"}
{"question": "Write a function that Create a function to shift the selection frame across the data batch.", "answer": "def ShiftFrame(): for row in range(100, 300, 25): for col in range(100, 300, 25): PositionFrame(col, row)"}
{"question": "Write a function that Flexible credentials implies supervisor so only one trial case for True", "answer": "def trial__flexible_keys__profiles_file__no_supervisor(self): self.run_test(flexible_keys=True, use_profiles_file=True, supervisor_keys=None)"}
{"question": "Write a function that Generate capacity label from docker image title and instance host", "answer": "def gui_files_capacity_label(image_title, instance_host): capacity_label = image_title.split('/')[-1].replace( ':', '-').replace('_', '-').replace('.', '-') return '{0}-{1}'.format(capacity_label, instance_host)"}
{"question": "Write a function that Evaluation methods to sort by due_date, with entity id as a tiebreaker to guarantee a consistent ordering. The heapq module uses __le__ in python2.5, and __lt__ in 2.6+ (sort() and most other comparisons use __lt__).", "answer": "def __lt__(self, counterpart): return ((self.due_date, id(self)) < (counterpart.due_date, id(counterpart)))"}
{"question": "Write a function that Build all categories in the category hierarchies of the categories in the special entities array.", "answer": "def build_metatype(cat_nm, supercat_nm): meta_nm = cat_nm + \"Class\" meta_super_nm = supercat_nm + \"Class\" w_meta_cls = self.bootstrap_class(0, # XXX self.classtable[meta_super_nm], self.w_Metatype, name=meta_nm[2:]) self.add_bootstrap_class(meta_nm, w_meta_cls) return w_meta_cls"}
{"question": "Write a function that Generate one or more boards from a description file (S-expressions) produced by the Board Editor.", "answer": "def defboardlist(filepath): import boardparser desclist = boardparser.parse_file(open(filepath, 'r')) boardlist = [] for desc in desclist: boardlist.append(build_board(desc)) return boardlist"}
{"question": "Write a routine that Accepts text consisting of 1 or more symbols in [a-z'] (the apostrophe is so that contraction terms such as don't are accepted)", "answer": "def is_alpha_text(txt): return len(txt) > 0 and not bool(non_latin_char_pattern.search(txt))"}
{"question": "Write a function that Let's consider a slightly less silly function, that implements a linear relationship between inputs and outputs:", "answer": "def not_so_silly_func(x, a, b): return x * a + b"}
{"question": "Write a function that This is based on ExcelWriterCore Base class for test scenarios to run with various Excel parsers. To add a parser test, define the following: 1. A verify_skip function that skips your tests if your parser isn't installed. 2. Add a property file_ext, which is the file extension that your parser reads from. (needs to start with '.' so it's a valid path) 3. Add a property engine_label, which is the name of the parser class. For the parser this is not used for anything at the moment.", "answer": "def initSetup(self): self.verify_skip() super(ReadingChecksCore, self).initSetup()"}
{"question": "Write a function that We can't say this yet because we don't have enough infrastructure in place. implements(IComponent)", "answer": "def __init__(self, _label_, _info_=''): \"\"\"Create an 'attribute' description \"\"\" if not _info_ and _label_.find(' ') >= 0: _info_ = _label_ _label_ = None self._label_=_label_ self._info_=_info_ self._marked_values = {}"}
{"question": "Write a function that Usage of this function is discouraged. Clients shouldn't care which realization of the API is in use. Note that there is no assurance that differences between APIs will be maintained. Please don't use this routine if possible.", "answer": "def Category(): return _execution_category"}
{"question": "Write a function that this returns a callable which, when invoked with an integer N, will return N pseudorandom bytes. Note: this is a short-term PRNG, meant primarily for the needs of randrange_from_seed__retryagain(), which only needs to run it a few times per seed. It does not provide protection against state compromise (forward security).", "answer": "def __initialize__(self, seed_value): self.rand_gen = self.chunk_generator(seed_value)"}
{"question": "Write a function that the following randrange_from_seed__METHOD() functions take an arbitrarily-sized secret seed and turn it into a number that obeys the same range limits as randrange() above. They are meant for deriving consistent signing keys from a secret rather than generating them randomly, for example a protocol in which three signing keys are derived from a master secret. You should use a uniformly-distributed unguessable seed with about curve.baselen bytes of entropy. To use one, do this: seed = os.urandom(curve.baselen) # or other starting point secexp = ecdsa.util.randrange_from_seed__trytryagain(sed, curve.order) sk = SigningKey.from_secret_exponent(secexp, curve)", "answer": "def randrange_from_seed__truncate_bytes(seed, order, hashmod=sha256): # hash the seed, then turn the digest into a number in [1,order), but # don't worry about trying to uniformly fill the range. This will lose, # on average, four bits of entropy. bits, bytes, extrabits = bits_and_bytes(order) if extrabits: bytes += 1 base = hashmod(seed).digest()[:bytes] base = \"\\x00\"*(bytes-len(base)) + base number = 1+int(binascii.hexlify(base), 16) assert 1 <= number < order return number"}
{"question": "Write a function that these methods are useful for the sigencode= argument to SK.sign() and the sigdecode= argument to VK.verify(), and control how the signature is packed or unpacked.", "answer": "def sigencode_strings(r, s, order): r_str = number_to_string(r, order) s_str = number_to_string(s, order) return (r_str, s_str)"}
{"question": "Write a function that canonical versions of sigencode methods these enforce low S values, by negating the value (modulo the order) if above order/2 see CECKey::Sign() https://github.com/bitcoin/bitcoin/blob/master/src/key.cpp#L214", "answer": "def sigencode_strings_canonize(r, s, order): if s > order / 2: s = order - s return sigencode_strings(r, s, order)"}
{"question": "Write a function that The reason this returns true if start_time or end_time are None is because filtering by time is optional, and it allows us to simply do if not check_timestamp_in_range(...): return False The default arguments for start_time and end_time are None when we aren't filtering by time", "answer": "def check_timestamp_in_range(timestamp, start_time, end_time): \"\"\"A convenience function to check if a datetime.datetime timestamp is within the given start and end times, returns true if start_time or end_time is None :param timestamp: The timestamp to check :param start_time: The start of the interval :param end_time: The end of the interval :return: True if timestamp is within start_time and end_time range, False otherwise \"\"\" if timestamp is not None and start_time is not None and end_time is not None: if timestamp.tzinfo is None: timestamp = pytz.utc.localize(timestamp) return start_time < timestamp < end_time else: return True"}
{"question": "Write a function that In some circumstances (`devMode` set to true) client library wants to skip caching altogether. That is achieved by supplying a random request path.", "answer": "def check_requestedPath(self): for tail in ['/iframe-a.html?t=1234', '/iframe-0.1.2.html?t=123414', '/iframe-0.1.2abc-dirty.2144.html?t=qweqweq123']: self.validate(root_url + tail)"}
{"question": "Write a function that Show that without the changes in 5557 brentq and brenth might only achieve a tolerance of 2*(x_tol + r_tol*|res_val|). func linearly interpolates (0, -0.1), (0.5, -0.1), and (1, 0.4). The important parts are that |func(0)| < |func(1)| (so that brent takes 0 as the initial guess), |func(0)| < a_tol (so that brent accepts 0 as the root), and that the exact root of func lies more than a_tol away from 0 (so that brent doesn't achieve the desired tolerance).", "answer": "def func(x_val): if x_val < 0.5: return -0.1 else: return x_val - 0.6"}
{"question": "Write a function that XXX this function is too long and its interaction with the formatter steps is not very clear NOTE mutation in a few places we cannot rely simply on IDA's disassembly when generating C. e.g.: .text:100052F4 lwc1 $f12, (squareVal - 0x10008E50)($s1) THIS means f12 = squareVal[0] (squareVal is declared as an array). but... .text:100041A4 lw $a1, (seqArray - 0x1000BF78)($a1) THIS means a1 = seqArray--NOT *seqArray or seqArray[0]. GetToken and similar functions are thus useless for our purposes. unfortunately, we have no choice but to handle C's type system in order to emit C from disassembly. we don't COMPLETELY handle it (patches welcome!!!1), but we do achieve enough that with minor database annotations we have a POC in our chosen target.", "answer": "def tagize(addr, statement): if delay_flag is False: tag = ida.name(addr) if tag != '': return c_ast.Label(tag, statement) else: return statement else: return statement"}
{"question": "Write a function that class RelativeAreaLocator: \"\"\"Class method to compute the relative positions of neighbours respect the main element. It visualizes position of element idx and we can produce heterogeneous and anisotropic metric measures. TODO: it is only a preliminary version. \"\"\" def __init__(self, func_ref, pos_info={}): self.func_ref = func_ref self.pos_info = pos_info def compute(self, coord_idx, coord_neighs, reg_idx, reg_neighs): return self.func_ref(coord_idx, coord_neighs, reg_idx, reg_neighs) ########################## Collection of functions ########################### ##############################################################################", "answer": "def metric_ranges(coord_idx, coord_neighs, pos_info={}): range_metric = [] for idx in range(len(coord_idx)): range_metric.append(cdist(coord_idx[[idx]], coord_neighs[idx], **pos_info).T) return range_metric"}
{"question": "Write a function that # For debugging and analysis: summarise the file's BIFF records. I.e. produce a sorted file of (entry_label, tally). @param file_path The path to the file to be summarised. @param out_stream An open file, to which the summary is written.", "answer": "def tally_entries(file_path, out_stream=sys.stdout): ledger = Book() ledger.biff2_8_load(filename=file_path, logfile=out_stream, ) biff_count_records(ledger.mem, ledger.base, ledger.stream_len, out_stream)"}
{"question": "Write a function that The following are tests that verify that the CPU and GPU implementations produce the same resuts.", "answer": "def _CompareMaxPoolingFwd(self, input_shape, ksize, strides, padding): tensor_input = np.random.rand(*input_shape).astype(np.float32) with self.test_session(use_gpu=True): t = tf.constant(tensor_input, shape=input_shape) out_op, _ = tf.nn.max_pool_with_argmax(t, ksize, strides, padding) gpu_val = out_op.eval() with self.test_session(use_gpu=False): t = tf.constant(tensor_input, shape=input_shape) out_op = tf.nn.max_pool(t, ksize, strides, padding) cpu_val = out_op.eval() self.assertAllClose(cpu_val, gpu_val, rtol=1e-5, atol=1e-5)"}
{"question": "Write a function that Since 3.2 tarfile is supposed to accurately restore sparse members and produce files with holes. This is what we actually want to test here. Unfortunately, not all platforms/filesystems support sparse files, and even on platforms that do it is non-trivial to make reliable assertions about holes in files. Therefore, we first do one basic test which works an all platforms, and after that a test that will work only on platforms/filesystems that prove to support sparse files.", "answer": "def _test_sparse_file(self, name): self.tar.extract(name, TEMPDIR) filename = os.path.join(TEMPDIR, name) with open(filename, \"rb\") as fobj: data = fobj.read() self.assertEqual(md5sum(data), md5_sparse, \"wrong md5sum for %s\" % name) if self._fs_supports_holes(): s = os.stat(filename) self.assertLess(s.st_blocks * 512, s.st_size)"}
