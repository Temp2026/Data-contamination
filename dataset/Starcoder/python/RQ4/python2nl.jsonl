{"question": "def _sqlite_load(self): conn = self.session.connection() cursor = conn.connection.cursor() with open(self.options[\"sql_path\"], \"r\", encoding=\"utf-8\") as f: try: cursor.executescript(f.read()) finally: cursor.close() # self.session.flush()", "answer": "Read a SQLite script and initialize the in-memory database."}
{"question": "def _db_has_person_accounts_column(self, mapping): return ( self.models[mapping.table].__table__.columns.get(\"IsPersonAccount\") is not None )", "answer": "Returns whether \"IsPersonAccount\" is a column in mapping's table."}
{"question": "async def get_position_for_event(self, event_id: str) -> PersistedEventPosition: row = await self.db_pool.simple_select_one( table=\"events\", keyvalues={\"event_id\": event_id}, retcols=(\"stream_ordering\", \"instance_name\"), desc=\"get_position_for_event\", ) return PersistedEventPosition( row[\"instance_name\"] or \"master\", row[\"stream_ordering\"] )", "answer": "Get the persisted position for an event"}
{"question": "def find_intersection(self,other): # Determinant for finding points of intersection x = ((self.x1*self.y2 - self.y1*self.x2)*(other.x1-other.x2) - (self.x1-self.x2)*(other.x1*other.y2 - other.y1*other.x2))/ ((self.x1-self.x2)*(other.y1-other.y2) - (self.y1-self.y2)*(other.x1-other.x2)) y = ((self.x1*self.y2 - self.y1*self.x2)*(other.y1-other.y2) - (self.y1-self.y2)*(other.x1*other.y2 - other.y1*other.x2))/ ((self.x1-self.x2)*(other.y1-other.y2) - (self.y1-self.y2)*(other.x1-other.x2)) x = int(x) y = int(y) return x,y", "answer": "Finds intersection of this line and other. One line must be horizontal and the other must be vertical"}
{"question": "def to_str(self): return pformat(self.to_dict())", "answer": "Returns the string representation of the model"}
{"question": "def __ne__(self, other): return not self == other", "answer": "Returns true if both objects are not equal"}
{"question": "def write_chemdner_files(results, models, goldset, ths, rules): print(\"saving results to {}\".format(results.path + \".tsv\")) with codecs.open(results.path + \".tsv\", 'w', 'utf-8') as outfile: cpdlines, max_entities = results.corpus.write_chemdner_results(models, outfile, ths, rules) cpdlines = sorted(cpdlines, key=itemgetter(2)) with open(results.path + \"_cpd.tsv\", \"w\") as cpdfile: for i, l in enumerate(cpdlines): if l[2] == 0: cpdfile.write(\"{}_{}\\t0\\t{}\\t1\\n\".format(l[0], l[1], i+1)) else: cpdfile.write(\"{}_{}\\t1\\t{}\\t{}\\n\".format(l[0], l[1], i+1, l[2]*1.0/max_entities))", "answer": "results files for CHEMDNER CEMP and CPD tasks"}
{"question": "def _storeMessage(self, message: IRCMessage): if message.command and message.command.lower() in self.bot.moduleHandler.mappedTriggers: # ignore bot commands return if 'tracking' in message.metadata: # ignore internal messages from alias processing if any(m in message.metadata['tracking'] for m in ['Sub', 'Chain', 'Alias']): return self.messages[message.replyTo] = message", "answer": "stores the current message for _prevmsg to return later"}
{"question": "def _tojson(self, message: IRCMessage): return IRCResponse(json.dumps(message.parameters), message.replyTo)", "answer": "converts input string to json-escaped string"}
{"question": "def test_placholder(): ...", "answer": "Placeholder test to pass CI until creating actual test suite."}
{"question": "def get_validation_dependencies( self, configuration: Optional[ExpectationConfiguration] = None, execution_engine: Optional[ExecutionEngine] = None, runtime_configuration: Optional[dict] = None, ): return { \"result_format\": parse_result_format( self.get_runtime_kwargs( configuration=configuration, runtime_configuration=runtime_configuration, ).get(\"result_format\") ), \"metrics\": dict(), }", "answer": "Returns the result format and metrics required to validate this Expectation using the provided result format."}
{"question": "def get_firewalls_for_tenant(self, context, **kwargs): LOG.debug(_(\"get_firewalls_for_tenant() called\")) fw_list = [ self.plugin._make_firewall_dict_with_rules(context, fw['id']) for fw in self.plugin.get_firewalls(context) ] return fw_list", "answer": "Agent uses this to get all firewalls and rules for a tenant."}
{"question": "def shortDescription(self): return None", "answer": "preventing nose (unittest) from using the docstring"}
{"question": "def show_config(): sys.stdout.write(str(_cupyx.get_runtime_info())) sys.stdout.flush()", "answer": "Prints the current runtime configuration to standard output."}
{"question": "def add_lines(self, levels, colors, linewidths): del self.lines N = len(levels) x = np.array([1.0, 2.0]) X, Y = np.meshgrid(x,levels) if self.orientation == 'vertical': xy = [list(zip(X[i], Y[i])) for i in xrange(N)] else: xy = [list(zip(Y[i], X[i])) for i in xrange(N)] col = collections.LineCollection(xy, linewidths=linewidths, ) self.lines = col col.set_color(colors) self.ax.add_collection(col)", "answer": "Draw lines on the colorbar. It deletes preexisting lines."}
{"question": "def extract_msg_options(options, keep=MSG_OPTIONS): return dict((name, options.get(name)) for name in keep)", "answer": "Extracts known options to `basic_publish` from a dict, and returns a new dict."}
{"question": "def format(self, indent=0, indent_first=True): info = [QUEUE_FORMAT.strip() % dict( name=(name + \":\").ljust(12), **config) for name, config in self.items()] if indent_first: return textindent(\"\\n\".join(info), indent) return info[0] + \"\\n\" + textindent(\"\\n\".join(info[1:]), indent)", "answer": "Format routing table into string for log dumps."}
{"question": "def _sphinx_version(): major, minor, micro, level, serial = sys.version_info release = '%s%s' % (major, minor) release += '%s' % (micro,) if level == 'candidate': release += 'rc%s' % (serial,) elif level != 'final': release += '%s%s' % (level[0], serial) return release", "answer": "Format sys.version_info to produce the Sphinx version string used to install the chm docs"}
{"question": "def ResetFont(self): # Called from configdialog.py # Update the code context widget first, since its height affects # the height of the text widget. This avoids double re-rendering. if self.code_context is not None: self.code_context.update_font() # Next, update the line numbers widget, since its width affects # the width of the text widget. if self.line_numbers is not None: self.line_numbers.update_font() # Finally, update the main text widget. new_font = idleConf.GetFont(self.root, 'main', 'EditorWindow') self.text['font'] = new_font self.set_width()", "answer": "Update the text widgets' font if it is changed"}
{"question": "def RemoveKeybindings(self): # Called from configdialog.py self.mainmenu.default_keydefs = keydefs = idleConf.GetCurrentKeySet() for event, keylist in keydefs.items(): self.text.event_delete(event, *keylist) for extensionName in self.get_standard_extension_names(): xkeydefs = idleConf.GetExtensionBindings(extensionName) if xkeydefs: for event, keylist in xkeydefs.items(): self.text.event_delete(event, *keylist)", "answer": "Remove the keybindings before they are changed."}
{"question": "def set_notabs_indentwidth(self): # Called from configdialog.py if not self.usetabs: self.indentwidth = idleConf.GetOption('main', 'Indent','num-spaces', type='int')", "answer": "Update the indentwidth if changed and not using tabs in this window"}
{"question": "def reset_help_menu_entries(self): help_list = idleConf.GetAllExtraHelpSourcesList() helpmenu = self.menudict['help'] # first delete the extra help entries, if any helpmenu_length = helpmenu.index(END) if helpmenu_length > self.base_helpmenu_length: helpmenu.delete((self.base_helpmenu_length + 1), helpmenu_length) # then rebuild them if help_list: helpmenu.add_separator() for entry in help_list: cmd = self.__extra_help_callback(entry[1]) helpmenu.add_command(label=entry[0], command=cmd) # and update the menu dictionary self.menudict['help'] = helpmenu", "answer": "Update the additional help entries on the Help menu"}
{"question": "def __extra_help_callback(self, helpfile): def display_extra_help(helpfile=helpfile): if not helpfile.startswith(('www', 'http')): helpfile = os.path.normpath(helpfile) if sys.platform[:3] == 'win': try: os.startfile(helpfile) except OSError as why: tkMessageBox.showerror(title='Document Start Failure', message=str(why), parent=self.text) else: webbrowser.open(helpfile) return display_extra_help", "answer": "Create a callback with the helpfile value frozen at definition time"}
{"question": "def get_default_verify_paths(): parts = _ssl.get_default_verify_paths() # environment vars shadow paths cafile = os.environ.get(parts[0], parts[1]) capath = os.environ.get(parts[2], parts[3]) return DefaultVerifyPaths(cafile if os.path.isfile(cafile) else None, capath if os.path.isdir(capath) else None, *parts)", "answer": "Return paths to default cafile and capath."}
{"question": "def fromnid(cls, nid): return super().__new__(cls, *_nid2obj(nid))", "answer": "Create _ASN1Object from OpenSSL numeric ID"}
{"question": "def fromname(cls, name): return super().__new__(cls, *_txt2obj(name, name=True))", "answer": "Create _ASN1Object from short name, long name or OID"}
{"question": "def pending(self): return self._sslobj.pending()", "answer": "Return the number of bytes that can be read immediately."}
{"question": "def version(self): return self._sslobj.version()", "answer": "Return a string identifying the protocol version used by the current SSL channel."}
{"question": "def write(self, data): self._checkClosed() if self._sslobj is None: raise ValueError(\"Write on closed or unwrapped SSL socket.\") return self._sslobj.write(data)", "answer": "Write DATA to the underlying SSL channel. Returns number of bytes of DATA actually transmitted."}
{"question": "def connect(self, addr): self._real_connect(addr, False)", "answer": "Connects to remote ADDR, and then wraps the connection in an SSL channel."}
{"question": "def DER_cert_to_PEM_cert(der_cert_bytes): f = str(base64.standard_b64encode(der_cert_bytes), 'ASCII', 'strict') ss = [PEM_HEADER] ss += [f[i:i+64] for i in range(0, len(f), 64)] ss.append(PEM_FOOTER + '\\n') return '\\n'.join(ss)", "answer": "Takes a certificate in binary DER format and returns the PEM version of it as a string."}
{"question": "def _resnet_plain(self, inputs, blocks, output_stride=None, scope=None): with tf.variable_scope(scope, values=[inputs]): with slim.arg_scope([slim.conv2d], outputs_collections='end_points'): net = resnet_utils.stack_blocks_dense(inputs, blocks, output_stride) end_points = slim.utils.convert_collection_to_dict('end_points') return net, end_points", "answer": "A plain ResNet without extra layers before or after the ResNet blocks."}
{"question": "def _stack_blocks_nondense(self, net, blocks): for block in blocks: with tf.variable_scope(block.scope, 'block', [net]): for i, unit in enumerate(block.args): with tf.variable_scope('unit_%d' % (i + 1), values=[net]): net = block.unit_fn(net, rate=1, **unit) return net", "answer": "A simplified ResNet Block stacker without output stride control."}
{"question": "def requires_preprocessing(self) -> Optional[bool]: return pulumi.get(self, \"requires_preprocessing\")", "answer": "Value that indicates whether the rule action requires preprocessing."}
{"question": "def properties(self) -> Optional[Mapping[str, str]]: return pulumi.get(self, \"properties\")", "answer": "dictionary object for custom filters"}
{"question": "def capacity(self) -> Optional[int]: return pulumi.get(self, \"capacity\")", "answer": "The specified messaging units for the tier. For Premium tier, capacity are 1,2 and 4."}
{"question": "def requires_preprocessing(self) -> Optional[bool]: return pulumi.get(self, \"requires_preprocessing\")", "answer": "Value that indicates whether the rule action requires preprocessing."}
{"question": "def __init__(self, **kwargs): super().__init__(**kwargs) self.timestamp = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")", "answer": "Initialize the query with a UTC timestamp at initialization time."}
{"question": "def get_vrf_object(vrf_name: str) -> Vrf: for vrf_obj in devices.vrf_objects: if vrf_name is not None: if vrf_name == vrf_obj._id or vrf_name == vrf_obj.display_name: return vrf_obj elif vrf_name == \"__hyperglass_default\" and vrf_obj.default: return vrf_obj elif vrf_name is None: if vrf_obj.default: return vrf_obj raise InputInvalid(params.messages.vrf_not_found, vrf_name=vrf_name)", "answer": "Match VRF object from VRF name."}
{"question": "def digest(self): return hashlib.sha256(repr(self).encode()).hexdigest()", "answer": "Create SHA256 hash digest of model representation."}
{"question": "def random(self): return hashlib.sha256( secrets.token_bytes(8) + repr(self).encode() + secrets.token_bytes(8) ).hexdigest()", "answer": "Create a random string to prevent client or proxy caching."}
{"question": "def summary(self): items = ( f\"query_location={self.query_location}\", f\"query_type={self.query_type}\", f\"query_vrf={self.query_vrf.name}\", f\"query_target={str(self.query_target)}\", ) return f'Query({\", \".join(items)})'", "answer": "Create abbreviated representation of instance."}
{"question": "def device(self): return devices[self.query_location]", "answer": "Get this query's device object by query_location."}
{"question": "def _GetJavaVersion(): proc = subprocess.Popen(['java', '-version'], stderr=subprocess.PIPE) unused_stdoutdata, stderrdata = proc.communicate() version_line = stderrdata.splitlines()[0] return _VERSION_REGEX.search(version_line).group()", "answer": "Returns the string for the current version of Java installed."}
{"question": "def test_create_page_without_promote_tab(self): response = self.client.get( reverse('wagtailadmin_pages:add', args=('tests', 'standardindex', self.root_page.id)) ) self.assertEqual(response.status_code, 200) self.assertContains(response, '<a href=\"#tab-content\" class=\"active\">Content</a>') self.assertNotContains(response, '<a href=\"#tab-promote\" class=\"\">Promote</a>')", "answer": "Test that the Promote tab is not rendered for page classes that define it as empty"}
{"question": "def test_unpublish_view(self): # Get unpublish page response = self.client.get(reverse('wagtailadmin_pages:unpublish', args=(self.page.id, ))) # Check that the user received an unpublish confirm page self.assertEqual(response.status_code, 200) self.assertTemplateUsed(response, 'wagtailadmin/pages/confirm_unpublish.html')", "answer": "This tests that the unpublish view responds with an unpublish confirm page"}
{"question": "def test_create_accessible(self): response, page = self._create_page(Page.objects.get(pk=2)) self.assertIsNotNone(page.url) self.assertTrue(any( 'View live' in message.message and page.url in message.message for message in response.context['messages']))", "answer": "Create a page under the site root, check the flash message has a valid \"View live\" button."}
{"question": "def test_edit_accessible(self): response, page = self._edit_page(Page.objects.get(pk=2)) self.assertIsNotNone(page.url) self.assertTrue(any( 'View live' in message.message and page.url in message.message for message in response.context['messages']))", "answer": "Edit a page under the site root, check the flash message has a valid \"View live\" button."}
{"question": "def prep_cmd_pkt(self): reqstr = struct.pack( b'6sB17s', bt.str2ba(self.addr), bt.ACL_LINK, b'\\0' * 17) request = array.array('b', reqstr) handle = fcntl.ioctl(self.hci_fd, bt.HCIGETCONNINFO, request, 1) handle = struct.unpack(b'8xH14x', request.tostring())[0] self.cmd_pkt = struct.pack('H', handle)", "answer": "Prepare the command packet for requesting RSSI."}
{"question": "def _write_to_file(self, key, binary_features, input_file): self._transition.setdefault(key, len(self._transition) + 1) self._match_transition[self._transition[key]] = key input_str = str(self._transition[key]) + ' ' + binary_features + '\\n' input_file.write(input_str.encode('utf-8'))", "answer": "write the binary features to input file and update the transition dictionary"}
{"question": "def test_wireup(self): self.assertIsInstance( Iota(self.adapter).getInputs, GetInputsCommand, )", "answer": "Verify that the command is wired up correctly."}
{"question": "def ensure_session(session: Optional[boto3.Session] = None) -> boto3.Session: if session is not None: return session return boto3.Session()", "answer": "Ensure that a valid boto3.Session will be returned."}
{"question": "def ensure_postgresql_casts(): psycopg2.extensions.register_adapter(bytes, psycopg2.Binary) typecast_bytea = lambda data, cur: None if data is None else bytes(psycopg2.BINARY(data, cur)) # noqa BYTEA = psycopg2.extensions.new_type(psycopg2.BINARY.values, \"BYTEA\", typecast_bytea) psycopg2.extensions.register_type(BYTEA)", "answer": "Ensure that psycopg2 will handle some data types right."}
{"question": "def set_vif_mtu_config(conf, mtu): conf.mtu = mtu", "answer": "Populate a LibvirtConfigGuestInterface instance with network mtu."}
{"question": "def set_numa_memnode(conf, guest_node_id, host_cell_id): conf.cellid = guest_node_id conf.nodeset = [host_cell_id] conf.mode = \"strict\"", "answer": "Prepares numa memory node config for the guest."}
{"question": "def reset_parameters(self): logger.info('===== Initialize %s with normal distribution =====' % self.__class__.__name__) for n, p in self.named_parameters(): init_like_transformer_xl(n, p, std=0.02)", "answer": "Initialize parameters with normal distribution."}
{"question": "def check_json_precision(): n = Decimal(\"20000000.00000003\") satoshis = int(json.loads(json.dumps(float(n)))*1.0e8) if satoshis != 2000000000000003: raise RuntimeError(\"JSON encode/decode loses precision\")", "answer": "Make sure json library being used does not lose precision converting BTC values"}
{"question": "def determine_db_dir(): if platform.system() == \"Darwin\": return os.path.expanduser(\"~/Library/Application Support/SafeCapital/\") elif platform.system() == \"Windows\": return os.path.join(os.environ['APPDATA'], \"SafeCapital\") return os.path.expanduser(\"~/.safecapital\")", "answer": "Return the default location of the safecapital data directory"}
{"question": "def __ne__(self, other): # type: (object) -> bool return not self == other", "answer": "Returns true if both objects are not equal"}
{"question": "def dbnd_tracking_stop(): global _dbnd_script_manager if _dbnd_script_manager: _dbnd_script_manager.stop() _dbnd_script_manager = None", "answer": "Stops and clears the script tracking if exists"}
{"question": "def _set_dbnd_config_from_airflow_connections(): try: from dbnd_airflow.tracking.dbnd_airflow_conf import ( set_dbnd_config_from_airflow_connections, ) set_dbnd_config_from_airflow_connections() except ImportError: logger.info( \"dbnd_airflow is not installed. Config will not load from Airflow Connections\" )", "answer": "Set Databand config from Extra section in Airflow dbnd_config connection."}
{"question": "def _outgoing_order_request_handler(self, o): self.risk_manager.order_in_compliance( o) # order pointer; modify order directly if (self.risk_manager.passorder()): # self._order_manager.on_order(o) # self.order_window. msg = o.serialize() print('client send msg: ' + msg, datetime.now()) # print('client send msg: ' + msg) # text = o.destination + o.source + str(o.clientID) # requests.get('https://sc.ftqq.com/SCU49995T54cd0bf4d42dd8448359347830d62bd85cc3f69d085ee.send?text=%s &desp=%s'%(text,msg)) self._outgoing_queue.put(msg)", "answer": "process o, check against risk manager and compliance manager"}
{"question": "def bool_flag(s): if s.lower() in FALSY_STRINGS: return False elif s.lower() in TRUTHY_STRINGS: return True else: raise argparse.ArgumentTypeError(\"invalid value for a boolean flag\")", "answer": "Parse boolean arguments from the command line."}
{"question": "def reload_parameters(old_params, new_params, attributes): for k, v in old_params.__dict__.items(): if k in attributes and k not in new_params: setattr(new_params, k, v)", "answer": "Reload the parameters of a previous model."}
{"question": "def get_grad_norm(model): norm = 0 for param in model.parameters(): norm += param.grad.data.norm(2) ** 2 return np.sqrt(norm)", "answer": "Return the norm of the parameters gradients."}
{"question": "def update_lambda_value(config, n_iter): ranges = [i for i in range(len(config) - 1) if config[i][0] <= n_iter < config[i + 1][0]] if len(ranges) == 0: assert n_iter >= config[-1][0] return config[-1][1] assert len(ranges) == 1 i = ranges[0] x_a, y_a = config[i] x_b, y_b = config[i + 1] return y_a + (n_iter - x_a) * float(y_b - y_a) / float(x_b - x_a)", "answer": "Update a lambda value according to its schedule configuration."}
{"question": "def restore_segmentation(path): assert os.path.isfile(path) restore_cmd = \"sed -i -r 's/(@@ )|(@@ ?$)//g' %s\" subprocess.Popen(restore_cmd % path, shell=True).wait()", "answer": "Take a file segmented with BPE and restore it to its original segmentation."}
{"question": "def create_word_masks(params, data): if not hasattr(params, 'vocab') or len(params.vocab) == 0: return params.vocab_mask_pos = [] params.vocab_mask_neg = [] for lang, n_words in zip(params.langs, params.n_words): dico = data['dico'][lang] vocab = data['vocab'][lang] words = [EOS_WORD, UNK_WORD] + list(vocab) mask_pos = set([dico.index(w) for w in words]) mask_neg = [i for i in range(n_words) if i not in mask_pos] params.vocab_mask_pos.append(torch.LongTensor(sorted(mask_pos))) params.vocab_mask_neg.append(torch.LongTensor(sorted(mask_neg)))", "answer": "Create masks for allowed / forbidden output words."}
{"question": "def _train(self, dataset): targets_sa = dataset.sa[self.get_space()] targets = targets_sa.value if not \"regression\" in self.__tags__: targets = self._attrmap.to_numeric(targets) try: self._R_model = r[self._learner](dataset.samples, targets, **self._kwargs) except RRuntimeError as e: raise FailedToTrainError( \"Failed to train %s on %s. Got '%s' during call to fit().\" % (self, dataset, e) )", "answer": "Train the skl learner using `dataset` (`Dataset`)."}
{"question": "def jac_b_p_transpose(d_p): d_p_p = d_p * transport_matrix u_f = tf.reduce_sum(d_p_p, axis=2) / eps u_g = tf.reduce_sum(d_p_p, axis=1) / eps m1_tranpose_u_f = tf.linalg.matvec(m1, u_f, transpose_a=True) to_invert = tf.concat( [m1_tranpose_u_f[:, :, tf.newaxis], u_g[:, :, tf.newaxis]], axis=2) inverses = tf.linalg.solve(tf.transpose(schur, [0, 2, 1]), to_invert) inv_m1_tranpose_u_f, inv_u_g = inverses[:, :, 0], inverses[:, :, 1] jac_2 = -inv_m1_tranpose_u_f + inv_u_g return eps * jac_2 / b", "answer": "Transposed of the jacobian of the transport w.r.t the target weights."}
{"question": "def human_size(num, suffix='B'): for unit in ('', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi'): if abs(num) < 1024.0: return \"{0:3.1f}{1!s}{2!s}\".format(num, unit, suffix) num /= 1024.0 return \"{0:.1f}{1!s}{2!s}\".format(num, 'Yi', suffix)", "answer": "Convert bytes length to a human-readable version"}
{"question": "def detect_django_settings(): matches = [] for root, dirnames, filenames in os.walk(os.getcwd()): for filename in fnmatch.filter(filenames, '*settings.py'): full = os.path.join(root, filename) if 'site-packages' in full: continue full = os.path.join(root, filename) package_path = full.replace(os.getcwd(), '') package_module = package_path.replace(os.sep, '.').split('.', 1)[1].replace('.py', '') matches.append(package_module) return matches", "answer": "Automatically try to discover Django settings files, return them as relative module paths."}
{"question": "def check_new_version_available(this_version): import requests pypi_url = 'https://pypi.org/pypi/Zappa/json' resp = requests.get(pypi_url, timeout=1.5) top_version = resp.json()['info']['version'] return this_version != top_version", "answer": "Checks if a newer version of Zappa is available. Returns True is updateable, else False."}
{"question": "def contains_python_files_or_subdirs(folder): for root, dirs, files in os.walk(folder): if [filename for filename in files if filename.endswith('.py') or filename.endswith('.pyc')]: return True for d in dirs: for _, subdirs, subfiles in os.walk(d): if [filename for filename in subfiles if filename.endswith('.py') or filename.endswith('.pyc')]: return True return False", "answer": "Checks (recursively) if the directory contains .py or .pyc files"}
{"question": "def conflicts_with_a_neighbouring_module(directory_path): parent_dir_path, current_dir_name = os.path.split(os.path.normpath(directory_path)) neighbours = os.listdir(parent_dir_path) conflicting_neighbour_filename = current_dir_name+'.py' return conflicting_neighbour_filename in neighbours", "answer": "Checks if a directory lies in the same directory as a .py file with the same name."}
{"question": "def titlecase_keys(d): return {k.title(): v for k, v in d.items()}", "answer": "Takes a dict with keys of type str and returns a new dict with all keys titlecased."}
{"question": "def unregister_serializer(format): if not _serializers: _load_serializers() if format not in _serializers: raise SerializerDoesNotExist(format) del _serializers[format]", "answer": "Unregister a given serializer. This is not a thread-safe operation."}
{"question": "def get_xs(self): x1, x2, y1, y2, z1, z2 = self.bounds dx, dy, dz = self.dims nz, ny, nx = self.shape xs = np.arange(x1, x2 + dx, dx) if xs.size > nx + 1: return xs[:-1] return xs", "answer": "Return an array with the x coordinates of the prisms in mesh."}
{"question": "def data_frame(self): if self.__data_frame is None: self.__data_frame = self.PVT_hourly_aggregated_kW return self.__data_frame", "answer": "This get's used a couple of times in the calculations, avoid hitting the PlotCache each time"}
{"question": "def num_keys(self) -> int: return len(self._keys)", "answer": "Returns the number of keys stored in the SQS message so far."}
{"question": "def test_response_content_type_encoding(): headers = {\"Content-Type\": \"text-plain; charset=latin-1\"} content = \"Latin 1: ÿ\".encode(\"latin-1\") response = httpx.Response( 200, content=content, headers=headers, ) assert response.text == \"Latin 1: ÿ\" assert response.encoding == \"latin-1\"", "answer": "Use the charset encoding in the Content-Type header if possible."}
{"question": "def test_response_fallback_to_autodetect(): headers = {\"Content-Type\": \"text-plain; charset=invalid-codec-name\"} content = \"おはようございます。\".encode(\"utf-8\") response = httpx.Response( 200, content=content, headers=headers, ) assert response.text == \"おはようございます。\" assert response.encoding is None", "answer": "Fallback to autodetection if we get an invalid charset in the Content-Type header."}
{"question": "def test_response_non_text_encoding(): headers = {\"Content-Type\": \"image/png\"} response = httpx.Response( 200, content=b\"xyz\", headers=headers, ) assert response.text == \"xyz\" assert response.encoding is None", "answer": "Default to apparent encoding for non-text content-type headers."}
{"question": "def test_mock_session(mock_http_adapter): with get_responses(): # An error will be raised if a real request is made with pytest.raises(ValueError): requests.get(PASSTHRU_URL) # All mocked URLs will return a response based on requests-cache data for url in TEST_URLS: response = requests.get(url) assert getattr(response, 'from_cache', False) is False # responses will raise an error for an unmocked URL, as usual with pytest.raises(ConnectionError): requests.get(UNMOCKED_URL)", "answer": "Test that the mock_session fixture is working as expected"}
{"question": "def cli_documentdb_list(client, resource_group_name=None): if resource_group_name: return client.list_by_resource_group(resource_group_name) else: return client.list()", "answer": "Lists all Azure DocumentDB database accounts within a given resource group or subscription."}
{"question": "def _str_to_bool(s): if s.lower() not in ['true', 'false']: raise ValueError('Need bool; got %r' % s) return {'true': True, 'false': False}[s.lower()]", "answer": "Convert string to bool (in argparse context)."}
{"question": "def getOptions(): parser = argparse.ArgumentParser(description='Tool for identifying duplicates and creating various useful output') parser.add_argument('-i','--input',dest='fa', action='store', required=True, help='A list of fa file [Required]') parser.add_argument('-o','--out', dest='out', action='store', required=True, help='Output file for counts in csv format [Required]') parser.add_argument('--pixel', dest='pix', action='store', default=100, required=False, help='Number of pixels to consider a read as an optical duplicate [Default:100]') parser.add_argument('-a', dest='append', action='store_true', help='This flag will cause the output dataset to be appended too.') parser.add_argument('-t','--table', dest='table', action='store', required=False, help='Output table with the duplicate counts for each uniq sequence') parser.add_argument('-f','--faOut', dest='faOut', action='store', required=False, help='Output a FASTA file optical duplicates are reduced') parser.add_argument('-g','--log',dest='log',action='store',required=False, help='Create an error log') args = parser.parse_args() return(args)", "answer": "Function to pull in command line arguments"}
{"question": "def writeOutput(handle, myList): handle.write(','.join(str(x) for x in myList) + \"\\n\")", "answer": "Function to write output from a list to a csv"}
{"question": "def writeTable(table, mySeqDict): myDict = dict() for seq in mySeqDict: myDict[seq] = len(mySeqDict[seq]) with open(table,'w') as handle: for item in sorted(myDict,key=myDict.get,reverse=True): writeOutput(handle, [myDict[item],item])", "answer": "Write a table with how many time each sequence is duplicated."}
{"question": "def clear_being_calculated(): core.clear_being_calculated()", "answer": "Marks all entries in this cache as not being calculated."}
{"question": "def cache_dpath(): try: return core.expended_cache_dir except AttributeError: return None", "answer": "Returns the path to the cache dir, if exists; None if not."}
{"question": "def check(m: Message) -> bool: return role in m.role_mentions", "answer": "Checks that the message contains the role mention."}
{"question": "def auth_protected_view(f): def wrapped(*args, **kw): if get_app().conf['auth/token_key'] in get_session(): return f(*args, **kw) else: return redirect(url_for('auth/login')) return wrapped", "answer": "Decorator to only allow authorized users to access the view"}
{"question": "def view_logout(request): logout() return redirect(url_for('auth/login'))", "answer": "Just logout and redirect to the login screen."}
{"question": "def trainer(self, trainer: \"pl.Trainer\"): if not isinstance(trainer, pl.Trainer): raise MisconfigurationException( f\"Loop {self.__class__.__name__} should be connected to a `Trainer`, found: {trainer}.\" ) self._trainer = trainer for v in self.__dict__.values(): if isinstance(v, Loop): v.trainer = trainer", "answer": "Connects this loop's trainer and its children"}
{"question": "def connect(self, **kwargs: \"Loop\") -> None:", "answer": "Optionally connect one or multiple loops to this one. Linked loops should form a tree."}
{"question": "def on_load_checkpoint(self, state_dict: Dict) -> None:", "answer": "Called when loading a model checkpoint, use to reload loop state."}
{"question": "async def _send_rtcp_nack(self, media_ssrc: int, lost) -> None: if self.__rtcp_ssrc is not None: packet = RtcpRtpfbPacket( fmt=RTCP_RTPFB_NACK, ssrc=self.__rtcp_ssrc, media_ssrc=media_ssrc ) packet.lost = lost await self._send_rtcp(packet)", "answer": "Send an RTCP packet to report missing RTP packets."}
{"question": "def __stop_decoder(self) -> None: if self.__decoder_thread: self.__decoder_queue.put(None) self.__decoder_thread.join() self.__decoder_thread = None", "answer": "Stop the decoder thread, which will in turn stop the track."}
{"question": "def _qualname(obj): return obj.__module__ + '.' + obj.__qualname__", "answer": "Get the fully-qualified name of an object (including module)."}
