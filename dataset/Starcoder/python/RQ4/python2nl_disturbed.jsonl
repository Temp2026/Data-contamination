{"question": "def _sqlite_retrieve(self): link = self.session.connection() cur = link.connection.cursor() with open(self.options[\"sql_path\"], \"r\", encoding=\"utf-8\") as file: try: cur.executescript(file.read()) finally: cur.close() # self.session.flush()", "answer": "Read a SQLite script and initialize the in-memory datastore."}
{"question": "def _db_contains_person_accounts_field(self, schemaMap): return ( self.entities[schemaMap.table].__table__.columns.get(\"IsPersonAccount\") is not None )", "answer": "Returns whether \"IsPersonAccount\" is a field in schemaMap's table."}
{"question": "async def fetch_location_for_event(self, evt_id: str) -> PersistedEventPosition: record = await self.db_pool.simple_select_one( table=\"events\", keyvalues={\"event_id\": evt_id}, retcols=(\"stream_ordering\", \"instance_name\"), desc=\"fetch_location_for_event\", ) return PersistedEventPosition( record[\"instance_name\"] or \"master\", record[\"stream_ordering\"] )", "answer": "Retrieve the persisted location for an event"}
{"question": "def find_intersection(self,other): # Determinant for finding points of intersection x = ((self.x1*self.y2 - self.y1*self.x2)*(other.x1-other.x2) - (self.x1-self.x2)*(other.x1*other.y2 - other.y1*other.x2))/ ((self.x1-self.x2)*(other.y1-other.y2) - (self.y1-self.y2)*(other.x1-other.x2)) y = ((self.x1*self.y2 - self.y1*self.x2)*(other.y1-other.y2) - (self.y1-self.y2)*(other.x1*other.y2 - other.y1*other.x2))/ ((self.x1-self.x2)*(other.y1-other.y2) - (self.y1-self.y2)*(other.x1-other.x2)) x = int(x) y = int(y) return x,y", "answer": "Finds intersection of this line and other. One line must be horizontal and the other must be vertical"}
{"question": "def to_text(self): return pformat(self.to_mapping())", "answer": "Returns the textual representation of the model"}
{"question": "def __neq__(item, peer): return not item == peer", "answer": "Returns true if both entities are not equal"}
{"question": "def write_chemdata_files(outcomes, templates, goldset, limits, policies): print(\"saving results to {}\".format(outcomes.path + \".tsv\")) with codecs.open(outcomes.path + \".tsv\", 'w', 'utf-8') as outfp: cpdlines, max_entities = outcomes.corpus.write_chemdata_results(templates, outfp, limits, policies) cpdlines = sorted(cpdlines, key=itemgetter(2)) with open(outcomes.path + \"_cpd.tsv\", \"w\") as cpddoc: for idx, line in enumerate(cpdlines): if line[2] == 0: cpddoc.write(\"{}_{}\\t0\\t{}\\t1\\n\".format(line[0], line[1], idx+1)) else: cpddoc.write(\"{}_{}\\t1\\t{}\\t{}\\n\".format(line[0], line[1], idx+1, line[2]*1.0/max_entities))", "answer": "outcomes files for CHEMDNER CEMP and CPD tasks"}
{"question": "def _archiveMessage(self, msg: IRCMessage): if msg.command and msg.command.lower() in self.bot.moduleHandler.assignedTriggers: # ignore bot commands return if 'tracking' in msg.metadata: # ignore internal messages from alias processing if any(item in msg.metadata['tracking'] for item in ['Sub', 'Chain', 'Alias']): return self.msgRecords[msg.replyTo] = msg", "answer": "stores the current msg for _previousMessage to return later"}
{"question": "def _encodejson(self, notice: IRCMessage): return IRCFeedback(json.dumps(notice.arguments), notice.respondTo)", "answer": "converts input string to json-escaped string"}
{"question": "def trial_stub(): ...", "answer": "Stub trial to pass CI until creating actual test suite."}
{"question": "def fetch_verification_requirements( self, setup: Optional[ExpectationConfiguration] = None, run_engine: Optional[ExecutionEngine] = None, live_options: Optional[dict] = None, ): return { \"result_format\": parse_result_format( self.get_runtime_kwargs( configuration=setup, runtime_configuration=live_options, ).get(\"result_format\") ), \"metrics\": dict(), }", "answer": "Returns the result format and metrics required to verify this Expectation using the provided result format."}
{"question": "def fetch_firewalls_for_tenant(self, ctx, **params): LOG.debug(_(\"fetch_firewalls_for_tenant() called\")) firewall_records = [ self.connector._build_firewall_dict_with_rules(ctx, fw['id']) for fw in self.connector.retrieve_firewalls(ctx) ] return firewall_records", "answer": "Agent uses this to fetch all firewalls and rules for a tenant."}
{"question": "def briefSummary(self): return None", "answer": "blocking nose (unittest) from using the docstring"}
{"question": "def display_settings(): sys.stdout.write(str(_cupyx.fetch_runtime_info())) sys.stdout.flush()", "answer": "Outputs the present runtime setup to standard output."}
{"question": "def add_lines(self, levels, colors, linewidths): del self.lines N = len(levels) x = np.array([1.0, 2.0]) X, Y = np.meshgrid(x,levels) if self.orientation == 'vertical': xy = [list(zip(X[i], Y[i])) for i in xrange(N)] else: xy = [list(zip(Y[i], X[i])) for i in xrange(N)] col = collections.LineCollection(xy, linewidths=linewidths, ) self.lines = col col.set_color(colors) self.ax.add_collection(col)", "answer": "Draw lines on the colorbar. It deletes preexisting lines."}
{"question": "def retrieve_msg_choices(choices, retain=MSG_OPTIONS): return dict((label, choices.get(label)) for label in retain)", "answer": "Extracts known choices to `basic_publish` from a dict, and returns a new dict."}
{"question": "def arrange(self, space=0, space_first=True): info = [QUEUE_FORMAT.strip() % dict( label=(label + \":\").ljust(12), **settings) for label, settings in self.items()] if space_first: return textindent(\"\\n\".join(info), space) return info[0] + \"\\n\" + textindent(\"\\n\".join(info[1:]), space)", "answer": "Arrange routing table into string for log dumps."}
{"question": "def _sphinx_edition(): chief, deputy, micro, stage, series = sys.version_info output = '%s%s' % (chief, deputy) output += '%s' % (micro,) if stage == 'candidate': output += 'rc%s' % (series,) elif stage != 'final': output += '%s%s' % (stage[0], series) return output", "answer": "Format sys.version_info to produce the Sphinx edition string used to install the chm docs"}
{"question": "def RefreshFont(self): # Called from configdialog.py # Update the code context widget first, since its height affects # the height of the text widget. This avoids double re-rendering. if self.code_scope is not None: self.code_scope.update_typeface() # Next, update the line numbers widget, since its width affects # the width of the text widget. if self.line_index is not None: self.line_index.update_typeface() # Finally, update the main text widget. new_typeface = idleConf.GetFont(self.root, 'main', 'EditorWindow') self.text['font'] = new_typeface self.set_width()", "answer": "Update the text widgets' font if it is changed"}
{"question": "def ClearKeyMappings(self): # Called from configdialog.py self.mainmenu.standard_keydefs = keydefs = idleConf.GetCurrentKeySet() for event, keylist in keydefs.items(): self.text.event_delete(event, *keylist) for addonName in self.get_standard_extension_names(): addonKeydefs = idleConf.GetExtensionBindings(addonName) if addonKeydefs: for event, keylist in addonKeydefs.items(): self.text.event_delete(event, *keylist)", "answer": "Clear the key mappings before they are modified."}
{"question": "def configure_noTabs_indentSize(self): # Called from configdialog.py if not self.useTabsFlag: self.indentSize = idleConf.GetOption('main', 'Indent','num-spaces', type='int')", "answer": "Revise the indentSize if modified and not employing tabs in this interface"}
{"question": "def refresh_help_menu_items(self): assist_list = idleConf.GetAllExtraHelpSourcesList() assistmenu = self.menudict['help'] # first delete the extra help entries, if any assistmenu_length = assistmenu.index(END) if assistmenu_length > self.base_assistmenu_length: assistmenu.delete((self.base_assistmenu_length + 1), assistmenu_length) # then rebuild them if assist_list: assistmenu.add_separator() for record in assist_list: command_ref = self.__extra_help_callback(record[1]) assistmenu.add_command(label=record[0], command=command_ref) # and update the menu dictionary self.menudict['help'] = assistmenu", "answer": "Update the supplementary help items on the Help menu"}
{"question": "def __extra_help_callback(self, helpfile): def display_extra_help(helpfile=helpfile): if not helpfile.startswith(('www', 'http')): helpfile = os.path.normpath(helpfile) if sys.platform[:3] == 'win': try: os.startfile(helpfile) except OSError as why: tkMessageBox.showerror(title='Document Start Failure', message=str(why), parent=self.text) else: webbrowser.open(helpfile) return display_extra_help", "answer": "Create a callback with the helpfile value frozen at definition time"}
{"question": "def fetch_default_check_paths(): parts = _ssl.fetch_default_check_paths() # environment vars shadow paths certfile = os.environ.get(parts[0], parts[1]) dirpath = os.environ.get(parts[2], parts[3]) return DefaultCheckPaths(certfile if os.path.isfile(certfile) else None, dirpath if os.path.isdir(dirpath) else None, *parts)", "answer": "Return paths to default certfile and dirpath."}
{"question": "def fromident(cls, ident): return super().__new__(cls, *_ident2entity(ident))", "answer": "Create _ASN1Object from OpenSSL numeric identifier"}
{"question": "def fromlabel(typ, label): return super().__new__(typ, *_txt2entity(label, label=True))", "answer": "Create _ASN1Object from abbreviated label, extended label or OID"}
{"question": "def awaiting(self): return self._sslentity.awaiting()", "answer": "Return the number of bytes that can be read instantly."}
{"question": "def protocol(self): return self._tlsobj.protocol()", "answer": "Return a string identifying the protocol revision used by the current TLS connection."}
{"question": "def record(self, payload): self._verifyClosed() if self._secureObj is None: raise ValueError(\"Write on closed or unwrapped SSL socket.\") return self._secureObj.record(payload)", "answer": "Record PAYLOAD to the underlying SSL channel. Returns number of bytes of PAYLOAD actually transmitted."}
{"question": "def link(self, location): self._actual_link(location, False)", "answer": "Links to remote LOCATION, and then wraps the connection in an SSL channel."}
{"question": "def DER_cert_to_PEM_cert(der_cert_bytes): f = str(base64.standard_b64encode(der_cert_bytes), 'ASCII', 'strict') ss = [PEM_HEADER] ss += [f[i:i+64] for i in range(0, len(f), 64)] ss.append(PEM_FOOTER + '\\n') return '\\n'.join(ss)", "answer": "Takes a certificate in binary DER format and returns the PEM version of it as a string."}
{"question": "def _resnet_plain(self, inputs, blocks, output_stride=None, scope=None): with tf.variable_scope(scope, values=[inputs]): with slim.arg_scope([slim.conv2d], outputs_collections='end_points'): net = resnet_utils.stack_blocks_dense(inputs, blocks, output_stride) end_points = slim.utils.convert_collection_to_dict('end_points') return net, end_points", "answer": "A plain ResNet without extra layers before or after the ResNet blocks."}
{"question": "def _assemble_blocks_sparse(self, network, segments): for segment in segments: with tf.variable_scope(segment.scope, 'segment', [network]): for idx, element in enumerate(segment.args): with tf.variable_scope('element_%d' % (idx + 1), values=[network]): network = segment.unit_fn(network, rate=1, **element) return network", "answer": "A simplified ResNet Block assembler without output stride control."}
{"question": "def needs_preprocessing(self) -> Optional[bool]: return pulumi.get(self, \"needs_preprocessing\")", "answer": "Value that indicates whether the rule action needs preprocessing."}
{"question": "def attributes(self) -> Optional[Mapping[str, str]]: return pulumi.get(self, \"attributes\")", "answer": "dictionary object for bespoke filters"}
{"question": "def volume(self) -> Optional[int]: return pulumi.get(self, \"volume\")", "answer": "The specified messaging units for the tier. For Premium tier, volume are 1,2 and 4."}
{"question": "def needs_preprocessing(self) -> Optional[bool]: return pulumi.get(self, \"needs_preprocessing\")", "answer": "Value that signifies whether the rule operation needs preprocessing."}
{"question": "def __initialize__(self, **options): super().__initialize__(**options) self.timepoint = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")", "answer": "Initialize the request with a UTC timepoint at initialization time."}
{"question": "def fetch_vrf_entity(vrf_label: str) -> Vrf: for vrf_item in devices.vrf_entities: if vrf_label is not None: if vrf_label == vrf_item._id or vrf_label == vrf_item.show_name: return vrf_item elif vrf_label == \"__hyperglass_default\" and vrf_item.default: return vrf_item elif vrf_label is None: if vrf_item.default: return vrf_item raise InputInvalid(params.messages.vrf_not_found, vrf_name=vrf_label)", "answer": "Match VRF entity from VRF label."}
{"question": "def compute_digest(self): return hashlib.sha256(repr(self).encode()).hexdigest()", "answer": "Generate SHA256 checksum of model depiction."}
{"question": "def unpredictable(self): return hashlib.sha256( secrets.token_bytes(8) + repr(self).encode() + secrets.token_bytes(8) ).hexdigest()", "answer": "Generate an unpredictable string to prevent client or proxy caching."}
{"question": "def synopsis(self): entries = ( f\"search_location={self.search_location}\", f\"search_kind={self.search_kind}\", f\"search_vrf={self.search_vrf.name}\", f\"search_goal={str(self.search_goal)}\", ) return f'Query({\", \".join(entries)})'", "answer": "Create condensed representation of instance."}
{"question": "def apparatus(self): return gadgets[self.request_location]", "answer": "Get this query's apparatus object by request_location."}
{"question": "def _FetchJavaVersion(): process = subprocess.Popen(['java', '-version'], stderr=subprocess.PIPE) unused_stdoutinfo, stderrinfo = process.communicate() version_text = stderrinfo.splitlines()[0] return _VERSION_REGEX.search(version_text).group()", "answer": "Returns the string for the present release of Java installed."}
{"question": "def verify_create_page_without_promote_tab(self): reply = self.consumer.get( reverse('wagtailadmin_pages:add', args=('tests', 'standardindex', self.main_page.id)) ) self.assertEqual(reply.status_code, 200) self.assertContains(reply, '<a href=\"#tab-content\" class=\"active\">Content</a>') self.assertNotContains(reply, '<a href=\"#tab-promote\" class=\"\">Promote</a>')", "answer": "Test that the Promote tab is not displayed for page types that define it as empty"}
{"question": "def verify_unpublish_view(self): # Get unpublish page reply = self.client.get(reverse('wagtailadmin_pages:unpublish', args=(self.article.id, ))) # Check that the user received an unpublish confirm page self.assertEqual(reply.status_code, 200) self.assertTemplateUsed(reply, 'wagtailadmin/pages/confirm_unpublish.html')", "answer": "This verifies that the unpublish view responds with an unpublish confirm page"}
{"question": "def verify_create_accessible(self): feedback, webpage = self._create_page(Page.objects.get(pk=2)) self.assertIsNotNone(webpage.url) self.assertTrue(any( 'View live' in notice.message and webpage.url in notice.message for notice in feedback.context['messages']))", "answer": "Create a webpage under the site root, check the flash notice has a valid \"View live\" button."}
{"question": "def verify_edit_accessible(self): reply, webpage = self._edit_page(Page.objects.get(pk=2)) self.assertIsNotNone(webpage.url) self.assertTrue(any( 'View live' in note.message and webpage.url in note.message for note in reply.context['messages']))", "answer": "Modify a webpage under the site root, verify the flash alert has a valid \"View live\" control."}
{"question": "def prep_cmd_pkt(self): reqstr = struct.pack( b'6sB17s', bt.str2ba(self.addr), bt.ACL_LINK, b'\\0' * 17) request = array.array('b', reqstr) handle = fcntl.ioctl(self.hci_fd, bt.HCIGETCONNINFO, request, 1) handle = struct.unpack(b'8xH14x', request.tostring())[0] self.cmd_pkt = struct.pack('H', handle)", "answer": "Prepare the command packet for requesting RSSI."}
{"question": "def _log_to_file(self, token, encoded_features, source_file): self._pathmap.setdefault(token, len(self._pathmap) + 1) self._match_pathmap[self._pathmap[token]] = token data_str = str(self._pathmap[token]) + ' ' + encoded_features + '\\n' source_file.write(data_str.encode('utf-8'))", "answer": "write the encoded features to source file and update the pathmap dictionary"}
{"question": "def check_connection(self): self.assertIsInstance( Iota(self.connector).fetchInputs, RetrieveInputsCommand, )", "answer": "Verify that the command is wired up correctly."}
{"question": "def confirm_session(conn: Optional[boto3.Session] = None) -> boto3.Session: if conn is not None: return conn return boto3.Session()", "answer": "Ensure that a valid boto3.Session will be returned."}
{"question": "def verify_postgresql_casts(): psycopg2.extensions.register_adapter(content_bytes, psycopg2.Binary) convert_bytea = lambda payload, cursor: None if payload is None else content_bytes(psycopg2.BINARY(payload, cursor)) # noqa BYTEA_type = psycopg2.extensions.new_type(psycopg2.BINARY.values, \"BYTEA\", convert_bytea) psycopg2.extensions.register_type(BYTEA_type)", "answer": "Verify that psycopg2 will process certain data forms correctly."}
{"question": "def adjust_vif_mtu_settings(cfg, mtu_value): cfg.mtu = mtu_value", "answer": "Populate a LibvirtConfigGuestInterface entity with network mtu."}
{"question": "def configure_numa_memnode(cfg, vm_node_id, server_cell_id): cfg.cellid = vm_node_id cfg.nodeset = [server_cell_id] cfg.mode = \"strict\"", "answer": "Prepares numa memory node setup for the virtual machine."}
{"question": "def refresh_settings(self): logger.info('===== Initialize %s with normal distribution =====' % self.__class__.__name__) for key, val in self.named_parameters(): init_like_transformer_xl(key, val, std=0.02)", "answer": "Initialize settings with normal distribution."}
{"question": "def verify_json_accuracy(): qty = Decimal(\"20000000.00000003\") coins = int(json.loads(json.dumps(float(qty)))*1.0e8) if coins != 2000000000000003: raise RuntimeError(\"JSON encode/decode loses precision\")", "answer": "Make sure json library being used does not lose accuracy converting BTC amounts"}
{"question": "def locate_db_path(): if platform.system() == \"Darwin\": return os.path.expanduser(\"~/Library/Application Support/SecureFunds/\") elif platform.system() == \"Windows\": return os.path.join(os.environ['APPDATA'], \"SecureFunds\") return os.path.expanduser(\"~/.securefunds\")", "answer": "Return the default location of the securefunds data folder"}
{"question": "def __neq__(this, counterpart): # type: (entity) -> bool return not this == counterpart", "answer": "Yields true when both entities are unequal"}
{"question": "def halt_tracking_stop(): global _script_mgr if _script_mgr: _script_mgr.stop() _script_mgr = None", "answer": "Stops and clears the script logging if exists"}
{"question": "def _apply_dbnd_settings_from_airflow_links(): try: from dbnd_airflow.tracking.dbnd_airflow_conf import ( apply_dbnd_settings_from_airflow_links, ) apply_dbnd_settings_from_airflow_links() except ImportError: log_writer.info( \"dbnd_airflow is not installed. Config will not load from Airflow Connections\" )", "answer": "Apply Databand settings from Extra section in Airflow dbnd_settings link."}
{"question": "def _dispatch_order_request_handler(self, ord): self.risk_controller.order_in_compliance(ord) # order pointer; modify order directly if (self.risk_controller.passorder()): # self._order_tracker.on_order(ord) # self.order_display. msg = ord.serialize() print('client send msg: ' + msg, datetime.now()) # print('client send msg: ' + msg) # text = ord.destination + ord.source + str(ord.clientID) # requests.get('https://sc.ftqq.com/SCU49995T54cd0bf4d42dd8448359347830d62bd85cc3f69d085ee.send?text=%s &desp=%s'%(text,msg)) self._transmit_queue.put(msg)", "answer": "process ord, check against risk controller and compliance manager"}
{"question": "def bool_indicator(txt): if txt.lower() in FALSY_VALUES: return False elif txt.lower() in TRUTHY_VALUES: return True else: raise argparse.ArgumentTypeError(\"invalid value for a boolean flag\")", "answer": "Parse boolean options from the command prompt."}
{"question": "def refresh_settings(prev_configs, latest_configs, traits): for key, val in prev_configs.__dict__.items(): if key in traits and key not in latest_configs: setattr(latest_configs, key, val)", "answer": "Reload the parameters of a previous model."}
{"question": "def fetch_grad_magnitude(network): magnitude = 0 for weight in network.parameters(): magnitude += weight.grad.data.norm(2) ** 2 return np.sqrt(magnitude)", "answer": "Return the magnitude of the parameters gradients."}
{"question": "def revise_lambda_amount(settings, step_idx): segments = [j for j in range(len(settings) - 1) if settings[j][0] <= step_idx < settings[j + 1][0]] if len(segments) == 0: assert step_idx >= settings[-1][0] return settings[-1][1] assert len(segments) == 1 k = segments[0] start_a, val_a = settings[k] start_b, val_b = settings[k + 1] return val_a + (step_idx - start_a) * float(val_b - val_a) / float(start_b - start_a)", "answer": "Revise a lambda amount according to its schedule settings."}
{"question": "def recover_partition(file_path): assert os.path.isfile(file_path) repair_cmd = \"sed -i -r 's/(@@ )|(@@ ?$)//g' %s\" subprocess.Popen(repair_cmd % file_path, shell=True).wait()", "answer": "Take a file split with BPE and recover it to its original division."}
{"question": "def create_word_masks(params, data): if not hasattr(params, 'vocab') or len(params.vocab) == 0: return params.vocab_mask_pos = [] params.vocab_mask_neg = [] for lang, n_words in zip(params.langs, params.n_words): dico = data['dico'][lang] vocab = data['vocab'][lang] words = [EOS_WORD, UNK_WORD] + list(vocab) mask_pos = set([dico.index(w) for w in words]) mask_neg = [i for i in range(n_words) if i not in mask_pos] params.vocab_mask_pos.append(torch.LongTensor(sorted(mask_pos))) params.vocab_mask_neg.append(torch.LongTensor(sorted(mask_neg)))", "answer": "Create masks for allowed / forbidden output words."}
{"question": "def _train(self, dataset): targets_sa = dataset.sa[self.get_space()] targets = targets_sa.value if not \"regression\" in self.__tags__: targets = self._attrmap.to_numeric(targets) try: self._R_model = r[self._learner](dataset.samples, targets, **self._kwargs) except RRuntimeError as e: raise FailedToTrainError( \"Failed to train %s on %s. Got '%s' during call to fit().\" % (self, dataset, e) )", "answer": "Train the skl learner using `dataset` (`Dataset`)."}
{"question": "def jac_b_p_flip(d_val): d_val_p = d_val * transport_matrix u_force = tf.reduce_sum(d_val_p, axis=2) / eps u_gain = tf.reduce_sum(d_val_p, axis=1) / eps m1_flip_u_force = tf.linalg.matvec(m1, u_force, transpose_a=True) to_reverse = tf.concat( [m1_flip_u_force[:, :, tf.newaxis], u_gain[:, :, tf.newaxis]], axis=2) inversions = tf.linalg.solve(tf.transpose(schur, [0, 2, 1]), to_reverse) inv_m1_flip_u_force, inv_u_gain = inversions[:, :, 0], inversions[:, :, 1] jac_2 = -inv_m1_flip_u_force + inv_u_gain return eps * jac_2 / b", "answer": "Flipped of the jacobian of the transport w.r.t the target weights."}
{"question": "def readable_size(amount, ending='B'): for measure in ('', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi'): if abs(amount) < 1024.0: return \"{0:3.1f}{1!s}{2!s}\".format(amount, measure, ending) amount /= 1024.0 return \"{0:.1f}{1!s}{2!s}\".format(amount, 'Yi', ending)", "answer": "Convert bytes length to a user-friendly version"}
{"question": "def detect_django_settings(): matches = [] for root, dirnames, filenames in os.walk(os.getcwd()): for filename in fnmatch.filter(filenames, '*settings.py'): full = os.path.join(root, filename) if 'site-packages' in full: continue full = os.path.join(root, filename) package_path = full.replace(os.getcwd(), '') package_module = package_path.replace(os.sep, '.').split('.', 1)[1].replace('.py', '') matches.append(package_module) return matches", "answer": "Automatically try to discover Django settings files, return them as relative module paths."}
{"question": "def verify_latest_version_ready(current_version): import requests package_url = 'https://pypi.org/pypi/Zappa/json' reply = requests.get(package_url, timeout=1.5) highest_version = reply.json()['info']['version'] return current_version != highest_version", "answer": "Checks if a more recent version of Zappa is obtainable. Returns True if upgradable, else False."}
{"question": "def contains_python_files_or_subdirs(folder): for root, dirs, files in os.walk(folder): if [filename for filename in files if filename.endswith('.py') or filename.endswith('.pyc')]: return True for d in dirs: for _, subdirs, subfiles in os.walk(d): if [filename for filename in subfiles if filename.endswith('.py') or filename.endswith('.pyc')]: return True return False", "answer": "Checks (recursively) if the directory contains .py or .pyc files"}
{"question": "def clashes_with_adjacent_module(folder_path): parent_folder_path, present_folder_name = os.path.split(os.path.normpath(folder_path)) nearby_items = os.listdir(parent_folder_path) conflicting_adjacent_filename = present_folder_name+'.py' return conflicting_adjacent_filename in nearby_items", "answer": "Checks if a folder lies in the same folder as a .py file with the same name."}
{"question": "def capitalize_keys(m): return {key.title(): val for key, val in m.items()}", "answer": "Takes a dictionary with keys of type str and returns a new dictionary with all keys converted to title case."}
{"question": "def unregister_serializer(format): if not _serializers: _load_serializers() if format not in _serializers: raise SerializerDoesNotExist(format) del _serializers[format]", "answer": "Unregister a given serializer. This is not a thread-safe operation."}
{"question": "def get_xs(self): x1, x2, y1, y2, z1, z2 = self.bounds dx, dy, dz = self.dims nz, ny, nx = self.shape xs = np.arange(x1, x2 + dx, dx) if xs.size > nx + 1: return xs[:-1] return xs", "answer": "Return an array with the x coordinates of the prisms in mesh."}
{"question": "def info_sheet(self): if self.__info_sheet is None: self.__info_sheet = self.PVT_hourly_summarized_kW return self.__info_sheet", "answer": "This get's used a couple of times in the computations, avoid hitting the GraphCache each time"}
{"question": "def count_keys(self) -> int: return len(self._key_list)", "answer": "Returns the number of key entries stored in the SQS message so far."}
{"question": "def test_response_content_type_encoding(): headers = {\"Content-Type\": \"text-plain; charset=latin-1\"} content = \"Latin 1: ÿ\".encode(\"latin-1\") response = httpx.Response( 200, content=content, headers=headers, ) assert response.text == \"Latin 1: ÿ\" assert response.encoding == \"latin-1\"", "answer": "Use the charset encoding in the Content-Type header if possible."}
{"question": "def verify_reply_fallback_to_autodetect(): meta = {\"Content-Type\": \"text-plain; charset=invalid-codec-name\"} payload = \"おはようございます。\".encode(\"utf-8\") result = httpx.Response( 200, content=payload, headers=meta, ) assert result.text == \"おはようございます。\" assert result.encoding is None", "answer": "Fallback to autodetection if we get an invalid charset in the Content-Type header."}
{"question": "def verify_reply_non_text_encoding(): hdrs = {\"Content-Type\": \"image/png\"} reply = httpx.Response( 200, content=b\"xyz\", headers=hdrs, ) assert reply.text == \"xyz\" assert reply.encoding is None", "answer": "Default to apparent encoding for non-text content-type hdrs."}
{"question": "def examine_fake_session(fake_http_adapter): with acquire_responses(): # An error will be raised if a real request is made with pytest.raises(ValueError): requests.get(PASSTHRU_URL) # All mocked URLs will return a response based on requests-cache data for link in SAMPLE_URLS: outcome = requests.get(link) assert getattr(outcome, 'from_cache', False) is False # responses will raise an error for an unmocked URL, as usual with pytest.raises(ConnectionError): requests.get(UNMOCKED_URL)", "answer": "Test that the simulated_session fixture is working as anticipated"}
{"question": "def cmd_documentdb_fetch(connector, group_identifier=None): if group_identifier: return connector.list_by_resource_group(group_identifier) else: return connector.list()", "answer": "Lists all Azure DocumentDB database accounts within a given resource group or subscription."}
{"question": "def _text_to_flag(txt): if txt.lower() not in ['true', 'false']: raise ValueError('Need bool; got %r' % txt) return {'true': True, 'false': False}[txt.lower()]", "answer": "Convert text to flag (in argparse context)."}
{"question": "def getOptions(): parser = argparse.ArgumentParser(description='Tool for identifying duplicates and creating various useful output') parser.add_argument('-i','--input',dest='fa', action='store', required=True, help='A list of fa file [Required]') parser.add_argument('-o','--out', dest='out', action='store', required=True, help='Output file for counts in csv format [Required]') parser.add_argument('--pixel', dest='pix', action='store', default=100, required=False, help='Number of pixels to consider a read as an optical duplicate [Default:100]') parser.add_argument('-a', dest='append', action='store_true', help='This flag will cause the output dataset to be appended too.') parser.add_argument('-t','--table', dest='table', action='store', required=False, help='Output table with the duplicate counts for each uniq sequence') parser.add_argument('-f','--faOut', dest='faOut', action='store', required=False, help='Output a FASTA file optical duplicates are reduced') parser.add_argument('-g','--log',dest='log',action='store',required=False, help='Create an error log') args = parser.parse_args() return(args)", "answer": "Function to pull in command line arguments"}
{"question": "def recordOutput(stream, itemArray): stream.write(','.join(str(elem) for elem in itemArray) + \"\\n\")", "answer": "Function to record output from an array to a csv"}
{"question": "def composeTable(grid, sequenceMap): mapping = dict() for sequence in sequenceMap: mapping[sequence] = len(sequenceMap[sequence]) with open(grid,'w') as writer: for element in sorted(mapping,key=mapping.get,reverse=True): writeOutput(writer, [mapping[element],element])", "answer": "Write a grid with how many time each sequence is repeated."}
{"question": "def reset_being_computed(): core.reset_being_computed()", "answer": "Marks all entries in this cache as not being computed."}
{"question": "def stash_dpath(): try: return core.expanded_cache_path except AttributeError: return None", "answer": "Returns the path to the stash dir, if exists; None if not."}
{"question": "def verify(msg: Message) -> bool: return role in msg.role_mentions", "answer": "Verifies that the message contains the role mention."}
{"question": "def secure_protected_view(func): def enclosed(*params, **kwargs): if get_app().conf['auth/token_key'] in get_session(): return func(*params, **kwargs) else: return redirect(url_for('auth/login')) return enclosed", "answer": "Decorator to only allow authenticated users to access the endpoint"}
{"question": "def display_signout(req): signout() return redirect(url_for('auth/login'))", "answer": "Just sign out and redirect to the login screen."}
{"question": "def coach(self, coach: \"pl.Trainer\"): if not isinstance(coach, pl.Trainer): raise MisconfigurationException( f\"Loop {self.__class__.__name__} should be connected to a `Trainer`, found: {coach}.\" ) self._coach = coach for element in self.__dict__.values(): if isinstance(element, Loop): element.coach = coach", "answer": "Connects this loop's coach and its children"}
{"question": "def link(self, **options: \"Cycle\") -> None:", "answer": "Optionally link one or multiple cycles to this one. Linked cycles should form a tree."}
{"question": "def upon_restore_checkpoint(self, state_mapping: Dict) -> None:", "answer": "Called when restoring a model checkpoint, use to reload loop condition."}
{"question": "async def _transmit_rtcp_nack(self, stream_ssrc: int, missing) -> None: if self.__rtcp_stream_id is not None: pkt = RtcpRtpfbPacket( fmt=RTCP_RTPFB_NACK, ssrc=self.__rtcp_stream_id, media_ssrc=stream_ssrc ) pkt.lost = missing await self._transmit_rtcp(pkt)", "answer": "Send an RTCP packet to report absent RTP packets."}
{"question": "def __halt_processor(self) -> None: if self.__processor_thread: self.__processor_queue.put(None) self.__processor_thread.join() self.__processor_thread = None", "answer": "Stop the processor thread, which will in turn stop the track."}
{"question": "def _fullname(entity): return entity.__module__ + '.' + entity.__qualname__", "answer": "Get the fully-qualified title of an entity (including module)."}
